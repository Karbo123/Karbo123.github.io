<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="3D目标检测, 任我行">
    <meta name="description" content="3D目标检测介绍3D detection的各种模型框架方法等。
背景知识：

RGB image == 2D；RGB-D image == 2.5D；point cloud == 3D
Amodal 3D Object Detection：">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>3D目标检测 | 任我行</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">任我行</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">任我行</div>
        <div class="logo-desc">
            
            可以任我走怎么到头来又随着大队走，人群是那么像羊群
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Karbo123" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Karbo123" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>





<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/3.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        3D目标检测
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/3d/" target="_blank">
                                <span class="chip bg-color">3d</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/3d/" class="post-category" target="_blank">
                                3d
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-09-19
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                        6.7k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        27 分
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="3D目标检测"><a href="#3D目标检测" class="headerlink" title="3D目标检测"></a>3D目标检测</h1><p>介绍3D detection的各种模型框架方法等。</p>
<p>背景知识：</p>
<ul>
<li>RGB image == 2D；RGB-D image == 2.5D；point cloud == 3D</li>
<li>Amodal 3D Object Detection：即使部分被遮挡，也要能正确估计出尺寸，而不受遮挡的影响。</li>
<li>objectness：指代非背景的任何物体，不讨论特定的物体类别。</li>
<li>LiDAR：激光雷达（更精细）；radar：无线电波雷达（更远）</li>
</ul>
<h2 id="2D-Driven-3D-Object-Detection-in-RGB-D-Images"><a href="#2D-Driven-3D-Object-Detection-in-RGB-D-Images" class="headerlink" title="2D-Driven 3D Object Detection in RGB-D Images"></a>2D-Driven 3D Object Detection in RGB-D Images</h2><blockquote>
<p>ICCV2017《2D-Driven 3D Object Detection in RGB-D Images》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_iccv_2017/html/Lahoud_2D-Driven_3D_Object_ICCV_2017_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_iccv_2017/html/Lahoud_2D-Driven_3D_Object_ICCV_2017_paper.html</a></p>
</blockquote>
<h3 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h3><p>使用RGB-D图像，做detection。借助2D图像中成熟的detection技术，来减少3D中的搜索空间，加速运行速度，同时精度又不会损失很多。</p>
<p>TODO IDEA：将2D detection network换成2D segmentation network是否会更好？</p>
<h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><p>在RGB通道（普通彩图）使用传统的2D detection方法，得到2D bounding box。那么物体所在的位置就被限制在2D bounding box所在的视野范围内（即frustum，截头锥体）。使得搜索空间减少。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p><img src="1_1.png" alt></p>
<p>主要流程：</p>
<ul>
<li><p>2D object detection：得到frustum，减少搜索空间</p>
</li>
<li><p>object orientation：得到方向</p>
</li>
<li><p>bounding box regression：根据方向，回归出框框的位置和大小</p>
</li>
<li><p>refinement：根据环境信息，优化方框得分</p>
</li>
</ul>
<ol>
<li><p>Slit Detection</p>
<p>利用2D目标检测的技术，得到2D bounding box，从而得到frustum</p>
<p>使用Faster R-CNN网络，以VGG-16作为backbone</p>
<p><img src="1_2.png" alt></p>
</li>
<li><p>Estimating 3D Object Orientation</p>
<p>出发点：大多数物体都具有“Manhattan frame”，即方方正正的物体结构（若是“non-Manhattan structure”，例如球体，其任意的orientations输出均认为是正确的）。需要使得normals与3个主要的正交方向（三个坐标轴）对齐。并且假设一个frustum内只有一个object、物体放置在水平面上（orientation其中一个轴与floor法向平行）</p>
<p>the Manhattan Frame Estimation (MFE) technique：</p>
<p>   旋转矩阵$R$能通过求解下面的优化问题得到：</p>
<script type="math/tex; mode=display">
\min_{R,X} \frac{1}{2}||X-RN||^2_F + \lambda ||X||_{1,1}</script><p>   其中$N$是由每个3D点的normals组成的矩阵，$X$是使得$RN$稀疏的松弛变量。</p>
<p>   将normals旋转后，对齐坐标轴，即使得$RN$稀疏。</p>
</li>
<li><p>Bounding Box Regression</p>
<p>以3D points的重心作为原点，3个orientations作为坐标轴方向，建立局部的正交坐标系统。</p>
<p>然后沿着坐标轴（3个都要），然后根据3D points的坐标计算直方图，则直方图能表示点的密度（物体的surface处密度比较大）。然后将直方图输入MLP中进行学习，输出bounding box的位置和大小。</p>
<p>最后粗略计算score，它是score1和score2的线性组合：</p>
<ul>
<li>score1：2D detection时的score</li>
<li>score2：3D point density score（The 3D point density score is computed by training a linear SVM classifier on the 3D point cloud density of the 3D cuboids for all classes）</li>
</ul>
</li>
<li><p>Refinement Based on Context Information</p>
<p>利用环境信息优化结果，例如一般情况下chairs与table靠近的可能性比较大。</p>
<p>假设labels的分布是Gibbs distribution，然后构造factor graph，使用unary and binary log potential functions得到probability，然后Our goal is to find the labelling that maximizes the aposteriori (MAP)，然后转化为linear program求解。</p>
</li>
</ol>
<h2 id="Amodal-Detection-of-3D-Objects-Inferring-3D-Bounding-Boxes-from-2D-Ones-in-RGB-Depth-Images-👍"><a href="#Amodal-Detection-of-3D-Objects-Inferring-3D-Bounding-Boxes-from-2D-Ones-in-RGB-Depth-Images-👍" class="headerlink" title="Amodal Detection of 3D Objects: Inferring 3D Bounding Boxes from 2D Ones in RGB-Depth Images 👍"></a>Amodal Detection of 3D Objects: Inferring 3D Bounding Boxes from 2D Ones in RGB-Depth Images 👍</h2><blockquote>
<p>CVPR2017《Amodal Detection of 3D Objects: Inferring 3D Bounding Boxes from 2D Ones in RGB-Depth Images》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Deng_Amodal_Detection_of_CVPR_2017_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2017/html/Deng_Amodal_Detection_of_CVPR_2017_paper.html</a></p>
</blockquote>
<h3 id="概括-1"><a href="#概括-1" class="headerlink" title="概括"></a>概括</h3><p>本质：将RGB-D图当作普通的图像来处理，使用Fast R-CNN网络（网络中使用的proposal是2D的），只不过网络输出的2D box regression变成了3D box regression。然后使用外部方法将2D proposal转换为3D proposal。最后：final box == 3D proposal + 3D box regression</p>
<p>创新点：</p>
<ul>
<li><p>将2D图像的feature应用于3D bounding box的regression上，即不需要将2.5D RGB-D图转化为3D的数据来处理。说明2.5D能编码足够的3D amodal object detection特征。</p>
</li>
<li><p>能直接得到bounding box的位置、大小、朝向（因为将其表示为7维的向量了）</p>
</li>
</ul>
<p>注：</p>
<ul>
<li>2.5D方法：直接在2.5D的RGB-D上学习，将2D的结果转化为3D的结果</li>
<li>3D的方法：直接在3D点云上进行学习，从3D window中提取点云特征</li>
<li>真实采集RGB-D图像并不是完美的，在Depth上noisy，而且在Depth图可能有“black hole”（或许是红外线反光造成的）。而复原出的point cloud误差大、稀疏、且物体只有一部分的表面有点集。</li>
<li>作者还稍微改进/修正了NYUV2数据集</li>
</ul>
<p>与Fast R-CNN的不同：</p>
<ul>
<li>2D proposal的方法不同</li>
<li>本文是RGB图和D图的特征的concat，而Fast R-CNN没有“双路并行”和concat。</li>
<li>本文的网络后端是：classification、3D box regression；而Fast R-CNN后端是classification、2D box regression。</li>
<li>本文需要将2D proposal转换成3D proposal，才能利用网络输出的“3D box regression”来得到最终的box；而Fast R-CNN直接就是2D proposal + 3D box regression == final box</li>
</ul>
<p>TODO IDEA：如果网络中使用的是3D proposal而不是2D proposal（下图中的绿色的“云”的部分），那么效果或不会更好？（这样就更加像Fast R-CNN了）；能否用Region Proposal Networks来替代传统的proposal方式，以实现加速？；如何把2D box proposal转换为3D box proposal的过程使用神经网络来处理（转换成只使用神经网络处理的关键或许是如何设计neural network输入和输出的“数据”和“数据排列的结构”，因为中间的过程是个black box）？</p>
<h3 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h3><p>先想办法做出3D bounding box的proposals，然后利用2D的特征来regress你的3D proposals。</p>
<p>即：从RGB-D图像提议出一个2D proposal，然后将RGB-D和2D proposal送入网络，网络末端则输出classification和3D regression。然后基于2D proposal提议出3D proposal，再利用3D regression便得到最终的3D bounding box位置。</p>
<p>使用2D proposal竟然可以得到3D regression，表明网络需要从图像中隐式地预估出3D box并且学习得到3D regression。</p>
<h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><p><img src="2_1.png" alt></p>
<p>仿照Fast R-CNN的结构和方法。</p>
<p>将RGB图和D图输入到2个VGG16。基于2D object proposals和enlarged contextual patches从RoI pooling layer提取特征，然后将特征cancat，送入后续的multiple tasks learning网络中。</p>
<p>具体细节如下：</p>
<ol>
<li><p>2D RoI proposals</p>
<p>使用adapted MCG algorithm算法，来获取proposals（只是可能存在的区域，不一定真的含有物体），可以参考这里：<a href="https://zihuaweng.github.io/2017/12/24/region_proposals/" target="_blank" rel="noopener">多种region_proposal算法比较</a></p>
</li>
<li><p>3D box proposals</p>
<p><img src="2_2.jpg" alt></p>
<p>3D box proposals从2D segment proposals中产生。</p>
<p>将3D bounding box表示成7维向量：$[x,y,z,l,w,h,\theta]$（假设放置在水平面上，则方位角只需要一个变量$\theta$），（注：$z$是深度方向）</p>
<p>3D proposals的设定方式：</p>
<ul>
<li>3D box中心点的$x$和$y$：2D segment pixels投影到3D空间中获得</li>
<li>3D box中心点的$z$：设置成segment points深度的中值</li>
<li>3D box的大小$l,w,h$：设置成该类的平均尺寸（we simply use averaged class-wise box dimensions estimated from training set as base 3D box size.）</li>
<li>3D box的方向角$\theta$：设为零</li>
</ul>
</li>
<li><p>3D box regression</p>
<p>将proposals修正得到最终的box，修正量：$[\delta_x,\delta_y,\delta_z,\delta_l,\delta_w,\delta_h,\delta_\theta]$</p>
<p>训练时，因为有ground-truth boxes，所以可以知道“修正量”的目标值应该是多少。</p>
<p>与Fast R-CNN的方法类似，将feature和box输入到3D box regressor net，从而训练得到“修正量”。</p>
</li>
<li><p>Multi-task Loss</p>
<p>将“物体种类分类”和“方框回归”的损失函数合在一起，得到多任务的Loss</p>
</li>
<li><p>Post processing</p>
<p>在2D detected boxes中使用NMS，在3D中不使用NMS。</p>
<p>对结果不pruning（例如不基于物体数值统计上的尺寸来进行筛选去除结果）。</p>
</li>
<li><p>Mini-batch sampling</p>
<p>主要讲怎么从标记的数据中，采样出包含positive和negative样本的minibatch，详略。</p>
</li>
</ol>
<h2 id="Deep-Sliding-Shapes-for-Amodal-3D-Object-Detection-in-RGB-D-Images-👍"><a href="#Deep-Sliding-Shapes-for-Amodal-3D-Object-Detection-in-RGB-D-Images-👍" class="headerlink" title="Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images 👍"></a>Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images 👍</h2><blockquote>
<p>CVPR2016《Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images》</p>
<p>paper下载：<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Song_Deep_Sliding_Shapes_CVPR_2016_paper.html" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Song_Deep_Sliding_Shapes_CVPR_2016_paper.html</a></p>
</blockquote>
<h3 id="概括-2"><a href="#概括-2" class="headerlink" title="概括"></a>概括</h3><p>仿照Faster R-CNN，提出了3D Region Proposal Network（RPN）和joint Object Recognition Network（ORN）。</p>
<p>其中RPN则利用voxels作为输入，然后输出bounding box（在anchor的基础上学习offset）和objectness score；而ORN则利用voxels和RGB image作为输入，然后输出bounding box offset和class score</p>
<p>特点：box的位置的proposal使用3D方法；RPN具有两个感受野；ORN结合了3D几何结构特征和2D图像特征。</p>
<p>效果：SOTA且更快（与Sliding Shapes相比）</p>
<p>TODO IDEA：能不能将real world的bounding box转化为在depth map上的等效标签？</p>
<h3 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>Encoding 3D Representation（using directional TSDF）</p>
<p>将space划分为等间隔的3d voxel grid，每一个voxel的内容都是一个3维向量$[dx,dy,dz]$。其中$\sqrt{dx^2+dy^2+dz^2}$是这个voxel center到其他points（point on surface）的最近的距离，数值分别沿着坐标轴方向。然后再被$2\delta$ clipped（$\delta$是格子大小）。正负号该voxel center代表在surface的前面还是后面。</p>
</li>
<li><p>Multi-scale 3D Region Proposal Network</p>
<p><img src="3_1.png" alt></p>
<p>作用：提出区域建议，所以输入是用directional TSDF编码后的voxels；输出的objectness score如果太低则不被采纳；</p>
<p>特点：两个感受野，分别建议出大框框和小框框。</p>
<p><img src="3_2.png" alt></p>
<p>实现细节：</p>
<ul>
<li>使用房间的主方向作为所有proposals的朝向（即使用了Manhattan world assumption）</li>
<li>每个voxel上有个feature，anchor有N个。将其送入softmax分支（2N个nodes）则得到N个objectness score；送入L1 smooth分支（6N个nodes）则得到N个bounding box offset（根据anchor和offset就可以计算出理想值为ground truth的proposal，这是第一次回归）</li>
<li>感受野更大的是因为有一个pooling，每个位置具有15个anchors；感受野小的每个位置上具有4个anchor；合起来相当于能输出19种不同大小的框框。</li>
<li>根据框框内点的密度，移除近似真空的box</li>
<li>训练过程：minibatch包含2张图，每张图采样出256个anchors。positive（iou较大）比negative（iou较小）为1比1</li>
<li>多任务损失：将softmax和L1 smooth线性结合得到合成的损失函数。</li>
<li>使用3D NMS剔除重合度大的多余框框</li>
</ul>
</li>
<li><p>Joint Amodal Object Recognition Network</p>
<p><img src="3_3.png" alt></p>
<p>实现细节：</p>
<ul>
<li>将box各个尺度上扩大12.5%，以容纳更多信息。然后截取框内的部分输入到网络中。</li>
<li>3D部分（只用了depth map，没有颜色信息）：将box内的space划分成30x30x30的的voxels，然后用directional TSDF编码voxel；2D部分：将box内的3D点投射到2D上，从而获取2D box，然后用预训练的VGG提取feature map，然后用RoI pooling池化到7x7固定尺寸。最后将2D和3D特征concat，预测object label（softmax）和3D box offset（L1 smooth）。</li>
<li>训练过程：For each mini-batch, we sample 384 examples from different images, with a positive to negative ratio of 1:3.</li>
<li>多任务损失：将softmax和L1 smooth线性结合得到合成的损失函数。</li>
<li>使用3D NMS剔除重合度大的多余框框</li>
<li>使用Object size pruning技术来降低不合常规的框框的得分（比常规太大或太小则得分除以2）</li>
</ul>
</li>
</ol>
<h2 id="Deep-Continuous-Fusion-for-Multi-Sensor-3D-Object-Detection"><a href="#Deep-Continuous-Fusion-for-Multi-Sensor-3D-Object-Detection" class="headerlink" title="Deep Continuous Fusion for Multi-Sensor 3D Object Detection"></a>Deep Continuous Fusion for Multi-Sensor 3D Object Detection</h2><blockquote>
<p>ECCV2018《Deep Continuous Fusion for Multi-Sensor 3D Object Detection》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_ECCV_2018/html/Ming_Liang_Deep_Continuous_Fusion_ECCV_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/html/Ming_Liang_Deep_Continuous_Fusion_ECCV_2018_paper.html</a></p>
</blockquote>
<h3 id="概括-3"><a href="#概括-3" class="headerlink" title="概括"></a>概括</h3><p>将雷达（LIDAR，point cloud数据）和前视摄像头（camera image，前视RGB图像）的数据做特征融合。做object detection（在BEV平面视角下的2D detection，或3D detection都支持）。使用端到端的网络结构，多尺度下的特征图融合。效果：显著的SOTA，推理速度快。</p>
<p><img src="4_4.png" alt></p>
<p>注：</p>
<ul>
<li>BEV即Bird’s-Eye-View，即俯视图</li>
<li>难点：如何实现point cloud与RGB的特征融合？</li>
<li>camera image和point cloud都是车辆的前方视角的数据</li>
</ul>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>原理概述：将前视图像的特征图转变为俯视的特征图；将point cloud转变为俯视图；然后两个俯视图相加；再在多层级上融合；然后用与RPN类似的方法提取区域建议，最后得到detection result。</p>
<p>将前视的camera image转变为俯视的BEV的关键原理（continuous fusion layer的功能）：</p>
<ul>
<li>用CNN提取特征得到多层级的camera image feature map，将camera image feature map（下图中的红色“camera image”）的feature利用投影关系“加载”到point cloud中，再将point cloud投影到BEV平面上。给定BEV上的一个target pixel（下图中右边的白色正方形），先用KNN的方法寻找其邻居，然后使用使用类似于“点卷积”的方法聚合信息，从而获取到target pixel应得的特征向量。</li>
</ul>
<p><img src="4_1.png" alt></p>
<h3 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h3><p><img src="4_2.png" alt></p>
<p>网络的整体架构如上。</p>
<ul>
<li>黄色的camera stream：使用ResNet18提取camera image的多层级的feature map。</li>
<li>红色的LIDAR stream：使用ResNet18（不是同一个）提取LIDAR BEV（雷达点云的俯视图）的多层级的feature map</li>
<li>蓝色的Fusion Layers：使用continuous fusion layer将前视的feature map转变为俯视的feature map，然后与LIDAR BEV的feature map做融合</li>
<li>绿色的detection header：使用类似于Faster R-CNN的方法，用RPN的方法提取区域建议，然后分类识别等等。</li>
</ul>
<ol>
<li><p>Continuous Fusion Layer</p>
<p><img src="4_3.png" alt></p>
<ul>
<li>如果要求BEV上的一个浅蓝色正方形像素点对应的feature vector，则首先寻找其K个邻居（邻居是点云的俯视图投影的来的）；从而知道这K个邻居在点云中是哪K个点，并且计算在3D点云空间中的相对坐标$x_j-x_i$（$x_j$是邻居，$x_i$是中心点）</li>
<li>然后将这K个点投影到前视图（实质上是前视图的feature map），这K个点落在哪个像素上（因为不可能刚好落在像素上，所以实际上是使用双线性插值），就被携带了这个像素所对应的feature vector；这样这K个点就都有各自的feature vector了，第$j$个点的feature vector记作$f_j$</li>
<li>然后作者仿照“点卷积”（$h_i=\sum_j MLP(x_i-x_j)\cdot f_j$）的公式，作者提出使用：<script type="math/tex">h_i=\sum_j MLP(cancat[f_j,x_j-x_i])</script>公式更快更省内存。使用这条公式得到的$h_i$即是浅蓝色正方形得到的feature vector</li>
</ul>
<p>特点：BEV图上的像素点包含了“点云的局部空间信息”、“前视图的特征信息”，并使用MLP使这两个信息”融合处理”，从而生成BEV图。</p>
</li>
<li><p>Architecture of our model</p>
<ul>
<li>使用ResNet18提取feature map</li>
<li>continuous fuse layer的输入是对应的image feature map以及所有特征图融合后的输出；特征图之间用逐元素之间的加法加起来</li>
<li>随后将得到的feature map使用1x1卷积；用2个anchors；anchor的输出是逐像素的类别置信度以及box的center、location、size、orientation；最后用NMS</li>
<li>使用多任务混合损失函数：$L=L_{cls}+\alpha L_{reg}$，即分类和回归任务的混合</li>
</ul>
</li>
</ol>
<h2 id="Frustum-PointNets-for-3D-Object-Detection-from-RGB-D-Data"><a href="#Frustum-PointNets-for-3D-Object-Detection-from-RGB-D-Data" class="headerlink" title="Frustum PointNets for 3D Object Detection from RGB-D Data"></a>Frustum PointNets for 3D Object Detection from RGB-D Data</h2><blockquote>
<p>CVPR2018《Frustum PointNets for 3D Object Detection from RGB-D Data》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Frustum_PointNets_for_CVPR_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_Frustum_PointNets_for_CVPR_2018_paper.html</a></p>
</blockquote>
<h3 id="概括-4"><a href="#概括-4" class="headerlink" title="概括"></a>概括</h3><p>将RGB-D转为point cloud，然后使用3d的方法来处理点云数据。整体框架：先用2D detection的方法缩小搜索空间，然后做3D Instance Segmentation剔除杂点，最后Amodal 3D Box Estimation来回归得到框框。</p>
<p>作者声称的优点：efficiency、high recall、precisely estimate 3D bounding boxes even under strong occlusion or with very sparse points、SOTA、having real-time capability</p>
<p>模型名字：Frustum PointNets</p>
<h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p><img src="5_1.png" alt></p>
<p>利用2D detection的方法缩小搜素空间（形成frustum）；然后剔除杂点、生成回归框。</p>
<p>生成frustum的优点：efficiently propose possible locations of 3D objects in a 3D space</p>
<h3 id="实现-4"><a href="#实现-4" class="headerlink" title="实现"></a>实现</h3><p><img src="5_2.png" alt="Frustum PointNets for 3D object detection."></p>
<p><img src="5_3.png" alt="Coordinate systems for point cloud."></p>
<ol>
<li><p>Frustum Proposal</p>
<p>利用2D detection的方法（如FPN），生成2D region proposal（predict amodal 2D boxes），并且分类类别（one-hot class vector）；然后region2frustum模块则根据2D region生成3D frustum；然后转而使用“Coordinate systems for point cloud”图中（b）的坐标系，即其中的一个轴是沿着视线的中央位置的。</p>
</li>
<li><p>3D Instance Segmentation</p>
<p>用二分类来对每个点做segmentation，同时利用2D detector得到的prediction，从而能够判断某个点是否属于目标物体（object of interest）的点；这样就能生成一张mask（掩膜），从而得到比较干净的区域；然后将XYZ坐标减去其重心，得到“Coordinate systems for point cloud”图中（c）的坐标系的样子（注意，我们不缩放点云的坐标）。</p>
<p><img src="5_4.png" alt></p>
<p>作用：剔除Foreground Occluder（遮挡物）和Background Clutter（背景杂乱），因为depth的区别比较大</p>
<p>前提：Note that each frustum contains exactly one object of interest.</p>
</li>
<li><p>Amodal 3D Box Estimation</p>
<p>先用T-Net（light-weight regression PointNet）来平移点云（回归出center的残差），使得centroid接近amodal box center（real object center）；</p>
<p><img src="5_5.png" alt></p>
<p>然后用Amodal 3D Box Estimation PointNet来回归出框框（网络输出的结点个数是$3+4\times NS+2\times NH$？？？）</p>
<p><img src="5_6.png" alt></p>
<p>回归框框的量：</p>
<ul>
<li>center residual：理想值是T-net之后的中心位置与真实中心的偏差（绝对坐标下的中心 = mask的中心 + “T-NET”学习到的偏移量 + 框框回归得到的偏移量）</li>
<li>size</li>
<li>heading angle$ \theta $（along up-axis）</li>
</ul>
</li>
<li><p>Training</p>
<ul>
<li><p>使用multi-task losses（三个网络的混合loss）</p>
</li>
<li><p>提出所谓的“corner loss”，能同时优化框框的center、size、heading，而避免了只优化一个量（本质上corner loss是预测框的8个顶点与ground truth的顶点的距离之和）</p>
</li>
</ul>
</li>
</ol>
<h2 id="Joint-3D-Proposal-Generation-and-Object-Detection-from-View-Aggregation"><a href="#Joint-3D-Proposal-Generation-and-Object-Detection-from-View-Aggregation" class="headerlink" title="Joint 3D Proposal Generation and Object Detection from View Aggregation"></a>Joint 3D Proposal Generation and Object Detection from View Aggregation</h2><blockquote>
<p>IROS2018《Joint 3D Proposal Generation and Object Detection from View Aggregation》</p>
<p>paper下载：<a href="https://ieeexplore.ieee.org/document/8594049" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/8594049</a></p>
</blockquote>
<h3 id="概括-5"><a href="#概括-5" class="headerlink" title="概括"></a>概括</h3><p>提出了一套无人驾驶中的detection方案叫AVOD（Aggregate View Object Detection network）。</p>
<p>使用“雷达点云数据+RGB图像”作为输入（两种模态所以需要multimodal feature fusion）。仿照Faster R-CNN，AVOD主要由RPN、detector network组成。特征提取操作还是在2D层次上的处理。</p>
<p>优点：</p>
<ul>
<li>可以检测小物体，且high recall（因为使用high resolution feature map（仿照了FPN的做法），以及两个模态融合，所以可以在proposal阶段达到high recall）</li>
<li>较精确预测3D box的orientation（因为作者提出了新的box表达方式，称作4 corner encoding）</li>
<li>SOTA、场景泛化性能好、实时、低内存占用（efficiency是因为proposal之前使用1x1 conv进行了feature map channels number的reduction）</li>
</ul>
<p>3D box与2D box的区别：3Dbox是3D的，3Dbox还要预测orientation</p>
<h3 id="实现-5"><a href="#实现-5" class="headerlink" title="实现"></a>实现</h3><p><img src="6_1.png" alt></p>
<ol>
<li><p>将point cloud数据通过某种基于voxel grid的方法转化成6-channel BEV map，这个BEV就是上图中的“BEV Input”</p>
</li>
<li><p>然后利用下图类似于FPN结构的网络来提取特征，分别得到“Image Feature Maps”和“BEV Feature Maps”（得到的是高分辨率的特征图，有助于识别尺寸小的物体。输出图的尺寸不变，但是通道数可能改变。取最后一层的输出作为特征图）</p>
<p><img src="6_2.png" alt></p>
</li>
<li><p>RPN</p>
<ul>
<li><p>目的：回归出anchor与GT的偏移量$(\Delta t_x,\Delta t_y,\Delta t_z,\Delta d_x,\Delta d_y,\Delta d_z)$（这里使用的是axis aligned bounding box），以及objectness score（注意这里并没有回归orientation）</p>
<p><img src="6_3.png" alt></p>
</li>
<li><p>anchor生成方式：centroid是BEV平面上的等间隔采样，中心的高度等于摄像机的高度，size是聚类获得。所以本质上是用2D的anchor表示3D（因为中心点的高度都是一样的）。并且移除空的anchors。暂不考虑orientation，即与坐标轴对齐</p>
</li>
<li><p>crop and resize：将3D anchor投影到BEV或前视图上，得到对应的ROI区域。然后将对应区域crop出来，再resize。从而得到固定尺寸的输入</p>
</li>
<li><p>流程：</p>
<ul>
<li>先1x1卷积将特征图缩小到只有1个通道（减少计算量）</li>
<li>然后根据anchors来进行crop and resize，得到“feature crop”</li>
<li>将“feature crops”以element-wise mean operation的方式进行融合</li>
<li>然后送入FC层，最后再2D NMS（本质是2D的，因为proposals中心点的高度都是一样的）</li>
</ul>
</li>
</ul>
</li>
<li><p>Detection Network</p>
<ul>
<li>目的：得到最终的detection box</li>
<li>输入：将3D proposals投影到BEV、前视图得到的区域，再crop and resize，这样输入尺寸才相同</li>
<li><p>输出：box regression, orientation estimation, and category classification for each proposal</p>
</li>
<li><p>框框编码：将3D box用“4 corner encoding”方法编码，即4个底角的xy坐标，以及上下面到地板的距离，那么框框的回归量就是$(\Delta x_1,\Delta x_2,\Delta x_3,\Delta x_4,\Delta y_1,\Delta y_2,\Delta y_3,\Delta y_4,\Delta h_1,\Delta h_2)$，回归量是proposal与GT的偏移量。相比前人的8 corner表示法，参数量从24减少到10个。</p>
</li>
<li>Orientation Vector Regression：传统的表示法就是$\theta$。而作者使用$(x_\theta,y_\theta)=(cos(\theta),sin(\theta))$表示orientation。（但是orientation好像已经在“4 corner encoding”暗含了，为什么又要估计方向？？）</li>
<li>流程：<ul>
<li>element-wise mean operation进行“feature crops”的融合</li>
<li>经过FC层，输出“框框10维回归量”+“方向2维估计量”+“one-hot分类”</li>
<li>最后NMS</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Multi-View-3D-Object-Detection-Network-for-Autonomous-Driving"><a href="#Multi-View-3D-Object-Detection-Network-for-Autonomous-Driving" class="headerlink" title="Multi-View 3D Object Detection Network for Autonomous Driving"></a>Multi-View 3D Object Detection Network for Autonomous Driving</h2><blockquote>
<p>CVPR2017《Multi-View 3D Object Detection Network for Autonomous Driving》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Chen_Multi-View_3D_Object_CVPR_2017_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2017/html/Chen_Multi-View_3D_Object_CVPR_2017_paper.html</a></p>
</blockquote>
<h3 id="概括-6"><a href="#概括-6" class="headerlink" title="概括"></a>概括</h3><p>使用Multi-View的方式，对“雷达点云+RGB图”的输入，进行特征融合。达到了高精度。将点云转换成图像表达，并且需要将3D proposal投射到2D平面上，所以其实MV3D还是基于2D方法。</p>
<p>方法简述：将稀疏的点云转变成multi-view表示（作者是BEV+FrontView），于是MV3D的输入就是LIDAR BEV + LIDAR FV + RGB Image。然后分别提取特征得到三个feature map。然后在LIDAR BEV的feature map上进行propose得到3D proposals（也用了基于anchor的方法），投影到平面上得到ROI区域，使用ROI pooling得到固定大小的输入，然后用“deep fusion”方法融合特征，最后预测类别和框框的回归量。</p>
<p>其他：</p>
<ul>
<li><p>MV3D == Multi-View 3D object detection network</p>
</li>
<li><p>Laser scanners have the advantage of accurate depth information while cameras preserve much more detailed semantic information（所以LIDAR有助于确定框框的位置，RGB有助于确定物体类别）</p>
</li>
</ul>
<h3 id="实现-6"><a href="#实现-6" class="headerlink" title="实现"></a>实现</h3><p>网络分为两部分：3D Proposal Network（类似于RPN） 和 Region-based Fusion Network（其实类似于ORN）</p>
<p><img src="7_1.png" alt></p>
<ol>
<li>数据预处理步骤</li>
</ol>
<p>将LIDAR point cloud手工提取特征/手工编码得到LIDAR BEV和LIDAR FV</p>
<ul>
<li><p>提取点云在BEV视图上的高度特征、密度特征、强度特征，得到Bird’s eye view features，它是6通道的特征图。</p>
</li>
<li><p>提取点云在FV视图上的高度特征、距离特征、强度特征，得到Front view features（FV视图是雷达的横向扫角、雷达的纵向扫角组成的视图。xoy平面是BEV视图）</p>
<p><img src="7_2.png" alt></p>
<p>最终得到的MV3D的输入是：</p>
<p><img src="7_3.png" alt></p>
</li>
</ul>
<ol>
<li><p>3D Proposal Network</p>
<ul>
<li>使用LIDAR BEV进行框框的propose（优点：保留了框框的物理实际尺寸、避免遮挡、垂直高度方向差异不大）。</li>
</ul>
</li>
</ol>
<ul>
<li>仿照Faster R-CNN使用基于anchor的方法，3D anchor为$(x,y,z,l,w,h)$，2D anchor为$(x_{BEV},y_{BEV},l_{BEV},w_{BEV})$，3D anchor size（$(l,w,h)$）是聚类获得的，$z$可以根据摄像头高度和$h$计算（假设是物体是放在地面上的），所以实际上是2D anchor。<ul>
<li>然后使用类似于VGG16的网络来提取特征图。</li>
</ul>
</li>
<li>因为BEV视图分辨率不足，识别小物体有困难，所以作者使用bilinear upsampling（图中的deconv）进行上采样增加分辨率。<ul>
<li>然后3D Proposal Network的输出就是anchor与GT的偏移量、以及objectness score</li>
</ul>
</li>
<li>移除空框框，使用multi-task loss，使用NMS，取出top2000进行训练，top300进行推断</li>
</ul>
<ol>
<li><p>Region-based Fusion Network</p>
<ul>
<li><p>将3D proposal投影到BEV/FV/RGB平面上得到各自的2D proposal（图中的红蓝绿矩形）</p>
</li>
<li><p>然后根据ROI来crop，再使用ROI pooling，得到固定大小的feature map</p>
</li>
<li><p>再将3个feature map使用“deep fusion”方法来进行特征融合，如下图的（c）。即先算元素均值、再分别用3个FC layers并行处理，再将结果取均值，以此反复。</p>
<p><img src="7_4.png" alt></p>
</li>
<li><p>回归量是$t = (\Delta x_0,…,\Delta x_7,\Delta y_0,…,\Delta y_7,\Delta z_0,…,\Delta z_7)$，也就是使用8 corners的坐标来表征bounding box。于是orientation也能从corners中推断出来。输出是回归量$t$和物体类别。使用multi-task loss，使用NMS。</p>
<p>可能是由于“deep fusion”训练困难，我们使用 drop-path training 和 auxiliary losses 的方法来正则化训练，不详述。</p>
</li>
</ul>
</li>
</ol>
<h2 id="VoxelNet-End-to-End-Learning-for-Point-Cloud-Based-3D-Object-Detection-👍"><a href="#VoxelNet-End-to-End-Learning-for-Point-Cloud-Based-3D-Object-Detection-👍" class="headerlink" title="VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection 👍"></a>VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection 👍</h2><blockquote>
<p>CVPR2018《VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_VoxelNet_End-to-End_Learning_CVPR_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_VoxelNet_End-to-End_Learning_CVPR_2018_paper.html</a></p>
</blockquote>
<h3 id="概括-7"><a href="#概括-7" class="headerlink" title="概括"></a>概括</h3><p>对单纯雷达点云数据的object detection（所以只有几何信息）。将feature extraction和bounding box prediction的过程整合进一个single stage, end-to-end trainable deep network中，取名叫VoxelNet。关键是voxel feature encoding (VFE) layer的构建，能自动学习有效的有鉴别力的特征。最后通过RPN来输出detection box。达到了新的SOTA。</p>
<p>处理LIDAR点云的难点：点云稀疏、点云密度变化、点云数量比较多（约100k个点）</p>
<p>基本思想：将点云使用voxel栅格化、且在每个voxel内使用“pointnet”，使其转变为4D tensor。接下来使用卷积的方法就可以了。</p>
<h3 id="实现-7"><a href="#实现-7" class="headerlink" title="实现"></a>实现</h3><p>整体分为3部分：(1) Feature learning network, (2) Convolutional middle layers, and (3) Region proposal network</p>
<ol>
<li><p>Feature Learning Network</p>
<ul>
<li><p>Voxel Partition：将3D空间等间距分割成很多个voxels</p>
</li>
<li><p>Grouping：在同一个voxel内的点被一起进行后续操作（根据voxel的分割将点云划分分组）</p>
</li>
<li><p>Random Sampling：从点数多于$T$的voxel内采样出$T$个点，使得每个voxel内的点数都不超过$T$（有助于解决点云的密度不均，以及节省计算）</p>
</li>
<li><p>Stacked Voxel Feature Encoding：将VFE layers级联，提取每个voxel的特征</p>
<p><img src="8_1.png" alt></p>
<p>上图是一层VFE layer对一个voxel的操作。图中假设$T=3$（就是采样出蓝、绿、黄三个点）。点$i$的输入特征向量（Point-wise Input）为$(x_i,y_i,z_i,r_i,x_i-v_x,y_i-v_y,z_i-v_z)$，其中$(x_i,y_i,z_i)$是点的坐标、$(r_i)$是雷达接收到的反射强度，$(x_i-v_x,y_i-v_y,z_i-v_z)$是相对重心（重心即所有点的均值）的相对坐标。简言之，有点类似于pointnet中的segmentation的特征操作，好比是一个voxel就是一个pointnet，但是FC layers参数是共享的。</p>
<p><img src="8_2.png" alt></p>
<p>经过n个VFE layers之后就得到了上图中的Point-wise Feature-n，然后输入到FC再MP，就得到了描述该voxel的特征Voxel-wise Feature。</p>
</li>
<li><p>Sparse Tensor Representation：每个voxel都有个特征向量，所以点云可以用4D tensor表示（尺寸$C\times D’\times H’\times W’$，$C$是每个voxel的特征向量长度，$D’$是Z轴方向上的voxels的个数，$H’$是Y轴方向上的voxels个数，$W’$是X轴方向上的voxels个数，xoy平面就是BEV平面）。超过90%的voxel都是空的，后续操作时不必对其进行操作（似乎就是作者提到的Efficient Implementation）。</p>
</li>
</ul>
</li>
<li><p>Convolutional Middle Layers</p>
<p>使用3D卷积对4D tensor进行卷积，并进行reshape到3D tensor。</p>
<p>举例：输入尺寸（4D tensor）是$128\times 10\times 400\times 352$，输出尺寸（经过Convolutional Middle Layers之后）是$64\times 2 \times400 \times 352$，然后reshape到$128 \times 400\times352$变成3D tensor（注意到$400\times 352$正是BEV视图上的栅格尺寸）</p>
<p>目的：</p>
<ul>
<li>reshape的目的是方便后续的Region Proposal Network进行2D卷积</li>
<li>3D卷积的目的是聚合周围环境voxels的信息</li>
</ul>
</li>
<li><p>Region Proposal Network</p>
<p>进行2D卷积，最后输出(1) a probability score map and (2) a regression map</p>
<p>虽然是在类似于BEV的视图上进行卷积，但是输出的回归量却是3D的。</p>
<p>回归量是$(\Delta x,\Delta y,\Delta z,\Delta l,\Delta w,\Delta h,\Delta \theta)$。</p>
<p>使用多任务损失：分类的positive/negative损失、位置回归的positive损失。</p>
<p>如下图所示：</p>
<p><img src="8_3.png" alt></p>
</li>
<li><p>完整结构</p>
<p><img src="8_4.png" alt></p>
</li>
</ol>

            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">给小编加个鸡腿🍗呗</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>转载规则</span>
        </p>
        
            <div class="center-align">
                <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《3D目标检测》
                </span> 由
            <a xmlns:cc="http://creativecommons.org/ns#" href="/3d/3ddetection/" property="cc:attributionName"
               rel="cc:attributionURL">
                Karbo
            </a> 采用
            <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                知识共享署名 4.0 国际许可协议
            </a>进行许可。
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: 'WwrKLalwiFrnKlAcLCjpeyK7-gzGzoHsz',
        appKey: 'zF7jn8hejoyxVPESEeCAxCzY',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'ヾﾉ≧∀≦)o来评论啊，快活啊!'
    });
</script>
    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/english/englishgrammar/">
                    <div class="card-image">
                        
                        <img src="/english/englishgrammar/1.jpg" class="responsive-img" alt="英语语法基础">
                        
                        <span class="card-title">英语语法基础</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            简单介绍了英语的基本语法规则
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2019-10-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/english/" class="post-category" target="_blank">
                                    english
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/english/" target="_blank">
                        <span class="chip bg-color">english</span>
                    </a>
                    
                    <a href="/tags/grammar/" target="_blank">
                        <span class="chip bg-color">grammar</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/dl/precisionrecall/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="机器学习中常用的指标">
                        
                        <span class="card-title">机器学习中常用的指标</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            本文介绍了Precision、Recall、F1-score等一些常见的概念
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-09-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/dl/" class="post-category" target="_blank">
                                    dl
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/dl/" target="_blank">
                        <span class="chip bg-color">dl</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            本站由
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">hexo-theme-matery</a>主题搭建.

            
            &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
            <span class="white-color">80.3k</span>
            

            
            
            <br>
            
            <span id="busuanzi_container_site_pv">
                <i class="fa fa-heart-o"></i>
                本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                <i class="fa fa-users"></i>
                次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
            </span>
            
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
<a href="https://github.com/Karbo123" class="tooltipped" target="_blank" data-tooltip="我的GitHub" data-position="top"
    data-delay="50">
    <i class="fa fa-github"></i>
</a>



<a href="https://www.zhihu.com/people/karbo-50/activities" class="tooltipped" target="_blank" data-tooltip="我的知乎" data-position="top"
    data-delay="50">
    <i class="fa fa-user"></i>
</a>



<a href="mailto:lei@karbo.online" class="tooltipped" target="_blank" data-tooltip="邮件联系"
    data-position="top" data-delay="50">
    <i class="fa fa-envelope-open"></i>
</a>



<a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top"
    data-delay="50">
    <i class="fa fa-rss"></i>
</a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>

<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


</body>
</html>