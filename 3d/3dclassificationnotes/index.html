<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="3D点云特征提取笔记, 任我行">
    <meta name="description" content="3D点云特征提取笔记下面的papers都是有关3D点云特征提取的，将提取到的特征用于分类或分割任务。
经历了从深度学习+手工设计方法到几乎完全深度学习的转变。
本文完整的PDF版本你可以从这里下载。
PointNet 👍
CVPR2017">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>3D点云特征提取笔记 | 任我行</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">任我行</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">任我行</div>
        <div class="logo-desc">
            
            可以任我走怎么到头来又随着大队走，人群是那么像羊群
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Karbo123" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Karbo123" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>





<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/21.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        3D点云特征提取笔记
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/3d/" target="_blank">
                                <span class="chip bg-color">3d</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/3d/" class="post-category" target="_blank">
                                3d
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-08-31
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                        12.3k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        48 分
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="3D点云特征提取笔记"><a href="#3D点云特征提取笔记" class="headerlink" title="3D点云特征提取笔记"></a>3D点云特征提取笔记</h1><p>下面的papers都是有关3D点云特征提取的，将提取到的特征用于分类或分割任务。</p>
<p>经历了从<code>深度学习+手工设计</code>方法到<code>几乎完全深度学习</code>的转变。</p>
<p>本文完整的PDF版本你可以从<a href="3dClassificationNotes.pdf">这里</a>下载。</p>
<h2 id="PointNet-👍"><a href="#PointNet-👍" class="headerlink" title="PointNet 👍"></a>PointNet 👍</h2><blockquote>
<p>CVPR2017《PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation》</p>
<p>在线介绍：<a href="http://stanford.edu/~rqi/pointnet/" target="_blank" rel="noopener">http://stanford.edu/~rqi/pointnet/</a></p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Qi_PointNet_Deep_Learning_CVPR_2017_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2017/html/Qi_PointNet_Deep_Learning_CVPR_2017_paper.html</a></p>
<p>pytorch代码：<a href="https://github.com/fxia22/pointnet.pytorch" target="_blank" rel="noopener">https://github.com/fxia22/pointnet.pytorch</a></p>
</blockquote>
<h3 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h3><p>提出了一种“天然”适用于处理point cloud数据的Net。并且给出理论分析和较多实验。声称达到了state-of-the-art的效果：模型结构简单、精度高、计算复杂度低。</p>
<p>TODO IDEA：如果对称函数/max pooling换做了sort函数/top k函数（排序后返回前k大的值），那会怎么样？没有层次化特征提取的过程（PointNet++已解决）？</p>
<h3 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h3><p>最大的难点是如何处理point cloud数据的无序性，因为传统的操作都是有顺序依赖的（例如卷积，它是顺序相关的）。此外，点之间的空间相关性、变换（平移旋转等）的不变性也是难点所在。</p>
<p>传统的处理方法：将点云数据投影到二维平面然后使用图像的方法处理；将点云数据划分到有空间依赖关系的voxel；数据sort之后再输入；使用RNN尝试消除输入的顺序性。</p>
<h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><p>使用具有对称性质的函数（例如max函数），来实现处理点云的无序性。</p>
<p>形式化表述即：</p>
<script type="math/tex; mode=display">
   f(\{x_1,...,x_n\}) \approx g(h(x_1),...,h(x_n))</script><p>   意思是说，先进行非线性变换$h(\cdot)$，再使用对称函数$g(\cdot)$，就能近似出某一个能实现无序性的函数$f(\cdot)$。且$h(\cdot)$决定了$f(\cdot)$，所以关键是如何学习$h(\cdot)$。</p>
<p>   其中函数$h(\cdot)$使用多层感知机自动学习出来，$g(\cdot)$是某一个对称函数（例如max函数），$x_i$是第$i$个点。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>网络前端（实现变换不变性）</p>
<p>使用与输入数据相关的spatial transformer network（缩写stn），来生成一个仿射变换矩阵（它是方阵，例如一个object有2500个points且point的维度是3（x、y和z坐标构成3维）的点，那么丢进这个网络则会得到一个3x3大小的方阵）<br>然后将输入数据点施加这个仿射变换（乘以它），就得到预处理后的结果（虽然还是2500个维度是3的点）。可能可以认为这个仿射变换的作用是消除camera的摆放视角（看作是某一种变换）的影响？？</p>
<pre><code>input data size: [batchsize, 3, 2500]
after many conv1d: [batchsize, 1024, 2500]
after max function: [batchsize, 1024, 1]
after view: [batchsize, 1024]
after many fc layer: [batchsize, 9]
after reshape to matrix: [batchsize, 3, 3]
after add identity matrix: [batchsize, 3, 3] （加上3x3的单位矩阵，why？？可能类似于resnet的思想，或者是其他原因）
</code></pre><p>且我们在loss上加了正则约束项$||I-AA^T||^2_F$，使得学习到的矩阵$A$尽可能地是正交矩阵。</p>
</li>
<li><p>网络中端（消除输入的顺序性）</p>
<p>然后按照下图来操作：</p>
<p><img src="http://stanford.edu/~rqi/pointnet/images/pointnet.jpg" alt></p>
<p>两处用到了stn网络。stn生成仿射矩阵后对每个points都施加相同的仿射变换，不同sample的仿射矩阵不一样，都需要用stn网络计算出来。至于为什么后面也有个stn，那就只能姑且认为是stn网络起到类似于batchnorm的作用了。。。</p>
<p>其中max函数对每个feature_dim（共1024个）扫视一遍，然后取max（例如2500个points则取2500个数值中最大的，然后形成相应feature_dim上的值）</p>
<p>上图中蓝色部分是分类网络，黄色部分是分割网络。分割网络需要cancat global features和local features。（但实际上local features并没有充分地提取局部特征，例如密度表征等，所以后来才提出了其改进版PointNet++，但速度更慢）</p>
</li>
<li><p>网络后端（分类or分割）</p>
<ul>
<li><p>分类就是正常的Classificaion网络了</p>
</li>
<li><p>分割则是继续使用conv1d，然后view得到<code>[batchsize, 2500, classnum]</code>，再view作<code>[batchsize*2500, classnum]</code>然后使用softmax，最后再view回来<code>[batchsize, 2500, classnum]</code>就好了</p>
</li>
</ul>
</li>
</ol>
<h2 id="PointNet"><a href="#PointNet" class="headerlink" title="PointNet++"></a>PointNet++</h2><blockquote>
<p>NIPS2017《PointNet++: Deep Hierarchical Feature Learning onPoint Sets in a Metric Space》</p>
<p>在线介绍：<a href="http://stanford.edu/~rqi/pointnet2/" target="_blank" rel="noopener">http://stanford.edu/~rqi/pointnet2/</a></p>
<p>paper下载：<a href="http://papers.nips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space" target="_blank" rel="noopener">http://papers.nips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space</a></p>
</blockquote>
<h3 id="概括-1"><a href="#概括-1" class="headerlink" title="概括"></a>概括</h3><p>是PointNet的升级版。针对PointNet对local features提取能力弱的缺点（例如不能应对points density的variation），提出使用层级结构来提取local features。简言之，就是模仿了CNN的分层特征提取，它将全体Points划分为许多local regions（类比于CNN中Kernel大小的概念），然后使用原始版本的PointNet提取regions里点的特征，并利用centroid取代regions的点，实现点数的减少，再多次这样，最后就能提取包含local features的features了。</p>
<p>结果：特征表达更有效、鲁棒、精度高、但是计算代价高且慢（比PointNet慢几倍）</p>
<p>其他：作者还发现在Non-Euclidean Metric Space（为geodesic distances）中模型的表现也很好，可以抵抗object的形变（例如不同姿态的猫）。作者可视化了the first level kernels，<a href="http://stanford.edu/~rqi/pointnet2/images/features.jpg" target="_blank" rel="noopener">戳图</a>。</p>
<p>TODO IDEA：可能不同的度量空间对性能也有影响？感觉划定local regions的方式过于粗暴和生硬，有待改进？</p>
<h3 id="难点-1"><a href="#难点-1" class="headerlink" title="难点"></a>难点</h3><p>如何有效地提取local features以抵抗density variation？（density variation：即点云的密度变化，稀疏的点云和密集的点云对模型精度的影响比较大，模型应该能对这种变化鲁棒才行）</p>
<h3 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h3><p>模仿CNN的做法（分层级的特征提取）</p>
<h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>Hierarchical Point Set Feature Learning using <code>set abstraction levels</code></p>
<p>set abstraction levels由Sampling layer、Grouping layer和PointNet layer组成</p>
<ol>
<li><p>Sampling layer</p>
<p>作用：确定local regions的centroid位置</p>
<p>算法：farthest point sampling (FPS)最远点采样</p>
</li>
<li><p>Grouping layer</p>
<p>作用：确定centroid的neighborhood</p>
<p>算法（选其一）：</p>
<ul>
<li><p>ball query（推荐）：确定球面的半径，然后在半径以内的点都作为邻居</p>
</li>
<li><p>kNN（不推荐）：排序出最近的K个点作为邻居</p>
</li>
</ul>
</li>
<li><p>PointNet layer</p>
<p>  作用：特征提取</p>
<p>  算法过程：</p>
<ul>
<li><p>先将neighborhood的坐标转换为相对于centroid的相对坐标</p>
</li>
<li><p>再使用原始版本的PointNet作特征提取，提取到的特征作为centroid的特征。原本的neighborhood则不必再用，centroid作为下一个set abstraction levels的输入。</p>
</li>
</ul>
</li>
</ol>
</li>
<li><p>Robust Feature Learning under Non-Uniform Sampling Density</p>
<p>刚才所谓的set abstraction levels可能对density不鲁棒，我们需要融合多尺度（multi-scale，可以理解为neighborhood数量的多少，不一定是相同centroid的）的信息来达到鲁棒性。</p>
<p>不是多尺度的我们叫SSG（ablated PointNet++ with single scale grouping in each level），多尺度的我们叫MSG（multi-scale grouping）或MRG（multi-resolution grouping）。</p>
<p><img src="2_1.png" alt></p>
<p>我们提出了两种多尺度融合方式：MSG、MRG。</p>
<p>举个例子，MSG就是分别使用9999个、999个、99个neighborhood所提取到的features作concatenation所得到的features的方式；而MRG就是使用3个99neighborhood接着串联用1个99neighborhood再cancat（并联）直接使用999个neighborhood得到的特征。</p>
<p>效果上MSG慢但是精度高，MRG快但是精度不高。</p>
<p>注意：作者训练时使用了DropPoints（DP）技术（randomly dropping out input points with a randomized probability for each instance），但是model的density variation是否一部分得益于此（data的augmentation）不得而知。</p>
</li>
<li><p>训练流程</p>
</li>
</ol>
<p><img src="http://stanford.edu/~rqi/pointnet2/images/pnpp.jpg" alt></p>
<p>对于segmentation，还要对feature插值回原图的分辨率才能对每个点进行分类。</p>
<p>而classification则直接fc+softmax就好了。</p>
<h2 id="KCNet"><a href="#KCNet" class="headerlink" title="KCNet"></a>KCNet</h2><blockquote>
<p>CVPR2018《Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Mining_Point_Cloud_CVPR_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Mining_Point_Cloud_CVPR_2018_paper.html</a></p>
</blockquote>
<h3 id="概括-2"><a href="#概括-2" class="headerlink" title="概括"></a>概括</h3><ul>
<li><p>作者针对PointNet对local features提取能力弱的缺点（然而PointNet++速度慢），提出使用Kernel Correlation + Graph Pooling的方法来更有效地提取local features。</p>
</li>
<li><p>特点：Kernel的Shape可学习（并且可视化后有直观的几何意义）；不再使用handcrafted的features（如法向量、协方差矩阵）学习了</p>
</li>
<li><p>有益效果：在PointNet的基础上，能有效地提取local features</p>
</li>
<li><p>与PointNet++的比较：同样是局部化的特征提取，KCNet使用的是人为设计的度量函数，而PointNet++是自动提取特征（套用PointNet）；KCNet是对每一个点都提取了local feature，而PointNet++是只对FPS采样出来的点为centroid以及确定的邻域范围内使用PointNet来提取local feature。KCNet中有明显的模板/卷积核概念，而PointNet/PointNet++中没有明显的这一概念。</p>
</li>
<li><p>TODO IDEA：感觉point set的相似度衡量（correlation）过于依赖于选取，是否可能有自动学习这一过程，或者使这一过程更加自然？KCNet实现了Kernel，但是没有对应于stride的东西？是否可以多次地使用这种Kernel Layer而不是只用一次，类似于CNN的叠层使用一样？其中的高斯径向基的$\sigma$是否有自动学习的方法？</p>
</li>
</ul>
<h3 id="难点-2"><a href="#难点-2" class="headerlink" title="难点"></a>难点</h3><p>如何更加有效地提取local features？</p>
<p>PointNet++是将Point Cloud划分为多个分区，然后各个分区使用PointNet，以实现层次化的特征提取，那么KCNet又能怎么做呢？</p>
<p>PointNet的致命缺陷：PointNet只能感知点的是否存在，而不能编码/表征该点neighborhood的几何结构信息，造成局部描述能力弱。</p>
<h3 id="思想-2"><a href="#思想-2" class="headerlink" title="思想"></a>思想</h3><p>更加模仿CNN的做法（Learnable的PointSet模板匹配）</p>
<p>具体地说：</p>
<ul>
<li>我们有L个Kernel，每个Kernel有M个点，也就是说一个Kernel是一个point set，并且Kernel里点的位置都是learnable的，这就好比是我们有L个可变形的模板，或者说我们有L个可学习的“卷积核”。然后我们用数学方法人为地构造了一个叫KC(A,B)的度量函数用于度量point set A和point set B的相似程度，值越大越相似。然后这里的point set A就是Kernel，point set B就是我们model输入的point cloud里的其中一个点p的neighborhood的点集，也就是Kernel在整个point cloud上每一个点走过了一遍，因为有L个Kernel，所以一个点会得到一个L维的向量。以上就是Kernel Correlation的含义。</li>
<li>然后我们遍历每个点，基于该点的邻居的feature值，每个维度上取max，便是graph max pooling；将邻居的features作算术平均替换掉该点，便是graph average pooling。这就是graph pooling的含义。</li>
</ul>
<h3 id="额外的Knowledge"><a href="#额外的Knowledge" class="headerlink" title="额外的Knowledge"></a>额外的Knowledge</h3><ul>
<li>点云可能不止xyz坐标，或许还包括强度、法向量等信息，构成更高维的描述向量。点云只是描述Object surface的点，无Object内部的点。</li>
<li>处理点云的4种主流方法：<ul>
<li>volumetric-based：Volumetric-based approachpartitions the 3D space into regular voxels and apply 3D convolution on the voxels</li>
<li>patch-based：Patch-based approach parameterizes 3D surface into local patches and apply convolution over these patches</li>
<li>graph-based：Graph-based approach characterizes point clouds by graphs.</li>
<li>point-based：Pointbased approach such as PointNet directly operates on point clouds</li>
</ul>
</li>
</ul>
<h3 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h3><p><img src="3_2.png" alt></p>
<ol>
<li><p>kernel correlation layer（Learning on Local Geometric Structure）</p>
<p>所定义的度量函数为（我将论文的式子换了个形式好看些）：</p>
<script type="math/tex; mode=display">
KC(K,p) = \frac{1}{|N|}\sum_{p_K\in K} \sum_{p_N\in N}K_\sigma(p_K,p_N-p)</script><p>其中$K$代表Kernel（里面有$M$个点，其中的点用$p_K$表示）；$N$代表点$p$的邻居（不包含点$p$），邻居点记作$p_N$；$|N|$表示点$p$邻居的个数。</p>
<p>其中的$p_N-p$就是表示相对坐标，暗示Kernel应该是以原点为centroid的。</p>
<p>其中$K_\sigma$选用高斯径向基函数，那么最相似时这个$KC(K,p)$的值就是$M$（最大值），最小值就是$0$。</p>
</li>
<li><p>graph-based pooling layer（Learning on Local Feature Structure）</p>
<p>作者借助了一个数据结构，他起名叫“KNNG（K最近邻图）”，用来存储每一个点的邻居是谁，使用KNN算法得出邻居成员。</p>
<p>图结构的Pooling起到了feature aggregation的作用，据作者声称加强了特征的鲁棒性。</p>
<ul>
<li><p>Graph max pooling就是neighborhood特征的最大值（各个通道上）</p>
</li>
<li><p>Graph average pooling的直观解释：就是neighborhood特征的算术均值。原文中描述比较复杂，直观地说就是这样：</p>
<p><img src="3_1.png" alt></p>
<p>值得注意的是，pooling只是以邻居的特征计算后赋给自己。不知道为什么不算上自己的特征？？</p>
</li>
</ul>
</li>
</ol>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>速度快（只比PointNet稍慢），精度还算高（虽然不是最高的）</p>
<p>鲁棒性（随机替换point为噪点）：graph max pooling比graph average pooling更鲁棒；单纯使用graph max pooling比结合着使用graph max pooling + kernel correlation鲁棒性能更好，只使用kernel correlation鲁棒性能最差。</p>
<p>注意：作者训练时没有用data augmentation的方法</p>
<h2 id="SO-Net"><a href="#SO-Net" class="headerlink" title="SO-Net"></a>SO-Net</h2><blockquote>
<p>CVPR2018《SO-Net: Self-Organizing Network for Point Cloud Analysis》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Li_SO-Net_Self-Organizing_Network_CVPR_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/html/Li_SO-Net_Self-Organizing_Network_CVPR_2018_paper.html</a></p>
</blockquote>
<h3 id="概括-3"><a href="#概括-3" class="headerlink" title="概括"></a>概括</h3><ul>
<li>针对一些网络在处理point cloud时的缺点，如：不能对点的空间分布进行建模（例如PointNet++，只是能获取局部信息不能得到局部区域之间的空间关系），提出了SO-Net。SO的含义是利用Self-organizing map的Net。</li>
<li>结果：它具有能够对点的空间分布进行建模、层次化特征提取、可调节的感受野范围的优点，并能够用于多种任务如重建、分类、分割等等。取得了相似或超过SOTA的性能，因为可并行化和架构简单使得训练速度很快。</li>
<li>贡献：<ul>
<li>We design a permutation invariant network - the SO-Net that explicitly utilizes the <strong>spatial distribution of point clouds</strong>.</li>
<li>With point-to-node kNN search on SOM, hierarchical feature extraction is performed with systematically <strong>adjustable receptive field overlap</strong>（可调节的、感受野之间有交叠）.</li>
<li>We propose a <strong>point cloud autoencoder as pre-training</strong> to improve network performance in various tasks.</li>
<li>Compared with state-of-the-art approaches, similar or better performance is achieved in various applications with <strong>significantly faster training speed</strong>.</li>
</ul>
</li>
<li>TODO IDEA：作者发现将CNN直接用于SOM图上性能不升反降，为什么（推测：可能是SOM的2D map并不是保持了原本的空间对应关系，可能nodes之间是乱序的，导致用conv2d时精度反而降低）？</li>
</ul>
<h3 id="难点-3"><a href="#难点-3" class="headerlink" title="难点"></a>难点</h3><p>如何对local regions之间的空间关系进行建模？举个例子，即怎么显式地知道region A在region B的左边？</p>
<h3 id="额外的Knowledge-1"><a href="#额外的Knowledge-1" class="headerlink" title="额外的Knowledge"></a>额外的Knowledge</h3><ol>
<li><p>该文Related Work里对点云处理的“综述”比较详尽，怒赞！！！</p>
</li>
<li><p>网上找的SOM简介：<a href="https://www.cnblogs.com/surfzjy/p/7944454.html" target="_blank" rel="noopener">【机器学习笔记】自组织映射网络（SOM）</a></p>
</li>
</ol>
<h3 id="思想-3"><a href="#思想-3" class="headerlink" title="思想"></a>思想</h3><ul>
<li>点云的空间分布编码：使用SOM中nodes自带的拓扑结构实现</li>
<li>交叠感受野且可调：使用“point-to-node kNN search”，使得感受野大概率交叠，并且感受野大小受超参数控制。</li>
<li>无序化：使用作者提出改进的SOM即“Permutation Invariant SOM”，使得SOM的result对输入数据的顺序弱化至无。</li>
</ul>
<h3 id="做法"><a href="#做法" class="headerlink" title="做法"></a>做法</h3><ol>
<li><p>Permutation Invariant SOM</p>
<p>使用2维的SOM。注意2维的SOM并不是指nodes的features的dimension是2，而是指nodes的拓扑排列是2维正方形地排列。实质上nodes的features的dimension可以是任意维度，当是三维时就好比是学习point cloud的“聚类中心”。</p>
<p>传统SOM不能真正实现对输入数据的顺序不依赖性，需要作出修改：</p>
<ul>
<li>Assign fixed initial nodes for any given SOM configuration</li>
<li>Perform one update after accumulating the effects of all the points.（batch update）</li>
</ul>
</li>
<li><p>Encoder Architecture</p>
<p>记号：</p>
<ul>
<li><p>point cloud（其元素简称point） $P=\{p_i\in \mathbb{R}^3,i=0,…,N-1\}$</p>
</li>
<li><p>SOM nodes（其元素简称node） $S=\{s_j\in \mathbb{R}^3,j=0,…,M-1\}$</p>
</li>
</ul>
<ol>
<li><p>point-to-node kNN search</p>
<p>在$S$中寻找$p_i$的k个最近邻：$p_i$的第$k$个邻居记作$s_{ik}$</p>
</li>
<li><p>normalization</p>
<p>将$P$中的点都进行normalization：$p_{ik}=p_i-s_{ik}$</p>
<p>那么每个点$p_i$都有k个被归一化后的版本。一共有N*k个这样被normalization后的点。</p>
</li>
<li><p>shared FC layer（作用：施加非线性，提取point features）</p>
<p>将$p_{ik}$输入一层FC，得到$p_{ik}^1$；若输入$l$层FC层则得到$p_{ik}^l$</p>
<p>shared的意思大概是对于N*k个这样的$p_{ik}$输入的都是同一个FC网络。</p>
<p>构造N*k个$p_{ik}$的用途：</p>
<ul>
<li>提取point features：每一个point都有3个feature vectors</li>
<li>形成感受野：每一个node大致有$int(\frac{k N}{M})$个feature vectors。利用这一性质，我们在后面用max pooling操作提取node features。</li>
</ul>
</li>
<li><p>channel-wise max pooling operation（作用：从point features中提取SOM node features）</p>
<p>注意这里是从MLP尾巴$p_{ik}^l$提取的max pooling。</p>
<p>这里$max()$函数的里面的元素的个数就是感受野的大小，可知感受野大小不是确定的，容易知道感受野大小的期望就是$\frac{k N}{M}$，所以说感受野是可调的，并且存在overlap。</p>
<script type="math/tex; mode=display">
s_j^0 = \max(\{ p_{ik}^l ,\forall s_{ik}=s_j \})</script><p>原本$s_j$是3维向量，现在max pooling后额外得到了维度未知的向量$s_j^0$（维度取决于MLP最后一层的输出维度）。</p>
<p>node concatenation：然后可以将两者concat起来得到$[s_j,\;s_j^0]$，feature的维度更长了，融合了不同层次的信息。</p>
<p>注意到“shared FC layer + channel-wise max pooling operation”好比就是一个small PointNet，对“mini point cloud”进行编码。</p>
</li>
</ol>
</li>
</ol>
<p><img src="4_1.png" alt></p>
<p>网络结构如上。</p>
<p>总地来说就是，先计算SOM得到$s_j$，然后计算$p_{ik}$，接着将$p_{ik}$输入MLP得到变换后的$p_{ik}^l$，接着对$p_{ik}^l$作max pooling得到$s_j^0$，与原本的cancat使得node features“变长”（在图中表示就是那个网格拥有depth了），接着对SOM nodes作MLP再max pooling得到global feature。</p>
<p>segmentation与classification略去不说。</p>
<ol>
<li><p>Autoencoder</p>
<p>In this section, we design a decoder network to recover the input point cloud from the encoded global feature vector.</p>
<p><img src="4_2.png" alt></p>
</li>
<li><p>Experiments结果分析</p>
<p>略</p>
</li>
</ol>
<h2 id="Using-Local-Spectral-Graph-Convolution"><a href="#Using-Local-Spectral-Graph-Convolution" class="headerlink" title="Using Local Spectral Graph Convolution"></a>Using Local Spectral Graph Convolution</h2><blockquote>
<p>ECCV2018《Local Spectral Graph Convolution for Point Set Feature Learning》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_ECCV_2018/html/Chu_Wang_Local_Spectral_Graph_ECCV_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/html/Chu_Wang_Local_Spectral_Graph_ECCV_2018_paper.html</a></p>
</blockquote>
<h3 id="概括-4"><a href="#概括-4" class="headerlink" title="概括"></a>概括</h3><p>在局部图的区域上使用“图卷积”提取local features（将局部点图的图卷积转换到频域上进行操作），提出了fancy的池化操作（多次使用clustering+pooling进行的池化操作）。</p>
<h3 id="思想-4"><a href="#思想-4" class="headerlink" title="思想"></a>思想</h3><p>利用图卷积的方式取代PointNet进行local regions的features extraction。</p>
<p>提出使用先划分子区域（clustering）再pooling的池化方法，感觉像是分组卷积的思想？</p>
<h3 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h3><p><img src="5_1.png" alt></p>
<ol>
<li><p>使用FPS计算出centroids，kNN计算出local regions。</p>
</li>
<li><p>接着使用频域的图卷积，以及多次使用clustering+pooling进行池化。</p>
<p><img src="5_2.png" alt></p>
<p>频域图卷积过程如上图所示。</p>
<p>局部点图一共有k个点。其中：</p>
<p>$X$是输入特征矩阵（一共有k行，每一行是该点的特征向量，特征向量维度为m）</p>
<p>$G$是spectral modulation matrix，$W$是weights of the feature filter（好像是图的邻接矩阵？）</p>
<p>图的傅里叶变换：首先计算拉普拉斯矩阵$L=I-D^{-1/2}WD^{-1/2}$，然后对$L$作特征值分解得到特征向量矩阵$U$，那么正傅里叶变换就是$\tilde{X}=U^TX$，反傅里叶变换就是$X=U\tilde{X}$</p>
<p>池化：We partition the Fiedler vector to perform spectral clustering in a local k-NN. We alternate between max pooling and average pooling between different recurrences.</p>
</li>
<li><p>多次重复步骤2，最终获取特征用于分类/分割。</p>
</li>
</ol>
<h2 id="PointCNN"><a href="#PointCNN" class="headerlink" title="PointCNN"></a>PointCNN</h2><blockquote>
<p>NIPS2018《PointCNN: Convolution On X-Transformed Points》</p>
<p>paper下载：<a href="http://papers.nips.cc/paper/7362-pointcnn-convolution-on-x-transformed-points" target="_blank" rel="noopener">http://papers.nips.cc/paper/7362-pointcnn-convolution-on-x-transformed-points</a></p>
</blockquote>
<h3 id="概括-5"><a href="#概括-5" class="headerlink" title="概括"></a>概括</h3><p>作者声称提出了一种“generalization of typical CNNs to feature learning from point clouds”，因而称作“PointCNN”（我个人觉得人造痕迹比较多），并且接近/达到了SOTA的性能。</p>
<p>主要流程是：用kNN划分regions，然后对neighborhood的feature matrix进行transform，接着与kernel matrix进行conv；多层这样的“conv层”堆叠，最后得到特征输出。</p>
<p>但是需要注意的是：作者发现矩阵$X$并没有达到“permutation equivalence”的效果；而且作者训练时使用了augmentation的方法，包括shuffle输入数据点的顺序。</p>
<p>这里的“卷积”是真正传统意义上的卷积（元素间按位相乘再相加）；不同于KCNet提出的3D Kernel大法，不同于图结构的谱图卷积等等。</p>
<h3 id="思想-5"><a href="#思想-5" class="headerlink" title="思想"></a>思想</h3><p>想直接弄个conv类似的linear conv kernel，发现conv对输入数据的order sensitivity。于是想办法“纠正”输入数据的order，本想用“Permutation matrix”乘以它就好了，可能是ideal的Permutation matrix很难弄到，所以提出弄了个矩阵$X$，美言称能实现“simultaneously weight and permute the input features”，然后实在不知道怎么弄了，就让矩阵$X$自己从输入点集的坐标里学习吧（使用MLP），然后甚至还将点集坐标nonlinear transform后cancat进原本的features。最后施加矩阵$X$，最后卷积。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>传统卷积（暂不考虑kernel的滑动，只考虑在一个location上）可以表示为（这里的conv实际上是matrices间element-wise的product，最后sum）：</p>
<script type="math/tex; mode=display">
f = conv(K,[f_a,f_b,f_c,f_d]^T)</script><p>其中$K$表示卷积核，$f_a$等表示像素的特征向量（横向量，$f_a\in \mathbb{R}^{C_1}$）。上式表示2*2的kernel在一个location上的computation。</p>
<p>推广开来，在点云上，假设有4个points，然后做“卷积”，式子跟上面是一样的。但是对点云的输入顺序敏感，即$[f_a,f_b,f_c,f_d]^T$与$[f_b,f_a,f_c,f_d]^T$的结果会不一样，所以我们需要对它进行transform再输进去。我们这里选择用一个矩阵$X$与它相乘（矩阵有“置换矩阵”可以实现对输入顺序的矫正，推广到一般矩阵则相当于“置换+加权”的效果）。即：</p>
<script type="math/tex; mode=display">
f = conv(K,X \times [f_a,f_b,f_c,f_d]^T)</script><p>这个矩阵$X$是由输入数据通过MLP生成的。</p>
<p>在PointCNN中，一次computation（只在一个location上，不“滑动”）的过程就是：</p>
<script type="math/tex; mode=display">
F_p = conv(K,MLP(P-p) \times [MLP_\delta(P-p),F])</script><p>其中$K$是kernel matrix，$P$是输入点集的空间坐标（在region中，如果kernel覆盖了4个点，那么$P$的元素个数就是4），$p$是输出点的空间坐标（类似于该region的centroid，只有一个，$p\in P$），$F$是输入点集的feature matrix（与$P$的元素个数相同），$MLP()$和$MLP_\delta()$是多层感知机函数。</p>
<p>handcrafted的流程解释：</p>
<ul>
<li><p>转化到相对坐标系中$P-p$</p>
</li>
<li><p>矩阵$X$通过输入点集的空间坐标学习得来：$X=MLP(P-p)$</p>
</li>
<li>将输入点集维度升高，并与点集的特征向量进行cancat，作为最终的特征向量：$[MLP_\delta(P-p),F]$</li>
<li>进行“置换+加权”：$MLP(P-p) \times [MLP_\delta(P-p),F]$</li>
<li>最后进行常规的卷积操作得到$f$</li>
</ul>
<h3 id="实现-4"><a href="#实现-4" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>Hierarchical Convolution</p>
<p><img src="6_1.png" alt></p>
<p>模拟CNN，作者对图结构进行information的aggregation。</p>
</li>
<li><p>X-Conv Operator</p>
<p>作者的卷积结构称作“X-Conv”。我觉得直接从点云坐标学习得到矩阵$X$似乎是个很难的任务，感觉$X$矩阵并没有达到预期目的。</p>
<script type="math/tex; mode=display">
F_p = conv(K,MLP(P-p) \times [MLP_\delta(P-p),F])</script></li>
<li><p>PointCNN Architectures</p>
<p><img src="6_2.png" alt></p>
<p>通过多层的堆叠实现特征提取。</p>
</li>
</ol>
<h2 id="A-CNN"><a href="#A-CNN" class="headerlink" title="A-CNN"></a>A-CNN</h2><blockquote>
<p>CVPR2019《A-CNN: Annularly Convolutional Neural Networks on Point Clouds》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Komarichev_A-CNN_Annularly_Convolutional_Neural_Networks_on_Point_Clouds_CVPR_2019_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_CVPR_2019/html/Komarichev_A-CNN_Annularly_Convolutional_Neural_Networks_on_Point_Clouds_CVPR_2019_paper.html</a></p>
</blockquote>
<h3 id="概括-6"><a href="#概括-6" class="headerlink" title="概括"></a>概括</h3><p>使用循环卷积作为点云的特征提取方式：对点集投射到2D平面上进行圆周排序再输入到循环卷积中提取特征，输出的点的数量是上一级的centroids数量，多级嵌套实现“层次化”特征提取。</p>
<p>效果：提取局部几何结构特征（感觉是很明显的人工设计流程），adapt to the geometric variability and scalability at the signal processing level（文中没论述，不知道怎么看出来的），超过了SOTA（其实只是部分指标超过了SOTA）</p>
<p>BTW，文章Related Work部分的综述部分写的不错</p>
<p>TODO IDEA：为什么基本都需要kNN，可以不用吗？是否可以以平面极坐标的形式对投影p_j进行了排序后进行输入，而不需要划分ring再cos angle sort？？或者多个rings的特征组成更高维的tensor再滑动卷积？</p>
<h3 id="思想-6"><a href="#思想-6" class="headerlink" title="思想"></a>思想</h3><p>其实Annular Convolution的整个目的是为了实现neighborhood的<strong>无序化</strong>。在同一个ring上的确实现了无序化（从3D space project到2D plane，然后用angle的方式一一映射到1D line，最后使用1D circular convolution即可实现邻域特征的融合；同时ring的半径对应了感受野）</p>
<p>模仿PCA将points变动最大的方向保留（向切平面投影），感知centroid在距离远近上的特征（例如城市的内环特征、中环特征、外环特征分别是繁荣、住宅区、郊区这样子；再将这些“环”特征concat起来，作为这座城市的特征），而在“环”区域里面的顺序则是通过余弦角排序后输入循环卷积里面实现的（思路不错！）</p>
<p>主要创新点：将邻居点投射到2D平面上，然后对2D平面划分出多个不重叠的区域（它是同心圆环区域），然后指定一个标准点，与其计算余弦夹角后排序，从而得到点的圆周顺序排列，输入到循环卷积中提取特征；不同同心圆环的特征concat起来，再在所有邻居点之间作max pooling。</p>
<h3 id="实现-5"><a href="#实现-5" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>Regular and Dilated Rings on Point Clouds And Constraint based KNN Search</p>
<p><img src="7_1.png" alt></p>
<p>将平面空间划分为不重叠的区域，不重叠会减少计算量和避免特征冗余。如果是普通的ball query则大的感受野必然会包含小的感受野。作者使用环形的方式，甚至模拟空洞卷积使用带间隔空环的方式划分平面区域（增大了感受野）。最上面的圆形平面代表平面区域划分，中间和最下面的平面代表将最上面的解体开给你看的，说明没有作者提出的划分方式（Rings）没有重叠。</p>
<p>Constraint based KNN Search：只是将区域受限，进行的KNN算法。例如原本是$r&lt;R$范围内的，现在可能是$R_1&lt;r&lt;R_2$范围内的。</p>
<p>centroid使用FPS最远点采样算法获得，邻居使用Constraint based KNN Search获得。</p>
<p>做完这一步我们就可以得到多个centroid和其对应的neighborhood了（区域划分完成）。</p>
</li>
<li><p>Ordering Neighbors</p>
<ol>
<li><p>Normal Estimation on Point Clouds</p>
<p>首先估计centroid的法向量：首先沿着法向量，邻居的位置变化肯定是最小的。所以法向量就是邻居点的相对坐标的协方差矩阵最小的特征值所对的特征向量的方向。</p>
<p>似乎法向的方向颠倒之后得到的排序后的点的顺序也会相反，但好像只要使得法向始终与某一方向的夹角小于90°就好了？？？</p>
<p>有了法向量就可以估计切平面。</p>
</li>
<li><p>Orthogonal Projection</p>
<p>将邻居点向切平面投影，得到位于切平面上的投影点$p_j,k\in\{1,…,K\}$。</p>
</li>
<li><p>Counterclockwise Ordering</p>
<p>随便指定一个投影点作为参考点，例如就选$p_1$吧。记centroid为$q$。</p>
<p>那么以此计算$p_j-q$与$p_1-q$夹角的“余弦值”（借助叉积可以辨别是位于圆的上半部分还是下半部分，从而可以拓展到0~360°的识别范围，所以“余弦值”被我们拓展到$(-3,1]$的区间上了），将“余弦值”降序排列，那么就能对邻居点实现逆时针的排序了</p>
</li>
</ol>
</li>
<li><p>Annular Convolution on Rings And Pooling on Rings</p>
<p><img src="7_2.png" alt></p>
<p>将排序后的邻居点$[x_1,x_2,…,x_K]$输入到循环卷积里进行特征提取。</p>
<p>如果卷积核的大小是3，那么循环卷积相当于对$[x_1,x_2,…,x_K,x_1,x_2]$进行卷积核为3的普通卷积。</p>
<p>因为采用了循环卷积，所以参考点（$p_1$）到底是谁就不重要了。</p>
<p>将不同rings的特征concat，然后在所有邻居点之间做maxpooling。然后再把得到的东西再次送入类似的结构作“层次化提取”。</p>
</li>
<li><p>A-CNN Architecture</p>
<p>整体结构如下：</p>
<p><img src="7_3.png" alt></p>
<p>它的Segmentation Network上采样插值部分与之前某个网络有点类似（The interpolation method is based on the inverse squared Euclidean distance weighted average of the three nearest neighbors），不再详述。</p>
</li>
</ol>
<h2 id="PointConv-👍"><a href="#PointConv-👍" class="headerlink" title="PointConv 👍"></a>PointConv 👍</h2><blockquote>
<p>CVPR2019《PointConv: Deep Convolutional Networks on 3D Point Clouds》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_PointConv_Deep_Convolutional_Networks_on_3D_Point_Clouds_CVPR_2019_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_PointConv_Deep_Convolutional_Networks_on_3D_Point_Clouds_CVPR_2019_paper.html</a></p>
</blockquote>
<h3 id="概括-7"><a href="#概括-7" class="headerlink" title="概括"></a>概括</h3><p>这篇文章将卷积比较自然地拓展到点云的情形，思路很赞！</p>
<p>文章的主要创新点：“weight function”和“density function”，并能实现translation-invariance和permutation-invariance，可以实现层级化特征提取，而且能自然推广到其deconvolution的情形实现分割，在二维CIFAR-10图像分类任务中精度堪比CNN（表明能够充分近似卷积网络），达到了SOTA的性能。</p>
<p>缺点：每个kernel都需要由“kernel function”生成，而“kernel function”实质上是一个CNN网络，计算量比较大。</p>
<h3 id="思想-7"><a href="#思想-7" class="headerlink" title="思想"></a>思想</h3><p>察觉到：二维卷积中pixel的相对centroid位置与kernel vector的生成方式有关。</p>
<p>以二维卷积为例说明一下如何将卷积拓展到点云。这里只考虑使用一个kernel在一个location的一次卷积操作。</p>
<p>对于二维图像，我们可以将图像的pixels看作是一个点，那么图像就是整齐排列的点阵。每个point都有维度为$C_{in}$的特征向量（相当于图片是多通道的，一个通道对应于特征向量里的一个位置）。在二维卷积中，我们的kernel是“滑动”的，即我们在多个location的计算中共用一个kernel参数。这是为什么呢？我们如果认为这种共享参数的形式得益于整齐排列的points，那么这就是我们的PointConv的出发点了。</p>
<p><img src="8_1.png" alt></p>
<p>现在我们考虑一个point位置上的kernel是什么，在传统2D卷积中，这个值就是一个vector（$C_{in}$尺寸），如果points是正方形（2*2）整齐排列，那么我们可以认为kernel是$2\times2\times C_{in}$的尺寸。但是我们现在不这么认为，我们认为kernel的尺寸是$K\times C_{in}$（其中$K$是输入点的个数，这里是4），这样有助于推广到点云的情形。</p>
<p>在2D图像中，我们不妨可以认为kernel是这样生成的：kernel在一个point上的值（vector），取决于point的位置。那么在2D图像中，这个生成vector的分布，则是4点的狄拉克分布，即在空间坐标中只在这4个位置下，才有对应的向量值。</p>
<p>我们推广开来，假设这个分布是实数值的连续分布，不妨叫它做“weight function”，那么在3D点云中，这个“weight function”的输入是3D坐标系x、y和z，它的输出则是一个vector（尺寸$C_{in}$）。（在2D图像中，则$[f(0,0),f(1,0);f(0,1),f(1,1)]$组成了我们三维的kernel，尺寸$2\times2\times C_{in}$）。如果点的坐标是实数值（3D点云中其实就是实数值），那么我们点云的kernel尺寸就是$4\times C_{in}$，即我们每个point都有一个vector kernel与它对应。我们的计算过程就是：每个point的的feature与kernel vector做点积，最后把所有邻居点的点积的结果求和，得到的scalar就是我们一次卷积计算后的结果。</p>
<p>如果每个point的位置上是一个矩阵，那么相当于有多个kernel，最后得到的卷积结果不是scalar而是一个vector（有点像2D卷积中有多个卷积核的情形，输出就形成了多个channels）。</p>
<h3 id="实现-6"><a href="#实现-6" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>PointConv</p>
<p>在邻居点中实现卷积：</p>
<script type="math/tex; mode=display">
F_{out} = \sum_{k=1}^K \sum_{c_{in}=1}^{C_{in}} S(k)W(k,c_{in})F_{in}(k,c_{in})</script><p>其中$W\in\mathbb{R}^{K\times(C_{in}\times C_{out})}$是$C_{out}$个kernel，$F_{in} \in \mathbb{R}^{K\times C_{in}}$是邻居的特征矩阵（一行一个），$S$是点密度的修正项（density scale），$F_{out}$是卷积后输出的vector。其中的kernel由“kernel function”生成，而“kernel function”接收x、y和z坐标输入，然后通过2D卷积（用1x1卷积核），得到一个尺寸为$K\times C_{in}\times C_{out}$的tensor，就是$W$。输出的$F_{out}$的空间坐标就是centroid的坐标。</p>
<p><img src="8_2.png" alt></p>
<p>关于密度：作者首先使用“kernel density estimation”算法估计每一个点的密度，然后将得到的密度（一个点的密度是一个实数值，有$K$个点所以是一个1d vector）丢进MLP里非线性变换（丢进MLP里是为了让网络自己决定是否采用密度估计），估计密度是为了解决点云的非均匀采样导致的非均匀密度的问题。</p>
<p>作者发现原始版本的PointConv实现内存占用太大，提出了改进版本，在此不详述。</p>
<p>PointDeconv其实就是邻域3点线性插值上采样，与前面同级的特征concat，再使用PointConv。</p>
<p><img src="8_3.png" alt></p>
<p>上图是用于segmentation的pointconv网络。特征提取的过程好像也是先用FPS采样再grouping的。</p>
</li>
</ol>
<h2 id="KPConv👍"><a href="#KPConv👍" class="headerlink" title="KPConv👍"></a>KPConv👍</h2><blockquote>
<p>ICCV2019《KPConv: Flexible and Deformable Convolution for Point Clouds》</p>
<p>paper下载：<a href="https://arxiv.org/abs/1904.08889v2" target="_blank" rel="noopener">https://arxiv.org/abs/1904.08889v2</a></p>
</blockquote>
<h3 id="概括-8"><a href="#概括-8" class="headerlink" title="概括"></a>概括</h3><p>与“PointConv”和“KCNet”稍微有点类似，它也是将卷积自然推广到3D point cloud中，但是区别是生成kernel transform matrix的方式不一样，而且它的point kernel并不是用于直接度量点云之间的相似度而是用于建立分布来计算kernel transform matrix的值。简单地说是通过线性插值来得到矩阵的，而系数与点之间的距离相关。</p>
<p>效果：达到SOTA，可分类又可分割</p>
<p>注：</p>
<ul>
<li><p>KPConv == Kernel Point Convolution</p>
</li>
<li><p>我这里的kernel transform matrix指的是给定一个邻域内的点$y_i$（相对坐标），通过某一种方法得到该点相关联的特征向量$f_i$的转换矩阵$W$，其$W$就是kernel transform matrix。在一个位置上的卷积计算过程就是$output = \sum_i W_i y_i$，即：</p>
<script type="math/tex; mode=display">
(\mathcal{F}*\mathcal{g})(x) = \sum_{x_i\in\mathcal{N}_x} g(x_i-x)f_i</script></li>
</ul>
<p>TODO IDEA：还有没有其他方法来生成这个分布？找邻居的方法是否可以更加自然一点，使得嵌入神经网络的架构中？</p>
<h3 id="思想-8"><a href="#思想-8" class="headerlink" title="思想"></a>思想</h3><p>与“PointConv”类似，区别是它生成kernel transform matrix的方式不一样。在前篇”PointConv”中，生成方式是使用CNN合成，输入xyz坐标自动生成一个矩阵。在这篇“KPConv”则是利用类似于插值或者说平滑的方法来计算kernel transform matrix。</p>
<p>那么这个“插值”的算法是怎么计算的呢？这套算法需要我们首先定义一个小点云，小点云里面有$K$个点（$K$是任意的，可以不等于邻域内的邻居数，$K$越大则描述的分布越精细），而小点云里的每个点$d_k$都有个矩阵$W_k$与之关联。现在我们考虑输入点云的centroid的邻域内的一个邻居点$x$，那么计算得到的矩阵则是在小点云周围点的矩阵$W_k$的线性表示：</p>
<script type="math/tex; mode=display">
transform\;matrix = \sum h(d_k,x)W_k</script><p>其中的：</p>
<script type="math/tex; mode=display">
h(d_k,x) = max(0,1-\frac{||d_k-x||}{\sigma})</script><p><img src="9_1.png" alt></p>
<p>意思是这个分布实质上只是由$K$个“狄拉克分布”支撑起来的，只有在这$K$个地方才有真正的值。想要获取其他地方的值就只能通过线性插值得到。线性插值的“原子”则是与之离得比较近的点所对应的矩阵$W_k$，离得太远则会由于ReLU函数的截断性质而不再作出贡献。</p>
<p><img src="9_4.png" alt></p>
<p>上图是假设kernel points只有5个，黑色星星的位置是kernel points的位置，假设weight matrix只是一个scalar，使用KPConv的插值算法得到的分布图。画图的代码见<a href="9_code_to_plot_distribution.py">这里</a>。可以看出这个算法的效果就是：相当于允许邻居点neighbor point的位置有稍微的变动，其理想的等值面是一个球形，在波动允许的范围内则使用一个接近的transform matrix值，而没有受到影响的地方则默认是零。这样带来的好处可能是使得分布平滑（猜的），使用CNN生成的方式应该不能保证分布平滑（瞎猜的）。</p>
<h3 id="实现-7"><a href="#实现-7" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>Rigid or Deformable Kernel</p>
<p>在“思想”中介绍的就是Rigid Kernel，意思是kernel point的位置一开始就是固定好的，是不可改变、不可学习的参数，改变的只能是其小点云上的矩阵$W_k$。Rigid Kernel的初始化方式形象地说就是假想每个kernel point都是带正电的小球相互排斥，但是同时要使得小球被束缚在一个半径尽可能小的包围球里面，包围住全部的带点小球，那么最终稳态时的小球位置就是kernel point的坐标位置。</p>
<p>Deformable Kernel并不是指kernel point的位置可变，然后最后共用同一个分布，因为这样没什么意义，还不如选用好的初始化方法。</p>
<p>而Deformable Kernel则参照了二维图像中的deformable convolution的实现方法，就是在Rigid Kernel的基础上学习一个kernel point shift的量，在固定的基础上进行变动，从而实现这$K$个“狄拉克分布”的位置都是可变的。</p>
<p><img src="9_2.png" alt></p>
<p>在使用Deformable Kernel的时候，需要在损失函数上加上正则项，用来约束kernel point和neighbor point不能离太远、kernel points之间不能太近，否则效果奇差。</p>
</li>
<li><p>网络结构</p>
<p><img src="9_3.png" alt></p>
<p>用grid subsampling下采样，用max-pooling或KPConv来做pooling</p>
<p>用radius neighborhoods而不是k-nearest-neighbors</p>
</li>
</ol>
<h2 id="DGCNN-using-EdgeConv👍"><a href="#DGCNN-using-EdgeConv👍" class="headerlink" title="DGCNN using EdgeConv👍"></a>DGCNN using EdgeConv👍</h2><blockquote>
<p>TOG2019？《Dynamic Graph CNN for Learning on Point Clouds》</p>
<p>paper下载：<a href="https://arxiv.org/abs/1801.07829" target="_blank" rel="noopener">https://arxiv.org/abs/1801.07829</a></p>
</blockquote>
<h3 id="概括-9"><a href="#概括-9" class="headerlink" title="概括"></a>概括</h3><p>将传统卷积以另一种视角拓展到点云中来，称作EdgeConv。由EdgeConv组成的网络叫DGCNN。因为EdgeConv的图是动态计算的，所以其神经网络叫做Dynamic Graph CNN (DGCNN)。使用EdgeConv具有以下特点：聚合局部几何信息、EdgeConv模块可以级联使用、语义的长距离感知。并且达到了SOTA。</p>
<p>EdgeConv： EdgeConv能捕获局部几何结构，并且顺序无关。EdgeConv通过生成描述点与点之间的“边特征”（edge feature）来进行卷积计算。每当前向传播时，KNN图都会被再次计算（因为特征向量被改变，导致邻居也会变），称之为Dynamic Graph。</p>
<p>其本质上是使用graph结构vertex之间的connectivity关系，实现information通过edge来与vertex交互更新。</p>
<p>EdgeConv与PointConv的异同大概是：</p>
<ul>
<li>PointConv中，neighborhood与centroid的空间相对关系编码在distribution中；neighborhood transform也是编码在distribution中。信息传递显式地通过distribution的超距作用来交互。</li>
<li>EdgeConv中，neighborhood与centroid的空间相对关系编码在由MLP实现的$h(\cdot,\cdot)$中；neighborhood transform也是编码在由MLP实现的$h(\cdot,\cdot)$中。信息传递显式地依靠连通的edge来交互。</li>
</ul>
<p>TODO IDEA：能否不用KNN图？能否逐步减少点的数量？</p>
<h3 id="思想-9"><a href="#思想-9" class="headerlink" title="思想"></a>思想</h3><p>首先，有一个图$G$，它的每个顶点上有一个feature。下图是点$x_i$的KNN图。</p>
<p><img src="10_3.png" alt></p>
<p>然后我们利用“点特征”计算“边特征”：设这条边相邻的两个顶点的特征分别为$x_i$和$x_j$，那么“边特征”：（其中$h(\cdot,\cdot )$采用MLP实现）</p>
<script type="math/tex; mode=display">
e_{ij} = h(x_i,x_j-x_i)</script><p>每个边都由此计算得到它的边特征了（注：边的集合记作$\mathcal{E}$），现在我们利用“边特征”更新得到输出的“点特征”：</p>
<script type="math/tex; mode=display">
x_i^{'} = \max_{j:(i,j)\in \mathcal{E}} e_{ij} = \max_{j:(i,j)\in \mathcal{E}} h(x_i,x_j-x_i)</script><p>其中$x_i$（全局坐标）的输入变量编码了global shape structure，$x_j-x_i$（相对坐标）编码了local neighborhood information。</p>
<p>其中要求$h(\cdot,\cdot)$函数$\mathbb{R}^F \times \mathbb{R}^F \rightarrow \mathbb{R}^{F^{‘}}$是非线性函数，聚合操作$\max$可以是任何的对称操作符（例如$\sum$也可以）。不难知道，当$h(\cdot,\cdot)$函数是$h(x_i,x_j)=\theta_{j \; relative \; to \;i} x_j$时，聚合操作是$\sum$时，就化成普通的卷积了。</p>
<h3 id="实现-8"><a href="#实现-8" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>Edge Convolution</p>
<p>“思想”中的方法就是Edge Convolution的实现方式。</p>
<p>值得注意的是，经过Edge Convolution处理后，点的数量不变，可改变的只能是该点特征向量的维度。</p>
<p>性质：Permutation Invariance、“partial” translation invariance</p>
</li>
<li><p>Dynamic graph update</p>
<p>假设有两个Edge Convolution模块，输入特征维度是3，处理后的维度是64，再次处理后的维度是128。那么Dynamic graph update的意思是指：对3维的point cloud计算KNN图$G_1$，第一个EdgeConv根据$G_1$计算得到64维的输出。对64维的point cloud再次计算KNN图$G_2$（这次是在64维的空间中），然后第二个EdgeConv依据$G_2$计算得到128维的输出。以此类推。</p>
<p>所以动态图计算有助于算法自动构建合适的图结构来帮助优化问题。</p>
</li>
<li><p>实现</p>
<p><img src="10_2.png" alt></p>
<p>注释：</p>
<ul>
<li>$\bigoplus$是concat算符。</li>
<li>n是点云的点数，k是对于一个点的邻居数</li>
<li>图的上方分别是classification network和segmentation network。</li>
<li>左下角的网络起到类似于PointNet中的T-Net的作用，即align an input point set to a canonical space</li>
<li>右下角就是EdgeConv模块的实现方式。$h(\cdot,\cdot)$函数采用MLP实现，MLP的第$i$层的结点数记作$a_i$，输出的结点数为$a_n$（这里的n并不是指点云中点的数目）。pooling操作意指在k个邻居中max pooling。</li>
</ul>
</li>
</ol>
<h3 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h3><p>   不同层级提取到的特征（从左到右依次层级递增），通过指定一个点（红色点），然后计算其他点在该层级中与红点的距离来可视化，距离越近（代表在KNN图中是比较相邻的顶点）颜色越黄。可见该算法可以提取比较长距离的特征。</p>
<p>   <img src="10_1.png" alt></p>
<h2 id="Mo-Net"><a href="#Mo-Net" class="headerlink" title="Mo-Net"></a>Mo-Net</h2><blockquote>
<p>？？？《Mo-Net: Flavor the Moments in Learning to Classify Shapes》</p>
<p>paper下载：<a href="https://arxiv.org/abs/1812.07431" target="_blank" rel="noopener">https://arxiv.org/abs/1812.07431</a></p>
</blockquote>
<h3 id="概括-10"><a href="#概括-10" class="headerlink" title="概括"></a>概括</h3><p>提出使用几何矩的方式来提升输入点云的维度（$\mathbb{R}^3 \rightarrow \mathbb{R}^9 $），以捕获更多信息，在降低计算复杂度和内存消耗的同时提升精度。</p>
<p>注意：这篇paper主要是与PointNet相对比的；讨论的是点云的classification问题。</p>
<h3 id="实现-9"><a href="#实现-9" class="headerlink" title="实现"></a>实现</h3><p>注意，这里的MLP是shared的，只有一个MLP网络。</p>
<p><img src="11_1.png" alt></p>
<ol>
<li><p>使用几何矩</p>
<p>点云原本的输入是$(x,y,z)$，现在变成了$(x,y,z,x^2,y^2,z^2,xy,yz,xz)$</p>
</li>
<li><p>双重池化</p>
<p>将max pooing与avg pooling的结果进行concat</p>
</li>
</ol>
<h3 id="效果-1"><a href="#效果-1" class="headerlink" title="效果"></a>效果</h3><p><img src="11_3.png" alt><br>比PointNet的精度稍微高上一点点</p>
<p><img src="11_2.png" alt><br>MLP的层数可以大大减少，使得计算复杂度降低，内存消耗量降低</p>
<h2 id="Tangent-Convolutions"><a href="#Tangent-Convolutions" class="headerlink" title="Tangent Convolutions"></a>Tangent Convolutions</h2><blockquote>
<p>CVPR2018《Tangent Convolutions for Dense Prediction in 3D》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/html/Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper.html</a></p>
</blockquote>
<h3 id="概括-11"><a href="#概括-11" class="headerlink" title="概括"></a>概括</h3><p>提出了“Tangent Convolutions”，它本质是切平面上的卷积。将对point cloud feature的卷积转变为对image的卷积。</p>
<p>优点：适用于大规模场景（数百万个points）、在大规模场景可以precomputation一部分、在大规模场景中达到SOTA。</p>
<h3 id="思想-10"><a href="#思想-10" class="headerlink" title="思想"></a>思想</h3><p>将3D point cloud卷积转化/投射到2D平面的卷积。</p>
<p>即：将3D的$\sum_{q\in Neighborhood} point_feature(q)^T vector_kernel(q)$卷积转换到2D的平面卷积（卷积核等于输入图的大小，不滑动）</p>
<p>将邻居点project到切平面上，通过插值的方式产生位于切平面上的tangent image，然后使用平面卷积来卷积tangent image。</p>
<p>tangent image编码了局部的空间几何关系、以及原本作用在点云中的特征提取操作$F(q) $，现在对其平面卷积相当于对空间几何关系的operation、以及对$F(q) $的convolution。</p>
<h3 id="实现-10"><a href="#实现-10" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>Tangent Convolution</p>
<p>不仅是点云，只要3D data支持法向量估计（例如mesh），就能使用“Tangent Convolution”</p>
<p>Notation：</p>
<ul>
<li>点云$\mathcal{P}=\{p\}$</li>
<li>定义在点云$\mathcal{P}$上的函数$F(p)$（它可以描述该point的颜色/几何/或者其他任何特征）</li>
<li>点$p$的tangent plane $\pi_p$</li>
<li>continuous tangent image $S(u)$，其中$u$是tangent plane上的任意一点（可以不是投影点）</li>
</ul>
<p>Motivation：</p>
<ul>
<li>将离散定义域的$F(p)$连续化，才能对$F(p)$卷积</li>
</ul>
<p>Method：</p>
<ul>
<li><p>给定点云中的一个点$p$，用$||q-p||&lt;R$的方法选定其邻居$q$，用特征分解的方法来估计法向量$n_p$</p>
<p><img src="12_2.png" alt></p>
</li>
<li><p>将邻居$q$投射到切平面得到投影点$v$（其集合记作$V$，注意$p \notin V$），我们规定$S(v)=F(q)$（即在某几个离散位置值相等），然后其他位置使用插值的方法得到，我们使用最近邻插值：</p>
<script type="math/tex; mode=display">
S(u) = S(g_{plane}(u)) = F(g_{cloud}(u))</script><p>其中$g_{plane}(u)$表示从$V=\{v\}$中选出与$u$最近的点，$g_{cloud}(u)$表示$g_{plane}(u)$在点云中原本的点</p>
<p>在平面上原本只有几个离散的位置有值（几个狄拉克分布），现在被插值到整个平面上都有值了。</p>
</li>
<li><p>那么在平面$\pi_p $上的卷积就是：（$p$生成$\pi_p $，所以讨论$X(p)$）</p>
<script type="math/tex; mode=display">
X(p)=\sum_u c(u)S(u) = \sum_u c(u)F(g_{cloud}(u))</script><p>其中$c(u)$是卷积核。其中$g_{cloud}(u)$这项仅与点云有关，可以事先被计算。</p>
<p>实际上处理时，tangent image被处理成$l \times l$大小的2D网格图像。那么$u$相当于像素，$c(u)$相当于一个与tangent image同大小的卷积核。</p>
</li>
</ul>
</li>
<li><p>Implement a convolutional layer using tangent convolutions</p>
<p>不能算是真正意义上的“卷积层”，只能算是一个module吧</p>
<p>效果：点的数量不变，但是点的特征的维度改变</p>
<p>Notation：</p>
<ul>
<li><p>the number of points in point cloud: $N$</p>
</li>
<li><p>input feature map: $F_{in}$ of size $N \times C_{in}$</p>
</li>
<li><p>weight/flatten kernel: $W$ of size $1 \times L$（应该是有$C_{out}$个，尺寸应该是$C_{in}\times L\times 1$）</p>
</li>
<li><p>output feature map: $F_{out}$ of size $N \times C_{out}$</p>
</li>
<li><p>flatten the tangent image or kernel to 1D size: $L=l^2$</p>
</li>
</ul>
<p>Implement：</p>
<p><img src="12_1.png" alt></p>
<ul>
<li>预计算$g_{cloud}(u) $函数：对于每个来自point cloud中的点$p$，都对应了一副tangent image $S(u)$；对于每个$u\in Grid(l \times l)$，都计算一次$g_{cloud}(u) $的值。于是形成了index matrix$I$（shape: $N \times L$），记录的是点云中点的索引。</li>
<li>使用$F_{in}$矩阵将索引拓展开，得到tensor $M$，即每个点云中的点的索引值都被检索成其输入feature。$F(\cdot)$函数的作用是从点获取点的特征（from index to $C_{in}$ dimension feature），所以相当于作用了$F(\cdot)$函数。举例：point index为3，通过$F_{in}$查到$F_{in}(3,:)$的feature，相当于把$1$长度展开成$C_{in}$长度。</li>
<li>用$C_{out}$个卷积核$W$卷积$M$得到输出$F_{out} $</li>
</ul>
</li>
<li><p>Additional Ingredients</p>
<p>pooling：采用划分3D grid的方法，落在同一个grid的，坐标平均，特征向量平均</p>
<p>unpooling：将聚合点平均拷贝给其他落在同一个grid的点</p>
<p>Local distance feature：也要将邻居点$q$到切平面$\pi_{p} $的距离cancat到$q$的特征里</p>
</li>
<li><p>Architecture</p>
<p><img src="12_3.png" alt></p>
<p>其中的卷积使用tangent convolution，pooling和unpooling采用Additional Ingredients提及的方法。</p>
</li>
</ol>
<h2 id="Mixture-Model-Networks（MoNet）👍"><a href="#Mixture-Model-Networks（MoNet）👍" class="headerlink" title="Mixture Model Networks（MoNet）👍"></a>Mixture Model Networks（MoNet）👍</h2><blockquote>
<p>CVPR2017《Geometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Monti_Geometric_Deep_Learning_CVPR_2017_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2017/html/Monti_Geometric_Deep_Learning_CVPR_2017_paper.html</a></p>
</blockquote>
<h3 id="概括-12"><a href="#概括-12" class="headerlink" title="概括"></a>概括</h3><p>在非欧结构数据（non-Euclidean structured data）的几何深度学习（geometric deep learning）问题上，提出了在空间域上将传统CNN泛化到非欧几何数据（如graph、manifold）的统一的框架（MoNet），使得以往的模型设计都只是此框架内的特例，并且达到SOTA的效果。</p>
<p>此外本文还粗略地介绍了“Deep learning on graphs”（如Spectral CNN、Smooth Spectral CNN、Chebyshev Spectral CNN （ChebNet）、Graph convolutional network （GCN）、Diffusion CNN （DCNN））和“Deep learning on manifolds”（如Geodesic CNN （GCNN）、Anisotropic CNN （ACNN））</p>
<p>注：MoNet == mixture model networks</p>
<p>关键词：流形、图结构（graphs in the spectral domain）</p>
<p>其他：</p>
<ul>
<li>spectral CNN 只能适用于该图本身，不能迁移到其他图（domain-dependent）中使用。因为它的basis不同</li>
<li>基于空间域方法的优点是可以泛化到其他domain中去</li>
<li>本文提出的方法在manifold和graph上进行统一，有统一的解释性</li>
</ul>
<h3 id="实现-11"><a href="#实现-11" class="headerlink" title="实现"></a>实现</h3><p>Notation:</p>
<ul>
<li>a point on a manifold or a vertex of a graph： $x$</li>
<li>a neighborhood of point $x$： $y\in \mathcal{N(x)}$</li>
<li>d-dimensional vector of pseudo-coordinates： $u(x,y)$（可以粗略理解为相对坐标，或$e_{ij}$上的d维向量）</li>
<li>weighting functions： $w_1(u),\;w_2(u),\;…,\;w_J(u)$（each function with some learnable parameters）</li>
<li>get feature function： $f(y)$（获取该点的feature vector）</li>
</ul>
<p>The <strong>patch operator</strong> can therefore be written in the following general form（若$f(y)$是vector则计算结果也是vector，因为$w_j(u) $是一个scalar），这一步可以理解为“有J种聚合邻域信息的方式”：</p>
<script type="math/tex; mode=display">
D_j(x)f = \sum_{y\in \mathcal{N(x)}} w_j(u(x,y))f(y),\quad j=1,2,...,J</script><p>A spatial generalization of the <strong>convolution</strong> on non-Euclidean domains is then given by a template-matching procedure of the form：（$g_j$是scalar，$(f*g)(x)$的输出类型与$D_j(x)f$相同），这一步可以i理解为“将这J种聚合到的信息进行线性加权”</p>
<script type="math/tex; mode=display">
(f*g)(x) = \sum_{j=1}^J g_j D_j(x)f</script><p>所以关键问题是如何选取权重函数$w(u)$和伪坐标$u$。其中$w_j(u)$我们选用高斯函数（$\mathbb{R}^d \rightarrow \mathbb{R}$），因此可以理解为gaussian mixture model（GMM），即：</p>
<script type="math/tex; mode=display">
w_j(u) = e^{-\frac{1}{2}(u-\mu_j)^T \Sigma_j^{-1} (u-\mu_j)}</script><p>注意到，很多方法都能纳入这个框架，只需选取不同的$u(x,y)$和$w_j(u)$：</p>
<p><img src="13_1.png" alt></p>
<p>以CNN为例，假设在一个位置上的卷积，$3\times3$大小的卷积核，灰度图，则weight functions需要9个：$w_j(u)=\delta(u-\bar{u}_j),\quad j=1…,$9，其中$\bar{u}_1=(-1,1),\;\bar{u}_2=(0,1),\;\bar{u}_3=(1,1),\;…,\;\bar{u}_9=(0,0)$是kernel所覆盖点的相对坐标。则$D(x)f$是一个9维向量，所使用的卷积核$g$也是9维向量，两者进行内积则产生了一个scalar。</p>
<p>而且不难注意到，The patch operator公式就是KPConv中所用点卷积的泛化形式，将：</p>
<script type="math/tex; mode=display">
(\mathcal{F}*\mathcal{g})(x) = \sum_{x_i\in\mathcal{N}_x} g(x_i-x)f_i</script><p>泛化成：</p>
<script type="math/tex; mode=display">
D_j(x)f = \sum_{y\in \mathcal{N(x)}} w_j(u(x,y))f(y),\quad j=1</script>
            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">给小编加个鸡腿🍗呗</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>转载规则</span>
        </p>
        
            <div class="center-align">
                <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《3D点云特征提取笔记》
                </span> 由
            <a xmlns:cc="http://creativecommons.org/ns#" href="/3d/3dclassificationnotes/" property="cc:attributionName"
               rel="cc:attributionURL">
                Karbo
            </a> 采用
            <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                知识共享署名 4.0 国际许可协议
            </a>进行许可。
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: 'WwrKLalwiFrnKlAcLCjpeyK7-gzGzoHsz',
        appKey: 'zF7jn8hejoyxVPESEeCAxCzY',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'ヾﾉ≧∀≦)o来评论啊，快活啊!'
    });
</script>
    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/dl/precisionrecall/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="机器学习中常用的指标">
                        
                        <span class="card-title">机器学习中常用的指标</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            本文介绍了Precision、Recall、F1-score等一些常见的概念
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2019-09-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/dl/" class="post-category" target="_blank">
                                    dl
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/dl/" target="_blank">
                        <span class="chip bg-color">dl</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/dl/conv-understanding/">
                    <div class="card-image">
                        
                        <img src="/dl/conv-understanding/cover.jpeg" class="responsive-img" alt="理解深度学习中的各种卷积">
                        
                        <span class="card-title">理解深度学习中的各种卷积</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Towards intuitive understanding of convolutions through visualizations
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-08-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/dl/" class="post-category" target="_blank">
                                    dl
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/dl/" target="_blank">
                        <span class="chip bg-color">dl</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            本站由
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">hexo-theme-matery</a>主题搭建.

            
            &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
            <span class="white-color">77.2k</span>
            

            
            
            <br>
            
            <span id="busuanzi_container_site_pv">
                <i class="fa fa-heart-o"></i>
                本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                <i class="fa fa-users"></i>
                次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
            </span>
            
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
<a href="https://github.com/Karbo123" class="tooltipped" target="_blank" data-tooltip="我的GitHub" data-position="top"
    data-delay="50">
    <i class="fa fa-github"></i>
</a>



<a href="https://www.zhihu.com/people/karbo-50/activities" class="tooltipped" target="_blank" data-tooltip="我的知乎" data-position="top"
    data-delay="50">
    <i class="fa fa-user"></i>
</a>



<a href="mailto:lei@karbo.online" class="tooltipped" target="_blank" data-tooltip="邮件联系"
    data-position="top" data-delay="50">
    <i class="fa fa-envelope-open"></i>
</a>



<a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top"
    data-delay="50">
    <i class="fa fa-rss"></i>
</a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>

<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


</body>
</html>