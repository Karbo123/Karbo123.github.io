<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="3Dç»“æ„é‡å»º, ä»»æˆ‘è¡Œ">
    <meta name="description" content="3Dé‡å»ºä»‹ç»3Dé‡å»ºçš„å„ç§æ¨¡å‹æ¡†æ¶æ–¹æ³•ç­‰ã€‚
3Dæ•°æ®å¸¸ç”¨çš„è¡¨ç¤ºæ–¹æ³•ï¼š

Rasterized formsä¾‹å¦‚voxels and multi-view RGB(D) images.
Geometric formsä¾‹å¦‚point clouds">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>3Dç»“æ„é‡å»º | ä»»æˆ‘è¡Œ</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ä»»æˆ‘è¡Œ</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>é¦–é¡µ</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>æ ‡ç­¾</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>åˆ†ç±»</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>å½’æ¡£</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>å…³äº</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>å‹æƒ…é“¾æ¥</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="æœç´¢"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ä»»æˆ‘è¡Œ</div>
        <div class="logo-desc">
            
            å¯ä»¥ä»»æˆ‘èµ°æ€ä¹ˆåˆ°å¤´æ¥åˆéšç€å¤§é˜Ÿèµ°ï¼Œäººç¾¤æ˜¯é‚£ä¹ˆåƒç¾Šç¾¤
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                é¦–é¡µ
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                æ ‡ç­¾
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                åˆ†ç±»
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                å½’æ¡£
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                å…³äº
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                å‹æƒ…é“¾æ¥
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Karbo123" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Karbo123" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>





<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/17.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        3Dç»“æ„é‡å»º
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/3d/" target="_blank">
                                <span class="chip bg-color">3d</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/3d/" class="post-category" target="_blank">
                                3d
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2019-10-08
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                        14.7k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                        62 åˆ†
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="3Dé‡å»º"><a href="#3Dé‡å»º" class="headerlink" title="3Dé‡å»º"></a>3Dé‡å»º</h1><p>ä»‹ç»3Dé‡å»ºçš„å„ç§æ¨¡å‹æ¡†æ¶æ–¹æ³•ç­‰ã€‚</p>
<p>3Dæ•°æ®å¸¸ç”¨çš„è¡¨ç¤ºæ–¹æ³•ï¼š</p>
<ul>
<li>Rasterized formsä¾‹å¦‚voxels and multi-view RGB(D) images.</li>
<li>Geometric formsä¾‹å¦‚point clouds, polygon meshes, and sets of primitives</li>
<li>å…¶ä»–ï¼šgeometry imagesã€depth imagesã€classification boundariesã€signed distance function</li>
</ul>
<h2 id="3D-R2N2"><a href="#3D-R2N2" class="headerlink" title="3D-R2N2"></a>3D-R2N2</h2><blockquote>
<p>ECCV2016ã€Š3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstructionã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="https://arxiv.org/abs/1604.00449" target="_blank" rel="noopener">https://arxiv.org/abs/1604.00449</a></p>
</blockquote>
<h3 id="æ¦‚è¿°"><a href="#æ¦‚è¿°" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>æå‡º3D-R2N2ç½‘ç»œï¼Œèƒ½å¤Ÿè¾“å…¥ä¸€å¼ /å¤šå¼ å›¾ç‰‡å¹¶é‡å»ºå‡º3D occupancy gridï¼Œè¯¥æ–¹æ³•åœ¨è®­ç»ƒ/æµ‹è¯•é˜¶æ®µä¸éœ€è¦ä»»ä½•çš„å›¾åƒæ ‡æ³¨å’Œç‰©ä½“ç±»åˆ«æ ‡ç­¾ï¼ˆä½†éœ€è¦bounding boxï¼‰ã€‚åœ¨æŸäº›æƒ…å½¢ä¸­ä½¿ç”¨ä¼ ç»ŸSFM/SLAMæ–¹æ³•å¤±æ•ˆè€Œæœ¬æ–¹æ³•å´èƒ½å¤Ÿé‡å»ºå‡ºæ¥ï¼ˆå› ä¸ºè¿™äº›æƒ…å½¢ç¼ºå°‘çº¹ç†ï¼Œæˆ–è€…æ‘„åƒæœºçš„æ‹æ‘„è§†è§’å˜åŒ–å¤§ï¼‰ã€‚3D-R2N2æ˜¯è‡ªåŠ¨å­¦ä¹ çš„ã€end-to-endçš„ã€‚æ€§èƒ½è¶…è¶Šäº†SOTAã€‚</p>
<p>åˆ›æ–°ç‚¹ï¼šä½¿ç”¨RNNæ¥å®ç°å…è®¸å•å›¾ç‰‡/å¤šå›¾ç‰‡çš„è¾“å…¥</p>
<p>æ³¨ï¼š</p>
<ul>
<li>3D-R2N2 == 3D Recurrent Reconstruction Neural Network</li>
<li><p>å…ˆå‰æ–¹æ³•çš„è¦æ±‚æ¡ä»¶ï¼ˆå› ä¸ºSFM/SLAMè¿™ç±»æ–¹æ³•å‡è®¾äº†features can be matched across viewsï¼‰ï¼š</p>
<ul>
<li><p>è§‚å¯Ÿçš„è§†è§’å¯†é›†ï¼Œå³ç›¸æœºçš„ä½ç½®å˜åŒ–æ¯”è¾ƒå°</p>
</li>
<li><p>è¡¨é¢æ˜¯Lambertian reflectanceï¼Œå³å‡åŒ€çš„æ¼«åå°„</p>
</li>
<li><p>è¡¨é¢çš„çº¹ç†ä¸°å¯Œï¼Œä¸å•ä¸€</p>
</li>
</ul>
</li>
<li>æ‰€ä½¿ç”¨çš„æ•°æ®é›†ï¼šShapeNetã€PASCAL 3Dã€Online Productsã€MVS CAD Models</li>
<li>æ‰€å¯¹æ¯”çš„æ¨¡å‹ï¼šKar et al.ï¼ˆã€ŠCategory-Specific Object Reconstruction from a Single Imageã€‹ï¼‰ã€Multi View Stereo methodï¼ˆMVSï¼‰</li>
</ul>
<h3 id="åŸç†"><a href="#åŸç†" class="headerlink" title="åŸç†"></a>åŸç†</h3><p><img src="1_1.png" alt></p>
<p>åˆ©ç”¨RNNçš„â€œå¯æ¥å—ä»»æ„é•¿çš„åºåˆ—è¾“å…¥â€çš„æ€§è´¨ï¼Œæ¥è¾¾åˆ°å•è§†å›¾/å¤šè§†å›¾è¾“å…¥çš„ç»Ÿä¸€ã€‚</p>
<p>é¦–å…ˆå°†å›¾ç‰‡åˆ©ç”¨2D convç¼–ç æˆ1024ç»´çš„ç‰¹å¾å‘é‡ã€‚ç„¶åä¸¢åˆ°3D Convolutional LSTMä¸­ï¼Œè¾“å‡ºæ˜¯$4\times 4\times 4$å¤§å°çš„voxelsï¼ˆ4D tensorï¼‰ï¼Œæ¯ä¸ªvoxelä½ç½®ä¸Šéƒ½æ˜¯ä¸€ä¸ªvectorï¼ˆå…¶å®æ˜¯æ’åˆ—æˆ$4\times 4\times 4$çš„64ä¸ªLSTMå•å…ƒï¼Œç„¶åå–hidden stateä½œä¸ºæ¯ä¸ªvoxelçš„ç‰¹å¾å‘é‡ï¼‰ã€‚ç„¶åå°†4D tensorä¸¢åˆ°3D convä¸­ä¸Šé‡‡æ ·ï¼Œå¾—åˆ°$32\times 32\times 32$çš„3D occupancy gridï¼ˆæ¯ä¸ªvoxelä½ç½®ä¸Šæ˜¯è¿™ä¸ªvoxelå–åˆ°çš„æ¦‚ç‡ï¼Œæ‰€ä»¥éœ€è¦ä¸€ä¸ªthresholdæ¥ç¡®å®šæœ€ç»ˆçš„è¾“å‡ºï¼‰ã€‚</p>
<p>éšç€è¾“å…¥å›¾ç‰‡å˜å¤šï¼Œå¾—åˆ°çš„ç»“æœä¹Ÿé€æ¸å˜å¾—ç²¾ç»†ã€‚</p>
<p>è§†è§‰ä¸Šè§£é‡ŠLSTMå¸¦æ¥çš„ä¼˜ç‚¹ï¼šLSTMçš„é—å¿˜é—¨/è¾“å…¥é—¨æœºåˆ¶å¯¹åº”äºè‡ªåŠ¨çº é”™é”™è¯¯é‡å»ºçš„éƒ¨åˆ†/è‡ªåŠ¨é‡å»ºæœªçœ‹è§çš„éƒ¨åˆ†ï¼ˆæœ‰æ•ˆçš„å¤„ç†ç‰©ä½“é®æŒ¡é—®é¢˜ï¼‰</p>
<h3 id="å®ç°"><a href="#å®ç°" class="headerlink" title="å®ç°"></a>å®ç°</h3><p>åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼š2D Convolutional Neural Network (2D-CNN), a novel architecture named 3D Convolutional LSTM (3D-LSTM), and a 3D Deconvolutional Neural Network (3D-DCNN)</p>
<ol>
<li><p>Encoder: 2D-CNN</p>
<p>å¯ä»¥ä½¿ç”¨æ™®é€šçš„æµ…CNNï¼ˆä¸Šé¢é‚£ä¸ªï¼‰ï¼Œæˆ–è€…æ˜¯ä½¿ç”¨æ®‹å·®ç»“æ„çš„æ·±CNNï¼ˆä¸‹é¢é‚£ä¸ªï¼‰ã€‚å®éªŒè¡¨æ˜æ®‹å·®ç»“æ„æ›´å¥½ã€‚</p>
<p><img src="1_2.png" alt></p>
</li>
<li><p>Recurrence: 3D Convolutional LSTM</p>
<p><img src="1_3.png" alt></p>
<p>åœ¨å®æ–½ä¾‹ä¸­ï¼Œæœ‰64ä¸ªä¸åŒçš„LSTMå•å…ƒï¼Œæ’åˆ—æˆ$4\times 4\times 4$çš„å½¢çŠ¶ã€‚ç»è¿‡æŸç§è®¡ç®—ä¹‹åï¼Œæˆ‘ä»¬å–æ¯ä¸ªLSTMå•å…ƒçš„$N_h$ç»´çš„hidden stateä½œä¸ºè¾“å‡ºï¼Œäºæ˜¯å¾—åˆ°$4\times 4\times 4 \times N_h$çš„4D tensorè¾“å‡ºã€‚è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<p><img src="1_4.png" alt></p>
<p>å…¶ä¸­$f_t$æ˜¯é—å¿˜é—¨ï¼Œ$i_t$æ˜¯è¾“å…¥é—¨ï¼Œ$s_t$æ˜¯memory cellï¼Œ$h_t$æ˜¯hidden stateã€‚</p>
<p>å…ˆè€ƒè™‘åœ¨ä¸€ä¸ªä½ç½®ä¸Šçš„è®¡ç®—ï¼š$U*h_{t-1}$è¡¨ç¤ºå‘¨å›´é‚»å±…ï¼ˆçº¢è‰²ï¼‰çš„$t-1$æ—¶åˆ»çš„hidden stateçš„çº¿æ€§åŠ æƒå’Œ$\sum_{k \in \mathcal{N}_{index}} u_k h_{t-1}[k]$ï¼Œ$\mathcal{T(x_t)}$è¡¨ç¤º$t$æ—¶åˆ»çš„1024ç»´å‘é‡è¾“å…¥ã€‚é‚£ä¹ˆè¾“å‡º$h_t$å°±æ˜¯ä¸€ä¸ªå‘é‡ã€‚</p>
<p>å¦‚æœè€ƒè™‘å…¨éƒ¨64ä¸ªLSTMå•å…ƒï¼Œé‚£ä¹ˆè¾“å‡º$h_t$å°±æ˜¯ä¸€ä¸ª4D tensorã€‚</p>
<p>ä½œè€…åœ¨è¿™é‡Œæ²¡æœ‰ä½¿ç”¨outputs gateï¼ŒèŠ‚çœäº†å‚æ•°é‡ã€‚è¿™é‡Œçš„kernel sizeæ˜¯3ã€‚</p>
<p>å½“ç„¶ä¹Ÿæœ‰åŸºäºGRUï¼ˆGated Recurrent Unitï¼‰çš„å®ç°æ–¹æ³•ï¼Œå®éªŒè¡¨æ˜GRUæ•ˆæœå¥½äºLSTMï¼Œkernel sizeä¸º3æ—¶å¥½äºä¸º1æ—¶ã€‚</p>
</li>
<li><p>Decoder: 3D Deconvolutional Neural Network</p>
<p>å¯ä»¥ç”¨æ™®é€šçš„3Då·ç§¯ï¼Œä¹Ÿå¯ä»¥ç”¨æ®‹å·®ç»“æ„çš„3Då·ç§¯ã€‚</p>
<p>æœ€åå°†$32\times 32\times\times 32 \times 2$çš„è¾“å‡ºå¥—ç”¨softmaxï¼Œå¾—åˆ°voxel-wiseçš„æ¦‚ç‡å€¼ï¼ˆå°ºå¯¸$32\times 32\times \times 32$ï¼‰ã€‚ç„¶åç”¨thresholdæˆªæ–­æ¦‚ç‡ä¾¿å¾—åˆ°æœ€åçš„ç»“æœã€‚</p>
<p>æŸå¤±å‡½æ•°æ˜¯the sum of voxel-wise cross-entropy</p>
</li>
<li><p>è®­ç»ƒå’Œæ•ˆæœ</p>
<ul>
<li>Data augmentationï¼š augmented the input images with random cropsã€tinted the colorã€randomly translated the imagesã€all viewpoints were sampled randomly</li>
<li>Trainingï¼š variable length inputs ranging from one image to an arbitrary number of images</li>
<li>Metricsï¼š voxel Intersection-over-Union (IoU)ã€cross-entropy loss</li>
</ul>
</li>
</ol>
<h2 id="PointOutNet"><a href="#PointOutNet" class="headerlink" title="PointOutNet"></a>PointOutNet</h2><blockquote>
<p>CVPR2017ã€ŠA Point Set Generation Network for 3D Object Reconstruction from a Single Imageã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Fan_A_Point_Set_CVPR_2017_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2017/html/Fan_A_Point_Set_CVPR_2017_paper.html</a></p>
</blockquote>
<h3 id="æ¦‚è¿°-1"><a href="#æ¦‚è¿°-1" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>ä½œè€…æ˜¯ç¬¬ä¸€ä¸ªç”¨æ·±åº¦å­¦ä¹ é‡å»ºç‚¹äº‘çš„äººã€‚è¾“å…¥å•å¼ å›¾ç‰‡ï¼Œè¾“å‡ºç‚¹äº‘çš„3Dåæ ‡ã€‚ä»–ä»¬æ„é€ çš„æ¨¡å‹æ˜¯â€œconditional shape samplerâ€ï¼ˆå³æœ‰ä¸ªè¾“å…¥å˜é‡$r$å¯ä»¥æ§åˆ¶ç”Ÿæˆçš„å¤šæ ·æ€§ï¼Œç”¨äºæè¿°é‡å»ºçš„ä¸ç¡®å®šæ€§ï¼‰ï¼Œå¯ä»¥è¾“å‡ºå¤šç§å¯èƒ½çš„ç‚¹äº‘ï¼ˆå–å†³äº$r$ï¼‰ã€‚å•å›¾è¾“å…¥çš„æƒ…å†µä¸‹æ€§èƒ½è¶…è¶ŠSOTAï¼ˆä¸3D-R2N2å¯¹æ¯”ï¼‰ã€‚ä¹Ÿå¯ä»¥ç”¨äº3Dè¡¥å…¨ï¼Œä»¥åŠå¤šå¯èƒ½çš„è¾“å‡ºã€‚</p>
<p>ä¼¼ä¹æ²¡æ·±ç©¶å¦‚ä½•ç”Ÿæˆç‚¹äº‘ä»¥è¾¾åˆ°æ— åºæ€§è¾“å‡ºï¼Œæ–‡ä¸­å¥½åƒæ˜¯åœ¨fc/convè¿™æ ·çš„ç»“æ„åŒ–æ’åˆ—ä¸­è¾“å‡ºçš„ï¼Ÿ</p>
<p>éš¾ç‚¹ï¼š</p>
<ul>
<li>å¦‚ä½•è¾“å‡ºç‚¹äº‘</li>
<li>ä»…é è¾“å…¥çš„å•å¼ å›¾ç‰‡éš¾ä»¥ç›´æ¥ç¡®å®š3Då½¢çŠ¶ï¼ˆå³inherent ambiguity in groundtruthï¼‰</li>
</ul>
<p>ç‰¹ç‚¹ï¼š</p>
<ul>
<li>å¼•å…¥éšæœºå˜é‡$r$å¯ä»¥ä»è¾“å…¥æ“æ§ç”Ÿæˆç‚¹äº‘çš„å¤šæ ·æ€§</li>
</ul>
<p>ä½œè€…çš„Discussionï¼š</p>
<ul>
<li>First, how to generate an orderless set of entities. Towards building generative models for more sophisticated combinatorial data structures such as graphs, knowing how to generate a set may be a good starting point.</li>
<li>Second, how to capture the ambiguity of the groundtruth in a regression problem. Other than 3D reconstruction, many regression problems may have such inherent ambiguity. Our construction of the MoN loss by wrapping existing loss functions may be generalizable to these problems.</li>
</ul>
<p>TODO IDEAï¼šèƒ½å¦ä¸ä½¿ç”¨â€œDistance Metric between Point Setsâ€ï¼Œè½¬è€Œä½¿ç”¨èƒ½ç›´æ¥å¤„ç†ç‚¹äº‘çš„ç½‘ç»œï¼Ÿèƒ½å¦å®šå‘æ“æ§$r$å„ä¸ªåˆ†é‡æ‰€å¯¹åº”çš„3Då±æ€§ï¼Ÿ</p>
<h3 id="å®ç°-1"><a href="#å®ç°-1" class="headerlink" title="å®ç°"></a>å®ç°</h3><p>ä¸»è¦ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼šarchitecture, loss function and learning paradigm</p>
<p>æ³¨ï¼šarchitectureçš„ä½œç”¨æ˜¯æ ¹æ®å›¾ç‰‡å’Œéšæœºå‘é‡$r$æ¥ç”Ÿæˆç‚¹äº‘ï¼›loss functionçš„ä½œç”¨æ˜¯åº¦é‡ç‚¹äº‘ç›¸ä¼¼åº¦ï¼›learning paradigmä½œç”¨æ˜¯ä½¿å¾—éšæœºå˜é‡$r$èƒ½åœ¨ç½‘ç»œä¸­èµ·ä½œç”¨ï¼Œç›¸å½“äºåœ¨loss functionå¤–éƒ¨åŒ…ä¸Šäº†ä¸€å±‚â€œMoNå‡½æ•°â€ã€‚</p>
<ol>
<li><p>Architecture - Point Set Prediction Networkï¼ˆæ­¤ç½‘ç»œç®€è®°ä½œ$\mathbb{G}$ï¼‰</p>
<p><img src="2_1.png" alt></p>
<p>ä½œè€…è®¾è®¡äº†3ç§ç½‘ç»œçš„ç»“æ„ï¼švanilla versionã€two prediction branch versionå’Œhourglass version</p>
<p>æ¯ç§ç½‘ç»œéƒ½æœ‰encoder stageå’Œpredictor stageã€‚encoder stageç”¨äºå°†å›¾ç‰‡$I$å’Œè¾“å…¥çš„éšæœºå‘é‡$r$æ˜ å°„åˆ°embedding spaceï¼›è€Œpredictoråˆ™è¾“å‡ºä¸€ä¸ª$N \times 3$å¤§å°çš„çŸ©é˜µ$M$ï¼ˆ$N$æ˜¯é‡å»ºå‡ºçš„ç‚¹äº‘çš„ç‚¹æ•°ï¼‰ã€‚A random vector $r$ is subsumed so that it perturbs the prediction from the image $I$ï¼ˆéšæœºå‘é‡$r$çš„ç”¨æ³•åœ¨â€œGeneration of Multiple Plausible Shapesâ€ä¼šè®²åˆ°ï¼‰</p>
<ul>
<li>vanilla versionï¼šæœ€åŸå§‹çš„ç‰ˆæœ¬ï¼Œç»†èŠ‚è§å›¾ï¼ˆr.v.å°±æ˜¯éšæœºå‘é‡$r$ï¼‰ã€‚Though simple, this version works reasonably well in practice.</li>
<li>two prediction branch versionï¼šç›®çš„æ˜¯better accommodate large and smooth surfaces which are common in natural objectsã€‚å®ƒçš„predictoræœ‰ä¸¤ä¸ªå¹¶è¡Œçš„åˆ†æ”¯ï¼ša fully-connected (fc) branch and a deconvolution (deconv) branchã€‚fc branché¢„æµ‹$N_1=256$ä¸ªç‚¹ï¼ˆfcè¾“å‡º256*3ä¸ªnodesï¼‰ï¼Œdeconv branché¢„æµ‹è¾“å‡º$H \times W=24\times 32$ä¸ªç‚¹ï¼ˆæ’åˆ—æˆ$24\times 32$ç„¶åä¸€ä¸ªåƒç´ å¯¹åº”ä¸€ä¸ª3Dçš„ç‚¹ï¼Œæ˜¯3é€šé“çš„ï¼‰ã€‚é‚£ä¹ˆæ€»å…±è¾“å‡º$N = 24 \times 32 + 256=1024$ä¸ªç‚¹ï¼ˆä¸çŸ¥é“å¦‚ä½•å¤„ç†æ— åºæ€§å‘¢ï¼Ÿï¼Ÿï¼‰ã€‚Their predictions are later merged together to form the whole set of points in $M$. Multiple skip links are added to boost information flow across encoder and predictorã€‚fc branchåŠŸèƒ½ï¼šhigh flexibilityã€å¯describe intricate structuresã€‚deconvolution branchåŠŸèƒ½ï¼šèŠ‚çœå‚æ•°ã€more friendly to large smooth surfaces, due to the spatial continuity induced by deconv and convã€‚</li>
<li>hourglass versionï¼šThis deep network conducts the encoding-decoding operations recurrently, thus has stronger representation power and can mix global and local information better.</li>
</ul>
</li>
<li><p>Loss function - Distance Metric between Point Sets</p>
<p>å¯¹Lossçš„è¦æ±‚ï¼šå¯å¾®ã€é«˜æ•ˆè®¡ç®—ã€å¯¹å¼‚å¸¸ç‚¹é²æ£’</p>
<p>é‚£ä¹ˆéœ€è¦æ‰¾åˆ°ä¸€ç§è¡¡é‡ä¸¤ä¸ªç‚¹äº‘$S_i^{pred}$å’Œ$S_i^{gt}$ç›¸ä¼¼åº¦çš„è·ç¦»å‡½æ•°$d(S_i^{pred}ï¼ŒS_i^{gt})$ï¼Œé‚£ä¹ˆæŸå¤±å‡½æ•°å°±æ˜¯$L = \sum_i d(S_i^{pred}ï¼ŒS_i^{gt})$ï¼ˆå…¶ä¸­$i$æ˜¯training samplesçš„indexã€‚è¿™ä¸ªæŸå¤±å‡½æ•°è¿˜ä¸æ˜¯æœ€ç»ˆçš„æŸå¤±å‡½æ•°ï¼Œä¸èƒ½å®é™…åº”ç”¨ï¼‰</p>
<p>ä½œè€…å»ºè®®ä½¿ç”¨Chamfer distanceï¼ˆCDï¼‰æˆ–Earth Moverâ€™s distanceï¼ˆEMDï¼‰</p>
<p><img src="2_2.png" alt></p>
<p>Facing the inherent inability to resolve the shape precisely, neural networks tend to predict a â€œmeanâ€ shape averaging out the space of uncertainty. The mean shape carries the characteristics of the distance itself.</p>
</li>
<li><p>Learning paradigm - Generation of Multiple Plausible Shapes</p>
<p>The ambiguity of groundtruth shape may significantly affect the trained predictor, as the loss function induces our model to predict the mean of possible shapes. So We expect that the random<br>variable $r$ passed to â€œPoint Set Prediction Networkâ€ would help it explore the groundtruth distribution. å¦‚æœè·³è¿‡è¿™æ­¥ä¸åšçš„è¯ï¼Œå°±ä¼šå¯¼è‡´the loss minimization will nullify the randomness.</p>
<p>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æœ€å°åŒ–ä¸‹é¢çš„æŸå¤±å‡½æ•°ï¼ˆç§°ä½œMin-of-N loss ï¼ˆMoNï¼‰ï¼‰çš„æ–¹æ³•æ¥è§£å†³ï¼š</p>
<p><img src="2_3.png" alt></p>
<p>æ„æ€æ˜¯å°è¯•$n $ä¸ªrandom variableçš„å–å€¼ï¼Œç„¶åå–æœ€å°è·ç¦»ä½œä¸ºè·ç¦»å€¼ã€‚ï¼ˆ$n=2$è¶³çŸ£ï¼‰</p>
<p>å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨Conditional VAEï¼ˆè¿™æ ·å¥½åƒ$\mathbb{G}$é‡Œå°±ä¸ç”¨$r$äº†ï¼‰ï¼Œè¯¦æƒ…ç•¥ã€‚</p>
<p>ä¼¼ä¹ä¹Ÿèƒ½ç”¨Conditional GANï¼Œä½†æ˜¯ä½œè€…æ²¡æ·±ç©¶ã€‚</p>
</li>
</ol>
<h3 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><p>ç”¨ShapeNet datasetï¼Œä»CADæ¨¡å‹ä¸­æ¸²æŸ“å‡ºå›¾ç‰‡æ¥</p>
<ol>
<li><p>3D Shape Reconstruction from RGB Images</p>
<p>ä¸3D-R2N2ä½œæ¯”è¾ƒã€‚å°†3D-R2N2è¾“å‡ºçš„ä½“æ•°æ®ç”¨æœ€è¿œç‚¹é‡‡æ ·è·å¾—ç‚¹æ•°æ®ï¼Œç„¶åè®¡ç®—CDã€EMDå€¼ï¼›å°†æœ¬æ¨¡å‹è¾“å‡ºçš„ç‚¹æ•°æ®ç»è¿‡åæœŸå¤„ç†å¾—åˆ°ä½“æ•°æ®ï¼Œç„¶åè®¡ç®—IoUå€¼ã€‚</p>
<p>å®éªŒè¡¨æ˜æœ¬æ–¹æ³•åœ¨å•å¼ å›¾ç‰‡è¾“å…¥æ—¶ï¼Œåœ¨æ‰€æœ‰ç§ç±»ä¸Šç²¾åº¦è¿œè¶…3D-R2N2ã€‚åŒæ—¶å¤§éƒ¨åˆ†ç§ç±»çš„ç²¾åº¦è¿œè¶…5å¼ å›¾ç‰‡è¾“å…¥çš„3D-R2N2ã€‚è€Œä¸”æœ¬æ–¹æ³•ä¸å­˜åœ¨â€œè–„å¼±ç»†å°ç»“æ„â€ä¸èƒ½é‡å»ºçš„ç¼ºç‚¹ã€‚</p>
</li>
<li><p>3D Shape Completion from RGBD Images</p>
<p>å½“æ˜¯RGBDè¾“å…¥æ—¶ï¼Œè¿˜å¯ä»¥èµ·åˆ°3Dè¡¥å…¨çš„ä½œç”¨ã€‚</p>
<p><img src="2_4.png" alt></p>
</li>
<li><p>Predicting Multiple Plausible Shapes</p>
<p>æ”¹å˜$r$å€¼å¯ä»¥äº§ç”Ÿå¤šç§è¾“å‡ºã€‚</p>
<p><img src="2_5.png" alt></p>
</li>
<li><p>Network Design Analysis</p>
<ul>
<li><p>Effect of combining deconv and fc branches for reconstruction</p>
<ul>
<li><p>deconvçš„å¼•å…¥æå‡äº†ç²¾åº¦ï¼›Stacking another hourglass levelä¹Ÿæå‡äº†ç²¾åº¦</p>
</li>
<li><p>In the deconv branch the network learns to use the convolution structure to constructs a 2D surface that warps around the object. In the fully connected branch the output is less organized as the channels are not ordered.</p>
</li>
<li><p>The deconv branch is in general good at capturing the â€œmain bodyâ€ of the object, while the fully connected branch complements the shape with more detailed components</p>
<p><img src="2_6.png" alt></p>
</li>
</ul>
</li>
<li><p>Analysis of distance metrics</p>
<p>The network trained by CD tends to scatter a few points in its uncertain area (e.g. behind the door) but is able to better preserve the detailed shape of the grip. In contrast, the network trained by EMD produces more compact results but sometimes overly shrinks local structures. This is in line with experiment on synthetic data.</p>
</li>
</ul>
</li>
<li><p>More results and application to real world data</p>
<p>ä¹Ÿèƒ½ç”¨äºç°å®ç”Ÿæ´»ä¸­ç…§ç‰‡çš„3Dé‡å»ºï¼Œä½†éœ€è¦ä»èƒŒæ™¯åˆ†å‰²å‡ºç‰©ä½“æ¥</p>
</li>
<li><p>Analysis of human ability for single view 3D reconstruction</p>
<p>æŸäº›å›¾ç‰‡ä¸Šè¶…è¶Šäººç±»</p>
</li>
<li><p>Analysis of failure cases</p>
<p>ä»…ä»…æ˜¯ä¸»è§‚åˆ†æï¼Œç•¥</p>
</li>
</ol>
<h2 id="OGN-ğŸ‘"><a href="#OGN-ğŸ‘" class="headerlink" title="OGN ğŸ‘"></a>OGN ğŸ‘</h2><blockquote>
<p>ICCV2017ã€ŠOctree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputsã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="http://openaccess.thecvf.com/content_iccv_2017/html/Tatarchenko_Octree_Generating_Networks_ICCV_2017_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_iccv_2017/html/Tatarchenko_Octree_Generating_Networks_ICCV_2017_paper.html</a></p>
</blockquote>
<h3 id="æ¦‚è¿°-2"><a href="#æ¦‚è¿°-2" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>ä½¿ç”¨å…«å‰æ ‘ï¼ˆoctreeï¼‰çš„è¡¨ç¤ºæ³•ï¼Œç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„3Dä½“ç´ æ•°æ®ã€‚æœ¬æ–‡ä¸­çš„OGNæ˜¯deep convolutional decoderï¼ˆå³3Dä½“ç´ ç”Ÿæˆå™¨ï¼‰ã€‚è¿‘ä¼¼å¹³æ–¹çš„å¤æ‚åº¦ï¼ˆè€Œä¸æ˜¯ç«‹æ–¹å¤æ‚åº¦ï¼‰ï¼Œå¤§å¤§èŠ‚çœäº†å†…å­˜å’Œè®¡ç®—é‡æ¶ˆè€—ã€‚ä½åˆ†è¾¨ç‡æ—¶ä¸æ™®é€šçš„voxelæ–¹æ³•ç²¾åº¦å·®ä¸å¤šï¼Œè€Œä¸”å®ƒè¿˜èƒ½ç”Ÿæˆé«˜åˆ†è¾¨ç‡ä½“ç´ ï¼Œç”šè‡³å¯ä»¥ç”Ÿæˆ$512^3$è¿™ä¹ˆå¤§çš„åˆ†è¾¨ç‡ã€‚å¯ä»¥ç”¨åœ¨å¤šç§åœºåˆï¼Œå¦‚3D convolutional autoencodersã€reconstruction from high-level representations or a single image</p>
<p><img src="3_3.png" alt></p>
<p>æ³¨æ„ï¼š</p>
<ul>
<li>ä½¿ç”¨octreeæ„å‘³ç€å¯ä»¥ä½¿ç”¨ä¸åŒå¤§å°çš„cell sizeï¼Œä¸æ–­ç»†åˆ†å¤§çš„cellæ¥è¾¾åˆ°é«˜åˆ†è¾¨ç‡ã€‚å³ä¸æ–­ç²¾ç»†åŒ–ä½“ç´ æ¥è¾¾åˆ°é«˜åˆ†è¾¨ç‡</li>
<li>OGNæ˜¯åœ¨å…«å‰æ ‘ä¸Šæ“ä½œã€‚ç”¨binary occupancy mapsæ¥è¡¨ç¤ºç”Ÿæˆçš„å½¢çŠ¶</li>
<li>åŒæ—¶OGNä¹Ÿæ˜¯çµæ´»çš„ï¼Œå³å¯ä»¥ä»»æ„æŒ‡å®šå±‚æ•°å’Œå±‚çš„é…ç½®</li>
<li>OGNæ˜¯end-to-endçš„ï¼Œå¯ç”¨åå‘ä¼ æ’­è®¡ç®—</li>
</ul>
<h3 id="åŸç†-1"><a href="#åŸç†-1" class="headerlink" title="åŸç†"></a>åŸç†</h3><p><img src="3_1.png" alt></p>
<ul>
<li><p>æœ€å·¦è¾¹çš„â€œdense blockâ€ç”±æ™®é€šçš„3Då·ç§¯å±‚ç»„æˆï¼Œè¾“å‡º$d_1 \times d_2 \times d_3 \times c$å¤§å°çš„4D tensorã€‚</p>
</li>
<li><p>ç„¶åè¿™ä¸ª4D tensorè¢«è½¬æ¢ä¸ºé”®å€¼å¯¹ï¼ˆindex-value pairsï¼‰å­˜å‚¨åœ¨hash tableä¸­ï¼Œvalueå°±æ˜¯ä¸€ä¸ªvoxelå†…çš„ç‰¹å¾å‘é‡ã€‚</p>
</li>
<li><p>ç„¶åæ¥ä¸‹æ¥çš„octree blockå°±ä¼šé¢„æµ‹octreeæ–°ç”Ÿæˆçš„ç»“æ„ã€å’Œç›¸åº”ç”Ÿæˆçš„å†…å®¹ï¼ˆç‰¹å¾å‘é‡ï¼‰ã€‚</p>
</li>
<li><p>å¤šæ¬¡é€šè¿‡octree blockå¤„ç†å°±ä¼šç”Ÿæˆé«˜ç²¾åº¦çš„ä½“ç´ è¡¨ç¤ºã€‚</p>
</li>
</ul>
<h3 id="å®ç°-2"><a href="#å®ç°-2" class="headerlink" title="å®ç°"></a>å®ç°</h3><ol>
<li><p>Octreeç¼–ç æ³•</p>
<p>ä½œç”¨ï¼šå°†ä½“ç´ ç©ºé—´ç”¨octreeè¡¨ç¤ºï¼Œé‚£ä¹ˆå¯¹voxel gridçš„æ“ä½œå°±å¯ä»¥è½¬æ¢ä¸ºå¯¹octreeçš„æ“ä½œ</p>
<p>åŸºäºå“ˆå¸Œè¡¨çš„Octreeç¼–ç ï¼ˆå¯ä»¥å®ç°å¸¸æ•°æ—¶é—´çš„å…ƒç´ è·å–ï¼‰ï¼š</p>
<ul>
<li><p>Octree cellçš„ç©ºé—´åæ ‡$\mathtt{x}=(x,y,z)$ï¼Œå…¶åœ¨æ ‘ä¸­çš„å±‚çº§ï¼ˆåˆ†è¾¨ç‡ç­‰çº§ï¼‰ä¸º$l$ï¼Œå…¶å†…å®¹ä¸º$v$ã€‚</p>
</li>
<li><p>å°†å…¶è½¬æ¢ä¸ºç´¢å¼•$m=\mathcal{Z}(\mathtt{x},l)$ï¼Œå…¶ä¸­$\mathcal{Z}(\cdot)$æ˜¯Z-order curveã€‚</p>
</li>
<li><p>é‚£ä¹ˆå°±å½¢æˆäº†é”®å€¼å¯¹$(m,v)$ã€‚äºæ˜¯å…«å‰æ ‘å°±æ˜¯$O=\{(m,v)\}$</p>
</li>
</ul>
<p>é‚£ä¹ˆæ•°æ®æ“ä½œå’Œæ›´æ–°éƒ½åœ¨hash tableä¸­è¿›è¡Œã€‚</p>
<p>æŸ¥å€¼å‡½æ•°ï¼ˆä»å…«å‰æ ‘$O$ä¸­è·å–å€¼ï¼‰ï¼š</p>
<p><img src="3_2.png" alt></p>
</li>
<li><p>Octree Generating Networks</p>
<p>binary occupancy values $v=\{0,1\}$</p>
<p>ç”±æ™®é€š3Då·ç§¯ç”Ÿæˆ$d_1 \times d_2 \times d_3 \times c$å¤§å°çš„4D tensorï¼Œç„¶åè¢«è½¬æ¢æˆoctreeï¼Œå¹¶å°†æ•°æ®å­˜å‚¨åœ¨hash tableä¸­ã€‚</p>
<p><img src="3_4.png" alt></p>
<p>å›¾ä¸­ä¸ºäº†ç¤ºæ„çš„ç®€ä¾¿èµ·è§ï¼Œç”¨2D voxelæ›¿ä»£3D voxelæ¥å±•ç¤ºã€‚</p>
<p>propagated featuresæ˜¯æŒ‡éœ€è¦å¤„ç†æˆ–ç»†åˆ†çš„ç½‘æ ¼ç‰¹å¾</p>
<p>emptyæ˜¯æŒ‡ä¸æ˜¯å®ä½“çš„ç½‘æ ¼</p>
<p>filledæ˜¯æŒ‡è¢«å æ®ã€æ˜¯å®ä½“çš„ç½‘æ ¼</p>
<p>mixedæ˜¯æŒ‡éœ€è¦ç»†åˆ†çš„ç½‘æ ¼ï¼ˆä¸GTç›¸æ¯”æ—¢æœ‰emptyåˆæœ‰filledï¼‰</p>
<ul>
<li><p>OGN-Conv</p>
<p>OGN-Convéœ€è¦å¤„ç†ç”±å“ˆå¸Œè¡¨è¡¨ç¤ºçš„ç‰¹å¾å›¾ã€‚OGN-Convæ”¯æŒæ­¥é•¿å·ç§¯å’Œä¸Šé‡‡æ ·å·ç§¯ã€‚</p>
<p>åŸºæœ¬åŸç†ï¼ˆç±»ä¼¼äºâ€œim2colâ€å’Œâ€œcol2imâ€å‡½æ•°ï¼‰ï¼šå°†hash tableè½¬å˜ä¸ºfeature matrixï¼Œç„¶åä¸æƒé‡çŸ©é˜µç›¸ä¹˜ï¼Œå†å¤åŸå›hash table</p>
</li>
<li><p>OGN-Loss</p>
<p>predictionså°±æ˜¯åˆ¤æ–­voxelæ˜¯empty/filled/mixedä¸­çš„å“ªç§ï¼Œæ˜¯3åˆ†ç±»é—®é¢˜ã€‚ç”¨$1^3$å·ç§¯å’Œsoftmaxå®ç°å³å¯ã€‚</p>
<p>æœ€å°åŒ–predictionsä¸the cell state of the ground truthçš„äº¤å‰ç†µï¼š</p>
<p><img src="3_5.png" alt></p>
<p>$p_m^i$æ˜¯è¾“å‡ºæ¦‚ç‡å€¼ï¼Œ$M_l$æ˜¯ç¬¬$l$å±‚çš„å¶å­é›†åˆã€‚é‚£ä¹ˆæ€»ç›®æ ‡å‡½æ•°å°±æ˜¯å…¨éƒ¨å±‚çš„$\mathcal{L_l}$çš„æ±‚å’Œã€‚</p>
</li>
<li><p>OGN-Prop</p>
<p>å°†é¢„æµ‹å‡ºæ¥æ˜¯â€œmixedâ€çš„å–å‡ºæ¥ä½œä¸ºè¾“å‡ºã€‚å¯èƒ½è¿˜è¦å–å‡ºä¸€äº›å…¶ä»–çš„é‚»å±…ï¼Œä»¥ä¾¿ç”¨äºæ¥ä¸‹æ¥çš„å·ç§¯è®¡ç®—ã€‚</p>
<p>æ ¹æ®åœ¨æµ‹è¯•é˜¶æ®µæ˜¯å¦çŸ¥é“Octreeçš„GTï¼Œä¼ æ’­æ–¹å¼åˆ†ä¸ºï¼šProp-Knownæ–¹æ³•ï¼ˆä¾‹å¦‚è¯­ä¹‰åˆ†å‰²ï¼Œç»“æ„ä¸å˜ï¼Œåªéœ€è¦ä¸GTåšå¯¹æ¯”å³å¯ï¼‰å’ŒProp-Predæ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‰ç»´é‡å»ºï¼Œç»“æ„éœ€è¦ä½ é¢„æµ‹ï¼Œéœ€è¦è®­ç»ƒåˆ†ç±»æ¨¡å‹æ¥åˆ¤æ–­æ¯ä¸ªvoxelæ˜¯empty/filled/mixedä¸­çš„å“ªç§ï¼‰ã€‚ä¸è¯¦è¿°ã€‚</p>
</li>
</ul>
</li>
</ol>
<h2 id="MarrNet"><a href="#MarrNet" class="headerlink" title="MarrNet"></a>MarrNet</h2><blockquote>
<p>NIPS2017ã€ŠMarrNet: 3D Shape Reconstruction via 2.5D Sketchesã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="http://papers.nips.cc/paper/6657-marrnet-3d-shape-reconstruction-via-25d-sketches" target="_blank" rel="noopener">http://papers.nips.cc/paper/6657-marrnet-3d-shape-reconstruction-via-25d-sketches</a></p>
</blockquote>
<h3 id="æ¦‚è¿°-3"><a href="#æ¦‚è¿°-3" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>ä»å•å¼ å›¾ç‰‡é‡æ„å‡º3D voxel-based reconstructionã€‚ä»RGBå›¾å¾—åˆ°2.5Dè¡¨ç¤ºï¼Œå†è½¬æ¢æˆ3Då½¢çŠ¶ï¼ˆtwo-stepï¼‰ã€‚MarrNetå¯ä»¥åœ¨synthetic dataæ•°æ®ä¸Šè®­ç»ƒç„¶ååœ¨real dataä¸Šè¿›è¡Œself-supervisedçš„fine-tuneï¼ˆä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†domain adaptationé—®é¢˜ï¼‰ã€‚MarrNetæ˜¯end-to-endçš„å¯è®­ç»ƒæ¨¡å‹ï¼Œè¾¾åˆ°äº†SOTAã€‚</p>
<p>2D â†’ 2.5D â†’ 3Dçš„ä¼˜ç‚¹ï¼š</p>
<ul>
<li>First, compared to full 3D shape, 2.5D sketches are much easier to be recovered from a 2D image; models that recover 2.5D sketches are also more likely to transfer from synthetic to real data.</li>
<li>Second, for 3D reconstruction from 2.5D sketches, systems can learn purely from synthetic data.</li>
<li>Third, we derive differentiable projective functions from 3D shape to 2.5D sketches; the framework is therefore end-to-end trainable on real images, requiring no human annotations</li>
</ul>
<p>æ³¨ï¼š</p>
<ul>
<li>å–åMarrNetæ˜¯å› ä¸ºä¸David Marrâ€™s theory of perceptionç›¸è¿‘</li>
<li>intrinsic imagesï¼ˆæè¿°ç‰©ä½“å†…åœ¨å›ºæœ‰å±æ€§çš„å¯åˆ†ç¦»çš„æœ¬è´¨å›¾åƒï¼‰ï¼šä¾‹å¦‚depthã€surface normalsã€silhouetteç­‰ç­‰</li>
<li>Reprojection Consistencyåªåœ¨fine-tuneä¸­ä½¿ç”¨ï¼›é¢„è®­ç»ƒä½¿ç”¨ä¸GT voxel girdæ¯”è¾ƒçš„äº¤å‰ç†µã€‚</li>
<li>æœ¬æ–‡å®šæ€§åˆ†æï¼ˆå›¾ç‰‡å±•ç¤ºï¼‰æ¯”è¾ƒå¤šï¼Œå®šé‡åˆ†ææ¯”è¾ƒå°‘ï¼ˆåªæœ‰äººç±»è‚‰çœ¼æ¯”è¾ƒç»“æœå’Œä¸€ä¸ªIoUç»“è®ºï¼‰</li>
<li>æˆ‘æ„Ÿè§‰æœ¬æ–‡çš„ablation studyè¯´æœåŠ›ä¸è¶³ï¼Œå³ä¸èƒ½è¯´æ˜fine-tuneæ˜¯æœ‰æ•ˆçš„ï¼Œå¹¶ä¸èƒ½è¯´æ˜Reprojection Consistencyçš„è®¾è®¡æ˜¯èµ·åˆ°å®é™…ä½œç”¨çš„ã€‚è¯¦è§å®éªŒçš„ç¬¬äºŒéƒ¨åˆ†ã€‚</li>
</ul>
<h3 id="åŸç†-2"><a href="#åŸç†-2" class="headerlink" title="åŸç†"></a>åŸç†</h3><p><img src="4_1.png" alt></p>
<p>ç”¨2D CNNçš„æ–¹æ³•ç”Ÿæˆ2.5Då›¾ï¼Œç„¶åå°†2.5Då›¾ç”¨encoder-decoderæ–¹æ³•ç”Ÿæˆä½“ç´ è¡¨ç¤ºã€‚ç”¨reprojection consistency lossç¡®ä¿3Dä¸2.5DåŒ¹é…ã€‚</p>
<h3 id="å®ç°-3"><a href="#å®ç°-3" class="headerlink" title="å®ç°"></a>å®ç°</h3><ol>
<li><p>2.5D Sketch Estimation</p>
<p>ç”¨encoder-decoderç»“æ„ç”Ÿæˆ2.5Dè¡¨ç¤ºã€‚ç”¨ResNet-18ç¼–ç ï¼Œå°†256x256çš„RGBè½¬å˜ä¸º8x8x256çš„ç‰¹å¾å›¾ã€‚ç„¶åç”¨decoderæ¢å¤æˆ256x256çš„depth, surface normal, and silhouette images</p>
</li>
<li><p>3D Shape Estimation</p>
<p>ç”¨encoder-decoderç»“æ„ç”Ÿæˆ3Dä½“ç´ ã€‚è¾“å…¥depthå’Œnormalå›¾ï¼ˆæ–½åŠ ä»¥silhouette imagesæ©è†œï¼‰ï¼Œç„¶åç”¨å·ç§¯è½¬å˜ä¸º200ç»´å‘é‡ï¼Œç„¶åç”¨3Då·ç§¯ç”Ÿæˆ128x128x128çš„ä½“ç´ è¡¨ç¤ºã€‚</p>
</li>
<li><p>Reprojection Consistency</p>
<p>ä½¿å¾—3Dè¡¨ç¤ºä¸2.5Dè¡¨ç¤ºç›¸ä¸€è‡´ï¼Œå³å°†2.5DæŠ•å°„åˆ°3Dç©ºé—´ä¸­ï¼Œä½“ç´ ä¹Ÿéœ€è¦å…·æœ‰ä¸2.5Dçš„æè¿°ç›¸ä¸€è‡´çš„æ€§è´¨ã€‚reprojection consistency lossåˆ†ä¸ºdepth reprojection losså’Œsurface normal reprojection lossã€‚å¹¶ä¸”reprojection consistency losså¯¹voxelå¯æ±‚å¯¼ï¼Œä½¿å¾—å¯ä»¥ç”¨åå‘ä¼ æ’­è®¡ç®—å’Œä¼˜åŒ–ã€‚</p>
<p>è®°3D voxel gridåœ¨$(x,y,z)$å¤„å­˜åœ¨è¯¥voxelçš„æ¦‚ç‡ä¸º$v_{x,y,z}\in[0,1]$ï¼Œæ·±åº¦å›¾åœ¨$(x,y)$å¤„çš„å€¼ä¸º$d_{x,y}$ï¼Œæ³•å‘å›¾åœ¨$(x,y)$å¤„çš„æ³•å‘ä¸º$n_{x,y}=(n_a,n_b,n_c)$ã€‚å¹¶ä¸”å‡è®¾æ˜¯<strong>æ­£äº¤æŠ•å½±</strong>ï¼ˆæ³¨æ„è¿™é‡Œä¸æ˜¯ç›¸æœºæˆåƒçš„æŠ•å½±æ¨¡å‹ï¼‰</p>
<p><img src="4_3.png" alt></p>
<ul>
<li><p>depth reprojection lossçš„ç›®æ ‡æ˜¯ï¼šå°†depth imageçš„pointæŠ•å½±åˆ°3Dä¸­ï¼Œä½¿å¾—è¿™ä¸ª3D pointæ°å¥½å‡ºç°åœ¨3D voxel reconstructionä¸­ï¼Œå¹¶ä¸”è¯¥ç‚¹çš„è§†çº¿å‰æ–¹æ— é®æŒ¡ã€‚</p>
<p><img src="4_2.png" alt></p>
</li>
<li><p>surface normal reprojectionçš„ç›®æ ‡æ˜¯ï¼šä½¿å¾—è¯¥ç‚¹åœ¨3Dåˆ‡å¹³é¢ä¸Šçš„é‚»å±…å­˜åœ¨</p>
<p>å·²çŸ¥æ³•å‘$n_{x,y}=(n_a,b_b,n_c)$å¿…å®šä¸$n_xâ€™=(0,-1,n_b/n_c)$ã€$n_yâ€™=(-1,0,n_a/n_c)$å‚ç›´ã€‚é‚£ä¹ˆvoxelåœ¨$(x,y,z)\pm n_xâ€™$å’Œ$(x,y,z)\pm n_yâ€™$çš„å€¼å¿…å®šä¸º1ï¼ˆå½“è¿™äº›ç‚¹åœ¨silhouette imageä»¥å†…æ—¶æ‰ç®—ï¼‰ã€‚</p>
<p><img src="4_4.png" alt></p>
</li>
</ul>
</li>
<li><p>Training paradigm</p>
<p>å°†â€œ2.5D sketch estimationâ€å’Œâ€œ3D shape estimationâ€åˆ†åˆ«åœ¨synthetic imagesä¸Šé¢„è®­ç»ƒï¼šThe 3D interpreter is trained using ground truth voxels and a <strong>cross-entropy loss</strong>ï¼ˆæ³¨æ„é¢„è®­ç»ƒæ˜¯ç”¨ä¸GTæ¯”è¾ƒçš„äº¤å‰ç†µï¼ï¼‰</p>
<p>ç„¶åå†åœ¨çœŸå®å›¾ç‰‡ä¸Šfine-tuneï¼šThe <strong>reprojection consistency loss</strong> is used to fine-tune the 3D estimation component of our model on real images, using the predicted normal, depth, and silhouetteã€‚å›ºå®šdecoder of the 3D estimatorï¼ˆå› ä¸ºå®ƒåŒ…å«äº†3Då½¢çŠ¶çš„å…ˆéªŒï¼Œä¸å¸Œæœ›æ”¹å˜ï¼‰ï¼Œåªfine-tune the encoderï¼ˆå­¦ä¹ æ˜ å°„åˆ°decoderåˆç†çš„ç‰¹å¾ç©ºé—´ä¸­ï¼‰ã€‚è¿™ç§fine-tuneç±»ä¼¼è‡ªç›‘ç£ï¼Œå¯ä»¥åœ¨æ— ä»»ä½•æ ‡æ³¨çš„å•å¼ æµ‹è¯•å›¾ç‰‡ä¸Šè¿›è¡Œfine-tuneã€‚</p>
</li>
</ol>
<h3 id="å®éªŒ-1"><a href="#å®éªŒ-1" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><ol>
<li><p>3D Reconstruction on ShapeNet</p>
<p>ç”Ÿæˆçš„å½¢çŠ¶å…·æœ‰smoother surfaces and finer details</p>
<p>Our full model achieves a higher IoU (0.57) than the direct prediction baseline (0.52).</p>
<p>direct prediction baselineï¼šä¸ç»è¿‡2.5Dè¡¨ç¤ºï¼Œç›´æ¥åŸºäº3Då·ç§¯çš„ä½“ç´ ç”Ÿæˆ</p>
</li>
<li><p>3D Reconstruction on Pascal 3D+</p>
<p>ç°åœ¨ShapeNetä¸Šé¢„è®­ç»ƒï¼Œç„¶åfine-tune them on the PASCAL 3D+ dataset</p>
<p><img src="4_5.png" alt></p>
<p>ä¸Šå›¾çš„ablation studyè¡¨æ˜ï¼Œéœ€è¦å›ºå®šdecoder of the 3D estimatorè¿›è¡Œfine-tuneæ‰èƒ½å–å¾—æ›´å¥½çš„fine-tuneæ•ˆæœã€‚</p>
<p>ä½†æ„Ÿè§‰æœ¬æ–‡çš„ablation studyè¯´æœåŠ›ä¸è¶³ï¼Œæ–‡ä¸­è¯´The model trained on synthetic data provides a reasonable shape estimateå’ŒOur final model, fine-tuned with the decoder fixed, keeps the shape prior and provides more details of the shapeï¼Œè¿™åªæ˜¯ä½œè€…è‡ªå·±çš„è§‚ç‚¹ï¼Œå¹¶æ²¡æœ‰æ•°æ®æ”¯æ’‘ï¼Œå¹¶ä¸”â€œhuman studiesâ€ä¸­å¹¶æ²¡æœ‰fine-tuneå‰åçš„â€œpreferencesâ€å¯¹æ¯”ï¼Œå¹¶ä¸èƒ½è¯´æ˜fine-tuneæ˜¯æœ‰æ•ˆçš„ï¼Œå³å¹¶ä¸èƒ½è¯´æ˜Reprojection Consistencyçš„è®¾è®¡æ˜¯æœ‰ä½œç”¨çš„ã€‚</p>
<p>ä½œè€…è®¤ä¸ºIoUæŒ‡æ ‡ä¸å¥½ï¼Œä¸èƒ½æè¿°ç²¾ç»†ç»“æ„ç­‰ï¼Œæå‡ºâ€œhuman studiesâ€ï¼Œå³äººç±»è‚‰çœ¼æ¯”è¾ƒMarrNetå’Œç«äº‰å¯¹æ‰‹DRCå“ªä¸ªæ•ˆæœæ¯”è¾ƒå¥½ã€‚æ•ˆæœå½“ç„¶æ˜¯è¯´MarrNetæ¯”è¾ƒå¥½å•¦ã€‚</p>
<p><img src="4_6.png" alt></p>
<p>MarrNetä¸èƒ½å¤åŸå¤æ‚çš„ã€ç»†å¼±çš„ç»“æ„ï¼Œè€Œä¸”silhouette maskä¸èƒ½ç²¾ç¡®ä¼°è®¡ã€‚</p>
</li>
<li><p>3D Reconstruction on IKEA</p>
<p>IKEA furnitureæ•°æ®é›†ï¼Œour model can deal with mild occlusions in real life scenarios</p>
</li>
<li><p>Extensions</p>
<p>We further train MarrNet jointly on all three object categories, and our model successfully recovers shapes of different categories</p>
</li>
</ol>
<h2 id="LSM"><a href="#LSM" class="headerlink" title="LSM"></a>LSM</h2><blockquote>
<p>NIPS2017ã€ŠLearning a Multi-View Stereo Machineã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="http://papers.nips.cc/paper/6640-learning-a-multi-view-stereo-machine" target="_blank" rel="noopener">http://papers.nips.cc/paper/6640-learning-a-multi-view-stereo-machine</a></p>
</blockquote>
<h3 id="æ¦‚è¿°-4"><a href="#æ¦‚è¿°-4" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>åˆ©ç”¨nå¹…å›¾åƒï¼ˆnâ‰¥1ï¼‰ä»¥åŠè¿™äº›æ‘„åƒæœºçš„å†…å¤–å‚ï¼ˆcamera posesï¼‰ï¼Œæ±‚å‡ºç‰©ä½“çš„ä½“ç´ é‡å»ºï¼ˆVoxel LSMï¼‰æˆ–ç›¸åº”çš„nå¹…æ·±åº¦å›¾ï¼ˆDepth LSMï¼‰ã€‚LSMç«¯åˆ°ç«¯å¯å¾®åˆ†ã€‚æ ¸å¿ƒæ€æƒ³ï¼šåˆ©ç”¨æŠ•å°„å…³ç³»å°†2Dæ’åˆ—çš„ç‰¹å¾ä¸3Dæ’åˆ—çš„ç‰¹å¾ç›¸äº’è½¬æ¢ï¼Œä¸”èƒ½æ­¤è¿‡ç¨‹å¯å¾®åˆ†ï¼Œä½¿å…¶åˆ©ç”¨äº†ç©ºé—´æŠ•å½±å…³ç³»çš„å‡ ä½•å…ˆéªŒã€‚</p>
<p>æ³¨ï¼š</p>
<ul>
<li>å¤šè§†è§’ç«‹ä½“è§†è§‰ï¼ˆMulti-view stereopsisï¼Œç®€ç§°MVSï¼‰ï¼šç»™å®šç‰©ä½“çš„å¤šå¹…å›¾åƒã€è¿™äº›å›¾åƒæ‰€åˆ†åˆ«æ‹æ‘„çš„æ‘„åƒæœºçš„å§¿æ€ï¼ˆå†…å‚å’Œå¤–å‚ï¼‰ï¼Œè¯•æ±‚ç‰©ä½“çš„å‡ ä½•è¡¨ç¤ºï¼ˆ3Dç»“æ„/æ·±åº¦å›¾ç­‰ï¼‰</li>
<li>LSM == Learnt Stereo Machine</li>
<li>our system is able to better use camera pose information leading to significantly large improvements while adding more viewsï¼ˆç„¶è€Œå¯¹æ¯”çš„ç½‘è·¯ï¼ˆ3D-R2N2ï¼‰æ˜¯add pose information in a fully connected mannerï¼Œå¹¶æ²¡æœ‰ä¸“é—¨å¯¹æ­¤è®¾è®¡è¿‡ï¼‰</li>
<li>å¯èƒ½ä½œè€…è°ƒå‚å’Œä¼˜åŒ–äº†å¾ˆä¹…ã€‚ã€‚ã€‚</li>
</ul>
<p>TODO IDEAï¼šå°†å‡ ä½•æŠ•å½±ç­‰å…³ç³»ç¼–ç ä¸”ä½¿å¾—å¯å¾®åˆ†ï¼Œä½¿å¾—å¯ä»¥åå‘ä¼ æ’­ã€‚</p>
<h3 id="å®ç°-4"><a href="#å®ç°-4" class="headerlink" title="å®ç°"></a>å®ç°</h3><p><img src="5_1.png" alt></p>
<p>ç®€è¿°ï¼šè¾“å…¥nå¹…å›¾åƒï¼Œç„¶åç»è¿‡2D CNNç‰¹å¾æå–å‡º2Dçš„ç‰¹å¾å›¾ã€‚å†åˆ†åˆ«ä½¿ç”¨â€œunprojectionâ€æ“ä½œå¾—åˆ°3Dæ’åˆ—çš„ä½“ç‰¹å¾$\mathcal{G}^f_i$ã€‚ç„¶åä½¿ç”¨RNNå°†å…¶å…¨éƒ¨æ•´åˆæˆä¸€ä¸ªä½“ç‰¹å¾$\mathcal{G}^p$ã€‚å†å°†å…¶ç”¨3Då·ç§¯å¾—åˆ°$\mathcal{G}^o$ã€‚å¦‚æœæƒ³å¾—åˆ°ä½“ç´ è¡¨ç¤ºï¼Œåˆ™ç›´æ¥ä½¿ç”¨3Då·ç§¯ç”Ÿæˆå³å¯ï¼›å¦‚æœæƒ³å¾—åˆ°ç›¸åº”çš„æ·±åº¦å›¾ï¼Œåˆ™ä½¿ç”¨â€œprojectionâ€æ“ä½œè½¬æ¢ä¸º2Dç‰¹å¾å›¾ä¹‹åå†ä½¿ç”¨2Då·ç§¯ä¸Šé‡‡æ ·å³å¯ã€‚</p>
<ol>
<li><p>2D Image Encoder</p>
<p>ç”¨UNetç”Ÿæˆç‰¹å¾å›¾ã€‚ä»å›¾åƒ$\{I_i\}^n_{i=1}$è½¬å˜ä¸ºç‰¹å¾å›¾$\{\mathcal{F}_i\}^n_{i=1}$</p>
</li>
<li><p>Differentiable Unprojection</p>
<p>è¾“å…¥ç‰¹å¾å›¾å’Œç›¸æœºå§¿æ€ï¼Œè¾“å‡º3Dæ’åˆ—çš„ç‰¹å¾ã€‚</p>
<p>å³ä»ç‰¹å¾å›¾$\{\mathcal{F}_i\}^n_{i=1}$è½¬å˜ä¸º3D gird$\{\mathcal{G}_i^f\}^n_{i=1}$</p>
<p><img src="5_2.png" alt></p>
<p>ä¸Šå›¾åªæ˜¯æ–¹ä¾¿å›¾ç¤ºè€Œå·²ï¼Œå®é™…ä¸Šæ˜¯3D girdå’Œ2D feature mapã€‚</p>
<p>å®é™…å®ç°è¿‡ç¨‹ï¼šå°†3D gird centeræŠ•å½±åˆ°image planeå¾—åˆ°è¿ç»­çš„åæ ‡ï¼Œç„¶åæ ¹æ®discrete gridçš„feature valueç”¨bilinear samplingæ’å€¼å¾—åˆ°è¯¥3D girdçš„feature</p>
<p>ä¸ºäº†å¯ä»¥æ”¯æŒå•å¼ å›¾ç‰‡è¾“å…¥ï¼Œæˆ‘ä»¬è¿˜å¾€æ¯ä¸ª3D girdä¸­æ·»åŠ å‡ ä½•ç‰¹å¾ï¼ˆä¾‹å¦‚depth valueå’Œray directionï¼‰</p>
<p>è¿™ä¸ªè¿‡ç¨‹æ˜¯å¯å¾®åˆ†çš„ï¼Œä½¿å¾—å¯ä»¥ç«¯åˆ°ç«¯è®­ç»ƒã€‚</p>
</li>
<li><p>Recurrent Grid Fusion</p>
<p>ä»å¤šä¸ª3D gird$\{\mathcal{G}_i^f\}^n_{i=1}$åˆ°å•ä¸ª$\mathcal{G^p} $</p>
<p>ä½¿ç”¨3D convolutional variant of the Gated Recurrent Unit (GRU)ï¼Œç±»ä¼¼äº3D-R2N2ä¸­çš„åšæ³•ã€‚</p>
<p>è®­ç»ƒæ—¶éšæœºæ‰“ä¹±è¾“å…¥çš„é¡ºåºï¼Œå‡å°è¾“å…¥é¡ºåºå¸¦æ¥çš„å½±å“ã€‚</p>
</li>
<li><p>3D Grid Reasoning</p>
<p>å°†$\mathcal{G^p} $è½¬å˜ä¸º$\mathcal{G^o} $</p>
<p>ä½¿ç”¨3D UNetã€‚ç›®çš„ï¼ˆæ„Ÿè§‰ä¹±è¯´ã€‚ã€‚ï¼‰ï¼šuse shape cues present in $\mathcal{G^p} $ such as feature matches and silhouettes as well as build in shape priors like smoothness and symmetries and knowledge about object classes enabling it to produce complete shapes even when only partial information is visible</p>
</li>
<li><p>Differentiable Projection</p>
<p>ä»$\mathcal{G^o}$è½¬å˜ä¸ºå¤šä¸ª2D feature map$\{\mathcal{O}_i\}^n_{i=1}$</p>
<p>è¾“å…¥ï¼š$\mathcal{G^o}$å’Œç›¸æœºå§¿æ€ã€‚è¾“å‡ºï¼š2D feature map$\mathcal{O}$</p>
<p><img src="5_3.png" alt></p>
<p>ä¸Šå›¾åªæ˜¯æ–¹ä¾¿å›¾ç¤ºè€Œå·²ï¼Œå®é™…ä¸Šæ˜¯3D girdå’Œ2D feature mapã€‚</p>
<p>å®é™…å®ç°è¿‡ç¨‹ï¼šæœ‰å¤šä¸ªå¹³è¡Œäºç›¸æœºå¹³é¢çš„ç­‰é—´è·å¹³é¢ï¼ˆå›¾ä¸­çš„z=1,2,3å¹³é¢ï¼‰ï¼Œè§†çº¿rayæ˜¯ç©¿è¿‡2D feature mapçš„ç¦»æ•£æ ¼ç‚¹ä¸­å¿ƒçš„ã€‚ç”±æ­¤æ¨ªç©¿ç»è¿‡çš„3D girdçš„ç‰¹å¾å€¼å°±ä½œä¸ºç‰¹å¾å€¼ã€‚åœ¨3D girdä¸­æ˜¯nearest neighbor interpolationè€Œä¸æ˜¯trilinear interpolationã€‚è¯¦æƒ…è§ä¸Šå›¾ã€‚</p>
<p>æœ€åä½¿ç”¨1x1çš„å·ç§¯å¯ä»¥å‡å°‘channelsçš„æ•°é‡ã€‚</p>
</li>
<li><p>Architecture Details and Experiments</p>
<p>å·ç§¯å‡ä½¿ç”¨instance normalizationå’Œlayer normalization</p>
<ul>
<li><p>Voxel LSM (VLSM)ï¼šæœ€åä½¿ç”¨3Då·ç§¯ä¸Šé‡‡æ ·ã€‚softmax + binary cross entropy loss</p>
</li>
<li><p>Depth LSM (D-LSM)ï¼šä½¿ç”¨Projectionå°†$\mathcal{G^o}$è½¬å˜ä¸ºå¤šä¸ª2D feature map$\{\mathcal{O}_i\}^n_{i=1}$ï¼Œç„¶ååˆ†åˆ«è¿›è¡Œ1x1å·ç§¯å’Œdeconvolutionä¸Šé‡‡æ ·ï¼Œå…¶ä¸­deconvolutionæœ‰skip connectionsæ¥è‡ªä¹‹å‰çš„image encoderã€‚</p>
</li>
</ul>
<p>Experimentsæ€§èƒ½ï¼š</p>
<p><img src="5_4.png" alt></p>
</li>
</ol>
<h2 id="IM-NET-ğŸ‘"><a href="#IM-NET-ğŸ‘" class="headerlink" title="IM-NET ğŸ‘"></a>IM-NET ğŸ‘</h2><blockquote>
<p>CVPR2019ã€ŠLearning Implicit Fields for Generative Shape Modelingã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Implicit_Fields_for_Generative_Shape_Modeling_CVPR_2019_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Implicit_Fields_for_Generative_Shape_Modeling_CVPR_2019_paper.html</a></p>
</blockquote>
<h3 id="æ¦‚è¿°-5"><a href="#æ¦‚è¿°-5" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>ä½¿ç”¨éšå¼åœºçš„æ–¹æ³•æ¥ç”Ÿæˆ3Dç‚¹äº‘ï¼Œåå¤„ç†åçš„å½¢æˆçš„meshå…·æœ‰superior visual qualityï¼ˆhigher surface qualityï¼‰ã€‚å¹¶åœ¨æ’å€¼æ—¶è¡¨ç°å‡ºè‰¯å¥½çš„è¿‡åº¦æ€§è´¨ã€‚æ‰€ä½¿ç”¨çš„implicit field decoderç§°ä½œIM-NETï¼Œå¯ä»¥ç”¨äº3Då½¢çŠ¶è‡ªç¼–ç ï¼ˆå³shape representation learningï¼‰ï¼ˆIM-AEï¼‰ã€å½¢çŠ¶ç”Ÿæˆï¼ˆIM-GANï¼‰ã€å½¢çŠ¶æ’å€¼ã€å•è§†å›¾3Dé‡å»ºç­‰ã€‚å…¶ä¸­encoderä¸å±äºæœ¬æ–‡è®¾è®¡èŒƒç•´ï¼Œåªè¦èƒ½å¾—åˆ°shape featureçš„éƒ½å¯ä»¥ã€‚</p>
<p>æ³¨ï¼š</p>
<ul>
<li>Our work is the first to introduce a deep network for learning implicit fields for generative shape modeling</li>
<li>ç¼ºç‚¹ï¼šè®­ç»ƒæ—¶é—´é•¿ï¼ˆå› ä¸ºthe decoder needs to be applied on each point in the training setï¼‰ï¼Œæˆ–è®¸å¯ä»¥è€ƒè™‘åªç”Ÿæˆç‰©ä½“è¡¨é¢çš„ç‚¹æ¥æé«˜é€Ÿåº¦</li>
</ul>
<p>TODO IDEAï¼šåæœŸå¯ä»¥è€ƒè™‘ç”¨decoderæ¥ç”Ÿæˆå…¶ä»–çš„å±æ€§ï¼Œä¾‹å¦‚é¢œè‰²ã€çº¹ç†ç­‰ã€‚æˆ–è®¸è¿˜å¯ä»¥ç”¨æ¥åšpart segmentation</p>
<h3 id="åŸç†-3"><a href="#åŸç†-3" class="headerlink" title="åŸç†"></a>åŸç†</h3><p>decoderçš„å…³é”®æ˜¯æ€ä¹ˆæ ¹æ®shape featureå¾—åˆ°å‡º3Dæ•°æ®ï¼ˆç‚¹äº‘ï¼‰ã€‚è¿™é€šè¿‡åˆ¤æ–­ç»™å®šç‚¹$p$æ˜¯å¤„äºshapeçš„å†…éƒ¨è¿˜æ˜¯å¤–éƒ¨æ¥å®ç°çš„ï¼Œé‚£ä¹ˆä¸­é—´çš„åˆ†ç•Œç­‰å€¼é¢å°±æ˜¯shapeçš„è¾¹ç•Œã€‚</p>
<p><img src="6_1.png" alt></p>
<p>æ„é€ ä¸€ä¸ªMLPï¼Œè¾“å…¥æ˜¯shape featureå’Œpoint coordinateï¼Œè¾“å‡ºæ˜¯åˆ¤æ–­å†…å¤–éƒ¨çš„äºŒåˆ†ç±»ï¼ˆsigmoidå‡½æ•°ï¼‰ã€‚</p>
<p><img src="6_2.png" alt></p>
<p>å…¶ä¸­è¾“å…¥çš„point coordinateå¯¹ç©ºé—´çš„å‡åŒ€é‡‡æ ·å¾—åˆ°çš„ï¼Œå› è€Œè¾“å‡ºå½¢çŠ¶çš„åˆ†è¾¨ç‡å¯ä»¥ä»»æ„é«˜ã€‚</p>
<p>The skip connectionsï¼ˆcopy and concatenateï¼‰å¯ä»¥ä½¿è®­ç»ƒç¨³å®šã€åŠ å¿«è®­ç»ƒã€‚</p>
<h3 id="å®ç°-5"><a href="#å®ç°-5" class="headerlink" title="å®ç°"></a>å®ç°</h3><ol>
<li><p>ç”¨decoder $f_\theta(p)$ä¸ºæ¯ä¸ªç‚¹$p$è®¡ç®—â€œæ˜¯å†…éƒ¨ç‚¹çš„æ¦‚ç‡â€ï¼ˆ$f_\theta(p):[0,1]^3 \rightarrow [0,1]$ï¼‰ï¼Œç„¶åè®¡ç®—ç­‰å€¼é¢ï¼ˆå¦‚3Då½¢çŠ¶åˆ™ä½¿ç”¨Marching Cubesæ–¹æ³•ï¼Œ2Då›¾åƒåˆ™ä½¿ç”¨applying thresholdingæ–¹æ³•ï¼‰ï¼Œä»è€Œå¾—åˆ°meshè¡¨ç¤ºã€‚å¯¹äºé—­åˆå½¢çŠ¶ï¼ŒGTä¸º$\mathcal{F}(p)$å†…éƒ¨å–1å¤–éƒ¨å–0ã€‚</p>
</li>
<li><p>decoderè®­ç»ƒæ–¹æ³•ï¼ˆå¯é‡‡å–çš„æ–¹æ³•æœ‰ä¸¤ç§ï¼‰ï¼ˆä½œè€…çš„å®ç°æ–¹å¼æ˜¯ä¸€ä¸ªdecoderåªå¯¹åº”ä¸€ä¸ªç‰©ä½“ç§ç±»ï¼‰ï¼š</p>
<ul>
<li>A naive samplingï¼šå°†è®­ç»ƒå½¢çŠ¶çš„ç©ºé—´ç¦»æ•£åŒ–ï¼ˆvoxelize or rasterizeï¼‰ï¼Œç„¶åå‡åŒ€é‡‡æ ·ã€‚å¤šåˆ†è¾¨ç‡é‡‡æ ·ä¾æ¬¡å¾—åˆ°$16^3,32^3,64^3,128^3$ä¸ªç‚¹ã€‚å…ˆç”¨ä½åˆ†è¾¨ç‡è®­ç»ƒå†é€æ¸ç”¨é«˜åˆ†è¾¨ç‡è®­ç»ƒï¼ˆtrain the model progressivelyï¼‰ã€‚å¤§è‡´æ˜¯ç«‹æ–¹å¤æ‚åº¦ã€‚</li>
<li>A more efficient approachï¼šé‡‡æ ·æ›´å¤šçš„é è¿‘è¡¨é¢çš„ç‚¹ï¼Œå¯¹ç¦»è¡¨é¢æ¯”è¾ƒè¿œçš„ç‚¹ä¸é‡‡æ ·ã€‚ç„¶åå¯¹é‡‡æ ·çš„æ¯ä¸ªç‚¹éƒ½æœ‰ä¸ªæƒé‡$w_p$ï¼Œæ˜¯è¯¥ç‚¹é‡‡æ ·å¯†åº¦çš„å€’æ•°ï¼Œç”¨ä»¥è¡¥å¿é‡‡æ ·å¯†åº¦çš„å˜åŒ–ã€‚å¤§è‡´æ˜¯å¹³æ–¹å¤æ‚åº¦ã€‚</li>
</ul>
</li>
<li><p>æŸå¤±å‡½æ•°ï¼ˆ$S$æ˜¯é‡‡æ ·å¾—åˆ°çš„ç‚¹é›†ï¼‰ï¼š</p>
</li>
</ol>
<script type="math/tex; mode=display">
\mathcal{L}(\theta)=\frac{\sum_{p \in S}|f_\theta(p)-\mathcal{F}(p)|^2 \cdot w_p}{\sum_{p \in S} w_p}</script><ol>
<li><p>IM-NETçš„åº”ç”¨ä¸¾ä¾‹</p>
<ul>
<li><p>Auto-Encodingï¼šä½¿ç”¨3Då·ç§¯ä»$64^3$çš„voxelsä¸­æå–128ç»´ç‰¹å¾ï¼Œç„¶ådecoderä½¿ç”¨IM-NETã€‚ä½¿ç”¨progressive trainingã€‚</p>
</li>
<li><p>3D shape generationï¼šä½¿ç”¨autoencoderä¸­è®­ç»ƒå¥½çš„encoderçš„è¾“å‡ºä½œä¸ºlatent-GANçš„è¾“å…¥</p>
</li>
<li><p>single-view 3D reconstructionï¼ˆSVRï¼‰ï¼šç”¨ResNetå°†$128\times128$çš„å›¾åƒç¼–ç æˆ128ç»´çš„ç‰¹å¾å‘é‡ã€‚ä½¿ç”¨autoencoderä¸­è®­ç»ƒå¥½çš„decoderï¼Œå›ºå®šå…¶å‚æ•°ä¸å˜ï¼Œåªè®­ç»ƒResNetçš„å‚æ•°ï¼ˆencoderï¼‰å»æœ€å°åŒ–mean squared loss</p>
</li>
</ul>
</li>
</ol>
<h3 id="å®éªŒ-2"><a href="#å®éªŒ-2" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><ol>
<li><p>è·å–point cloudä¹‹åï¼Œè½¬æ¢ä¸ºmeshï¼ˆå¦‚Marching Cubesæ–¹æ³•ï¼‰ï¼Œæœ€åç”¨Poisson-disk Samplingè·å–10000ä¸ªè¡¨é¢çš„ç‚¹ã€‚</p>
</li>
<li><p>ä½œè€…è§‰å¾—chamfer distanceï¼ˆCDï¼‰ã€mean squared errorï¼ˆMSEï¼‰ã€IoUå¹¶ä¸èƒ½å¾ˆå¥½çš„æè¿°ç‰©ä½“è¡¨é¢çš„è§†è§‰æ€§è´¨ï¼ˆä¾‹å¦‚æ¡Œå­é¢å‘ç”Ÿä¸€ç‚¹ç‚¹ä¸Šä¸‹çš„ç§»åŠ¨å°†å‰§çƒˆåœ°æ”¹å˜IoUçš„å€¼ï¼Œä½†æ˜¯è§†è§‰ä¸Šçš„æ•ˆæœå´å·®ä¸å¤šï¼›å¹¶ä¸”IoUæŒ‡æ ‡å¹¶ä¸æŠµåˆ¶è¡¨é¢çš„å‡¹å‡¸èµ·ä¼ï¼‰ï¼Œæå‡ºä½¿ç”¨è®¡ç®—æœºå›¾å½¢é¢†åŸŸçš„light field descriptorï¼ˆLFDï¼‰æŒ‡æ ‡ã€‚ä»¥åŠcoverage scoreï¼ˆCOV-LFDï¼‰ã€Minimum Matching Distanceï¼ˆMMD-LFDï¼‰æŒ‡æ ‡ã€‚</p>
</li>
<li><p>æ’å€¼æ•ˆæœ</p>
<p><img src="6_3.png" alt></p>
<p>ä¼˜ç‚¹ï¼šcleaner surface boundariesã€smooth part movementsã€handles topology changes</p>
<p>ä½†æ˜¯ä¸çŸ¥é“å¦‚ä½•æ§åˆ¶è¿™ç§å˜åŒ–çš„è¿‡ç¨‹</p>
</li>
</ol>
<h2 id="DISN-ğŸ‘"><a href="#DISN-ğŸ‘" class="headerlink" title="DISN ğŸ‘"></a>DISN ğŸ‘</h2><blockquote>
<p>NIPS2019ã€ŠDISN: Deep Implicit Surface Network for High-quality Single-view 3D Reconstructionã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="https://arxiv.org/abs/1905.10711" target="_blank" rel="noopener">https://arxiv.org/abs/1905.10711</a></p>
</blockquote>
<h3 id="æ¦‚è¿°-6"><a href="#æ¦‚è¿°-6" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>æå‡ºäº†ä¸€ç§å•è§†å›¾é‡å»ºçš„ç½‘ç»œï¼Œèƒ½ç”Ÿæˆé«˜è´¨é‡çš„3Då½¢çŠ¶ã€‚æ ¸å¿ƒæ˜¯é¢„æµ‹â€œsigned distance fieldâ€ã€‚ä¸ä»…ç»“åˆäº†â€œglobal image featuresâ€ï¼Œè¿˜ç»“åˆäº†â€œlocal features from the patchâ€ï¼Œå› è€Œèƒ½å¤Ÿç”Ÿæˆæ›´å¤šç»†èŠ‚çš„é«˜è´¨é‡3Då½¢çŠ¶ï¼ˆä¾‹å¦‚ç»†å°ç»“æ„ã€å­”æ´ï¼‰ã€‚åœ¨å•è§†å›¾é‡å»ºæ–¹é¢è¾¾åˆ°äº†SOTAã€‚ä½†æ˜¯åªèƒ½ç”¨äºå›¾ç‰‡èƒŒæ™¯å¹²å‡€çš„è¾“å…¥ã€‚</p>
<p>æ³¨ï¼š</p>
<ul>
<li>Signed Distance Functionsï¼ˆSDFï¼‰æ˜¯å±äºéšå¼çš„surfaceè¡¨ç¤ºï¼›ä¼ ç»Ÿçš„æ–¹æ³•æ˜¯æ˜¾å¼çš„surfaceè¡¨ç¤ºï¼ˆä¾‹å¦‚meshï¼‰</li>
<li>DISN == Deep Implicit Surface Network</li>
<li>åŸå§‹ç”Ÿæˆçš„3Då½¢çŠ¶æ˜¯ç‚¹äº‘ï¼Œç„¶åç”¨Marching Cubesæ–¹æ³•æ¥ç¡®å®šiso-surfaceï¼ˆä»¥è·å¾—3D meshï¼‰</li>
<li>ç¼ºç‚¹ï¼šè¦ç”Ÿæˆå¾ˆå¤š3D pointsæ‰èƒ½ç¡®å®šç­‰å€¼é¢ï¼ˆæœ€åéœ€è¦ä»dense 3D gridä¸­é‡‡æ ·æ ¼ç‚¹ä½œä¸ºè¾“å…¥ï¼‰ã€‚</li>
<li>ä¼˜ç‚¹ï¼šç”Ÿæˆçš„åˆ†è¾¨ç‡å¯ä»¥ä»»æ„é«˜</li>
<li>è¿˜å¯ä»¥æ‰©å±•åˆ°multi-view reconstructionå’Œshape interpolationåº”ç”¨ä¸­</li>
<li>å®ç°ç»†ç²’åº¦å¯èƒ½çš„åŸå› æ˜¯Local Featureæ˜¯ä»imagesä¸­çš„å¯¹åº”åŒºåŸŸæŠ ç‰¹å¾å­å›¾å®ç°çš„ã€‚Local Featureé¢„æµ‹å‡ºæ¥çš„SDFå€¼å¯ä»¥è®¤ä¸ºæ˜¯æ€»çš„SDFå€¼çš„æ®‹å·®ï¼Œæ®‹å·®å¯¹åº”â€œç»†ç²’åº¦/ç»†èŠ‚â€ã€‚</li>
</ul>
<p>TODO IDEAï¼š</p>
<ul>
<li>IDEA1ï¼šç”Ÿæˆç©ºé—´åˆ†å¸ƒï¼Œç„¶ååœ¨åˆ†å¸ƒä¸­é‡‡æ ·å¾—åˆ°ç‰©ä½“è¡¨é¢çš„ç‚¹ã€‚</li>
<li>IDEA2ï¼šä½¿ç”¨æ— ç¬¦å·çš„Distance Functionsï¼ˆè®°ä½œ$f(p)$ï¼‰ï¼Œç„¶åéšæœºåˆå§‹åŒ–ä¸€ä¸ª3ç»´ç©ºé—´ç‚¹$p\in \mathbb{R}^3$ï¼Œé€šè¿‡æ±‚è§£ä¼˜åŒ–é—®é¢˜$min_{p} \frac{\partial f(p)}{\partial p}$ï¼Œæ»¡è¶³æ­¤é—®é¢˜çš„è§£$p$ç»„æˆçš„ä¸€ç³»åˆ—çš„ç‚¹é›†å°±æ˜¯ç‰©ä½“çš„è¡¨é¢ã€‚ç›¸å½“äºç”¨å¯¼æ•°æ¥å¼•å¯¼pointåœ¨surfaceä¸Šçš„ç§»åŠ¨ã€‚è¿™æ ·ç†æƒ³æƒ…å†µä¸‹åªéœ€è¦åˆå§‹åŒ–ä¸€ä¸ªéšæœºç‚¹å°±èƒ½ä½¿å¾—è¯¥ç‚¹éå†æ•´ä¸ªsurfaceäº†ï¼ˆğŸ‘ï¼‰</li>
<li>IDEA3ï¼šèƒ½å¦å€Ÿé‰´U-Netçš„æ€æƒ³ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„ç»†ç²’åº¦SDFï¼Ÿ</li>
</ul>
<h3 id="åŸç†-4"><a href="#åŸç†-4" class="headerlink" title="åŸç†"></a>åŸç†</h3><p>Signed Distance Functionsï¼ˆSDFï¼‰æè¿°äº†ç©ºé—´æŸç‚¹åˆ°ç‰©ä½“è¡¨é¢çš„æœ‰ç¬¦å·è·ç¦»ã€‚</p>
<p>åœ¨ç‰©ä½“å¤–éƒ¨åˆ™ä¸ºæ­£å·ï¼Œå†…éƒ¨åˆ™ä¸ºç¬¦å·ï¼Œåœ¨ç‰©ä½“è¡¨é¢åˆ™ä¸ºé›¶ã€‚ç»å¯¹å€¼æ˜¯åˆ°è¡¨é¢çš„è·ç¦»ã€‚</p>
<p><img src="7_1.png" alt></p>
<p>ç„¶åé‡‡æ ·å¾ˆå¤šä¸ªç‚¹ï¼Œé€šè¿‡é¢„æµ‹SDFçš„å€¼ï¼Œå†ç”¨å¯»æ‰¾ç­‰å€¼é¢çš„æ–¹æ³•æ¥æ±‚å¾—è¡¨é¢ã€‚</p>
<h3 id="å®ç°-6"><a href="#å®ç°-6" class="headerlink" title="å®ç°"></a>å®ç°</h3><p>é¦–å…ˆä¼°è®¡ç›¸æœºå§¿æ€ï¼Œç›®çš„æ˜¯æŠŠ3Dç‚¹æŠ•å°„åˆ°2D planeä¸Šï¼Œç”¨ä»¥ç¡®å®š2D feature mapä¸Šlocal patchçš„ä½ç½®ã€‚ç„¶åå°†point-wise featureã€local featureã€global featureè”åˆèµ·æ¥æ¨æ–­SDFçš„å€¼ã€‚</p>
<p>æœ€åé‡‡æ ·dense 3D gridï¼Œä¸ºæ¯ä¸ªæ ¼ç‚¹é¢„æµ‹SDFå€¼ï¼Œç„¶åç”¨Marching Cubesè·å–3D meshã€‚</p>
<p>Local Featureæ˜¯ä»imagesä¸­çš„å¯¹åº”åŒºåŸŸæå–çš„ï¼Œpoint-wise featureç›´æ¥å°±æ˜¯MLPå¤„ç†ç‚¹åæ ‡ï¼Œglobal featureç›´æ¥å°±æ˜¯CNNå¤„ç†æ•´å¼ å›¾åƒã€‚</p>
<p>æ•´ä½“ç»“æ„ï¼ˆå›¾ä¸­çš„â€œ+â€å·æ˜¯åŠ æ³•ï¼Œä½œè€…å®éªŒè¡¨æ˜ä¸¤è·¯çš„æ¨æ–­ï¼ˆä¸¤ä¸ªdecoderï¼‰æ¯”ä¸€è·¯çš„æ¨æ–­ï¼ˆåªä½¿ç”¨ä¸€ä¸ªdecoderï¼‰æ•ˆæœè¦å¥½ï¼‰ï¼š</p>
<p><img src="7_2.png" alt></p>
<ol>
<li><p>Camera Pose Estimation</p>
<p><img src="7_3.png" alt></p>
<p>å°†è¾“å…¥å›¾ç‰‡ç”¨CNNæ¨æ–­å‡ºä½ç§»é‡$t$ï¼ˆTranslationï¼‰å’Œ6Dæ—‹è½¬è¡¨ç¤º$b$ï¼ˆRotationï¼‰ã€‚ç”±$b$å¯ä»¥ç”¨å…¬å¼è®¡ç®—å‡ºæ—‹è½¬çŸ©é˜µ$R$ï¼Œé‚£ä¹ˆç‚¹$p$çš„ç©ºé—´å˜æ¢å°±æ˜¯$Rp+t$ã€‚å¯¹aligned model spaceï¼ˆå³world spaceï¼‰æ–½åŠ ç©ºé—´å˜æ¢å¾—åˆ°â€œé¢„æµ‹çš„å˜æ¢ç‚¹äº‘â€ï¼Œå†ä¸GTæ¯”è¾ƒå°±å¯ä»¥è®¡ç®—å‡ºLossã€‚</p>
<p>Lossçš„è®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼ˆæœ¬è´¨æ˜¯mean squared errorï¼Œ$PC_w$ä»£è¡¨world spaceä¸­çš„ç‚¹äº‘ï¼Œ$p_G$ä»£è¡¨camera spaceä¸­çš„GTï¼‰ï¼š</p>
<p><img src="7_4.png" alt></p>
</li>
<li><p>SDF Prediction</p>
<ul>
<li><p>Point-wise featureï¼šç›®çš„æ˜¯å°†ä½ç½®å‘é‡æ˜ å°„åˆ°æ›´é«˜ç»´çš„ç©ºé—´ä¸­å»ï¼ˆå³å›¾ä¸­çš„â€œPoint featureâ€ï¼‰</p>
</li>
<li><p>Global featureï¼šåˆ©ç”¨CNNæ¨æ–­å…¨å±€çš„ç‰¹å¾å‘é‡</p>
</li>
<li><p>Local Featureï¼šåˆ©ç”¨ä¼°è®¡å‡ºæ¥çš„ç›¸æœºå‚æ•°å°†3Dç‚¹$p$æŠ•å°„åˆ°2D image planeçš„ç‚¹$q$å»ï¼Œç„¶åå°†ç›¸åº”ä½ç½®ä¸Šçš„ç‰¹å¾å­å›¾æŠ å‡ºæ¥å†concatï¼Œç”±æ­¤å¾—åˆ°local featureã€‚ï¼ˆå› ä¸ºç‰¹å¾å›¾å°ºå¯¸ä¸ä¸€æ ·ï¼Œæ‰€ä»¥å…ˆç”¨åŒçº¿æ€§æ’å€¼å†æŠ å›¾ï¼‰</p>
<p><img src="7_5.png" alt></p>
<p>é‚£ä¹ˆSDFçš„ç»“æœå°±æ˜¯ä¸¤ä¸ªdecoderè¾“å‡ºç»“æœçš„å’Œã€‚å¯ä»¥è®¤ä¸ºæ˜¯ä¸‹é¢è¿™ä¸ªdecoderåˆ†æ”¯æ˜¯ä¸€ç§â€œresidual SDFâ€ï¼Œå³ä¸€ç§æ®‹å·®é¢„æµ‹ç»“æ„ã€‚</p>
</li>
<li><p>Loss Functionsï¼šä½¿ç”¨åŠ æƒçš„æŸå¤±å‡½æ•°ï¼Œå«ä¹‰æ˜¯ä½¿å¾—æ›´çœ‹é‡GTè¡¨é¢é™„è¿‘çš„SDFä¼°è®¡è¯¯å·®ï¼ˆå…¶ä¸­$m_1&gt;m_2$ï¼‰</p>
<p><img src="7_6.png" alt></p>
</li>
</ul>
</li>
</ol>
<h3 id="å®éªŒ-3"><a href="#å®éªŒ-3" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><p>ä½¿ç”¨ShapeNetï¼Œå¹¶ä¸”train a single network on all categoriesï¼Œä½¿ç”¨VGG-16ä½œä¸ºCNNçš„æå–ç‰¹å¾ã€‚ä»¥CDã€EMDã€IoUä½œä¸ºæŒ‡æ ‡ã€‚ä¸å¤šç§æ¨¡å‹ï¼ˆå¦‚AtlasNet, Pixel2Mesh, 3DN, OccNet and IMNETï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œå–å¾—è¾ƒå¥½çš„æ€§èƒ½ã€‚è¯¦æƒ…ç•¥ã€‚</p>
<p><img src="7_7.png" alt></p>
<h2 id="Neural-Renderer"><a href="#Neural-Renderer" class="headerlink" title="Neural Renderer"></a>Neural Renderer</h2><blockquote>
<p>CVPR2018ã€ŠNeural 3D Mesh Rendererã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Kato_Neural_3D_Mesh_CVPR_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/html/Kato_Neural_3D_Mesh_CVPR_2018_paper.html</a></p>
</blockquote>
<h3 id="æ¦‚è¿°-7"><a href="#æ¦‚è¿°-7" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>å°†Rendererçš„æ¸²æŸ“è¿‡ç¨‹è¿‘ä¼¼å¯å¾®åŒ–ï¼Œä½¿å¾—æ¸²æŸ“å™¨ï¼ˆRendererï¼‰å¯ä»¥åµŒå…¥åˆ°ç¥ç»ç½‘ç»œç»“æ„ä¸­æ¥ã€‚æ¸²æŸ“çš„å¯¹è±¡æ˜¯3D meshï¼Œç”Ÿæˆ2Då›¾åƒã€‚ç”±æ­¤ä½œè€…æ ¹æ®Neural Rendereræå‡ºäº†ä¸¤ç§åº”ç”¨ï¼šsingle-image 3D mesh reconstruction with silhouette image supervisionå’Œgradient-based 3D mesh editing with 2D supervisionï¼ˆsuch as 2D-to-3D style transfer and 3D DeepDreamï¼‰ï¼Œå±•ç°äº†å°†Rendereré›†æˆåˆ°ç¥ç»ç½‘ç»œä¸­çš„å·¨å¤§å¨åŠ›</p>
<p><img src="8_1.png" alt></p>
<p>éš¾ç‚¹ï¼šå¦‚ä½•å°†rasterizationçš„è¿‡ç¨‹å¯å¾®åˆ†</p>
<p>æ³¨ï¼š</p>
<ul>
<li><p>polygon meshçš„ä¼˜ç‚¹ï¼šcompactnessï¼ˆå®¹æ˜“è¡¨ç¤ºã€å‚æ•°å°‘ï¼‰ã€geometric propertiesï¼ˆsuitability for geometric transformations. The rotation, translation, and scaling of objects are represented by simple operations on the vertices.ï¼‰</p>
</li>
<li><p>æ¸²æŸ“è¿‡ç¨‹ï¼šRendering consists of <strong>projecting</strong> the vertices of a mesh onto the screen coordinate system, and generating an image through regular grid <strong>sampling</strong>ã€‚åè€…çš„è¿‡ç¨‹ï¼ˆrasterizationï¼‰æ˜¯ç¦»æ•£çš„ã€ä¸å¯å¾®åˆ†çš„ï¼Œéœ€è¦æˆ‘ä»¬è¿‘ä¼¼æ¢¯åº¦ï¼Œä»è€Œå®ç°åå‘ä¼ æ’­ç®—æ³•</p>
</li>
<li><p>Our proposed renderer can flow gradients into texture, lighting, and cameras as well as object shapes.ï¼ˆmesh + texture + lighting + â€¦  = 2D rendered imageï¼‰</p>
</li>
<li><p>Polygon meshè¡¨ç¤ºæ³•ï¼š3Dé¡¶ç‚¹$\{v_i^o\}$å’Œé¢${f_j}$ï¼ˆå…¶ä¸­$f_j$æ˜¯3ç»´å‘é‡ï¼Œå†…å®¹æ˜¯ä¸‰è§’å½¢é¢çš„é¡¶ç‚¹çš„ç´¢å¼•ï¼‰</p>
</li>
<li><p>2D-to-3D style transferï¼š</p>
<script type="math/tex; mode=display">
\begin{align*}\frac{\partial Loss}{\partial Mesh}&=\frac{\partial Loss}{\partial Image}\times\frac{\partial Image}{\partial Mesh}\\&=(the\; gradient\; of\; loss) \times (the\; gradient\; of\;renderer)\end{align*}</script><p>é£æ ¼è¿ç§»ï¼šå°†content meshçš„â€œcontentâ€å’Œstyle imageçš„â€œstyleâ€èåˆåˆ°è¾“å‡ºçš„output meshä¸Šã€‚éœ€è¦ç”¨content lossè¡¡é‡contentçš„è¿ç§»æŸå¤±ã€style lossè¡¡é‡styleçš„è¿ç§»æŸå¤±<br>$Mesh \rightarrow Image$æä¾›äº†å¯¹é¡¶ç‚¹å’Œé¢çº¹ç†çš„æ¢¯åº¦æµï¼Œå› æ­¤å¯ä»¥ä¿®æ”¹é¢çº¹ç†ï¼Œå°†é£æ ¼è¿ç§»åˆ°é¢çº¹ç†ä¸Šã€‚</p>
</li>
<li><p>Rendererä½¿å¾—ä¸€äº›å¯¹å›¾åƒåœ°æ“ä½œï¼ˆä¾‹å¦‚é£æ ¼è¿ç§»ï¼‰è¿ç§»åˆ°3Dæ•°æ®ç»“æ„ä¸­æˆä¸ºå¯èƒ½ã€‚</p>
</li>
</ul>
<h3 id="å®ç°-7"><a href="#å®ç°-7" class="headerlink" title="å®ç°"></a>å®ç°</h3><ol>
<li><p>Rendering pipeline and its derivative</p>
<p>å°†3Dé¡¶ç‚¹$\{v_i^o\}$æŠ•å°„åˆ°2Då¹³é¢ä¸Šå¾—åˆ°$\{v_i^s\} $ï¼Œæ­¤è¿‡ç¨‹æ˜¯å¯å¾®åˆ†çš„</p>
<p>ç„¶åå°†$\{v_i^s\} $å’Œ$\{f_j\}$é€šè¿‡rasterizationå¾—åˆ°2D rendered imageï¼šè€ƒè™‘2D rendered imageä¸Šçš„ä¸€ä¸ªpixelç‚¹$P_j$ï¼ˆå…¶é¢œè‰²å€¼$I_j$ï¼‰ï¼Œå¦‚æœè¿™ä¸ªpixelçš„centerä½äºface $f_i$çš„å†…éƒ¨ï¼Œåˆ™æ­¤pixelçš„é¢œè‰²å€¼$I_j $è¢«èµ‹å€¼ï¼ˆæŸ“è‰²ï¼‰æˆ$I_{ij}$</p>
<p><img src="8_2.png" alt></p>
<p>å›¾ä¸­åªè€ƒè™‘$x_i$æ˜¯å¯å˜çš„ï¼Œå…¶ä»–æš‚æ—¶å†»ç»“ä½ä¸è€ƒè™‘å…¶å˜åŒ–</p>
<p>æˆ‘ä»¬å°†çªå˜çš„è¿‡ç¨‹è¿ç»­åŒ–ï¼ˆçº¿æ€§æ’å€¼ï¼‰ï¼Œå¾—åˆ°â€œï¼ˆdï¼‰â€æ‰€ç¤ºçš„æ•ˆæœã€‚æˆ‘ä»¬å‰å‘ä¼ æ’­ä½¿ç”¨å›¾â€œï¼ˆbï¼‰â€æ‰€ç¤ºçš„æ›²çº¿ï¼Œåå‘ä¼ æ’­çš„å¯¼æ•°ä½¿ç”¨â€œï¼ˆeï¼‰â€æ‰€ç¤ºçš„æ›²çº¿ã€‚</p>
<p>å…¶ä¸­é¢œè‰²çªå˜é‡$\delta_j^I=I(x_1)-I(x_0)$ï¼Œä½ç§»å˜åŒ–é‡$\delta_j^x=x_1-x_0$ï¼Œé‚£ä¹ˆæ–œçº¿çš„æ–œç‡å°±æ˜¯$\frac{\delta_j^I}{\delta_j^x}$</p>
<p>è€ƒè™‘åå‘ä¼ æ’­çš„è¯¯å·®ä¿¡å·$\delta_j^p = \frac{\partial Loss}{\partial I_j}$ï¼Œå½“$\delta_j^p&gt;0$æ—¶$I_j$ä¼šå‡å°‘ï¼Œå½“$\delta_j^I&gt;0$æ—¶$I_j$ä¼šå¢å¤§ã€‚ä¸ºäº†ä¸ä½¿å¾—åšæ— ç”¨åŠŸï¼Œæˆ‘ä»¬è¦æ±‚$\delta_j^I \delta_j^p &lt; 0$æ‰å¯ä»¥æ›´æ–°å‚æ•°ï¼Œæ‰€ä»¥ï¼š</p>
<p><img src="8_3.png" alt></p>
<p>ç±»ä¼¼åœ°ï¼Œå½“åƒç´ ç‚¹æœ¬èº«å°±åœ¨faceçš„å†…éƒ¨æ—¶ï¼Œåˆ™å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p>
<p><img src="8_4.png" alt></p>
<p>å¹¶ä¸”å…¶å¯¼æ•°å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p><img src="8_5.png" alt></p>
<p>å½“å¤šä¸ªfacesæ—¶ï¼Œour rasterizer draws only the frontmost face at each pixel, and do not flow gradients if they are occluded by surfaces not including $v_i$</p>
<p>Textureï¼šä½äºface$\{v_1,v_2,v_3\}$ä¸Šçš„ç‚¹$p$å¯ä»¥è¢«åˆ†è§£ä¸º$p=w_1v_1+w_2v_2+w_3v_3$ï¼Œé‚£ä¹ˆç”¨$(w_1,w_2,w_3)$å°±å¯ä»¥è¡¨ç¤ºå‡ºface$\{v_1,v_2,v_3\}$ä¸Šçš„ç‚¹ã€‚å…¶çº¹ç†textureå°±å¯ä»¥åˆ©ç”¨$(w_1,w_2,w_3)$ä» texture image$s_t\times s_t \times s_t$ï¼ˆeach face has its own texture imageï¼‰ä¸­æŸ¥å€¼è·å¾—ã€‚ä¸éš¾éªŒè¯å¿…å®šæ»¡è¶³$w_1 + w_2 + w_3 = 1$</p>
<p>Lightingï¼šè€ƒè™‘ç¯å¢ƒå…‰$l^a$å’Œå®šå‘å…‰æº$l^d$ï¼Œé‚£ä¹ˆpixel color$ I_j $ç»è¿‡å…‰æºæ¸²æŸ“åçš„é¢œè‰²å°±æ˜¯$I^l_j = (l^a+(n^d\cdot n^j)l^d)I_j$ï¼ˆ$n^j$æ˜¯faceä¸Špixelçš„å•ä½æ³•å‘ï¼Œ$n^d$æ˜¯å®šå‘å…‰æºçš„å•ä½æ–¹å‘ï¼‰</p>
</li>
<li><p>Single image 3D reconstruction</p>
<p><img src="8_6.png" alt></p>
<p>æ€æƒ³ï¼šmatch the ground truth silhouettesã€‚æœ‰ç‚¹åƒencoder-decoderç»“æ„</p>
<p>3D generator ideaï¼šdeform an isotropic sphere with 642 vertices to generate a new mesh, therefore the mesh we use is specified by 642*3 parametersã€‚ç„¶åä½¿ç”¨silhouette lossï¼ˆé¼“åŠ±IoUè¶Šå¤§è¶Šå¥½ï¼‰å’Œsmoothness lossï¼ˆé¼“åŠ±é¢é¢å¤¹è§’è¶Šæ¥è¿‘180Â°è¶Šå¥½ï¼‰è®­ç»ƒæ­¤generation function</p>
<p>å°†maskä½œä¸ºé™„åŠ é€šé“åŠ å…¥åˆ°RGBå›¾ä¸­</p>
</li>
<li><p>Gradient-based 3D mesh editing</p>
<p><img src="8_7.png" alt></p>
<p>We optimize a 3D mesh consisting of vertices, faces, and textures based on its rendered image</p>
<p>In this section, we propose a method to transfer the style of an image onto a mesh</p>
<p>å…¶ä¸­content lossç¡®ä¿3D msehçš„shapeç›¸åŒï¼›style lossç¡®ä¿é£æ ¼ç›¸åŒï¼ˆå›¾ä¸­çš„LossæŒ‡çš„æ˜¯style lossï¼‰ï¼›åŒæ—¶ä½¿ç”¨äº†regularizer for noise reductionã€‚æ€»Losså°±æ˜¯æ‰€æœ‰lossçš„åŠ æƒå’Œï¼Œå¯¹é¡¶ç‚¹å’Œçº¹ç†æœ€å°åŒ–lossçš„å€¼</p>
<p>ç±»ä¼¼åœ°ï¼Œè¿˜å¯ä»¥ç”¨äº3D DeepDream</p>
</li>
</ol>
<h2 id="Pixel2Mesh"><a href="#Pixel2Mesh" class="headerlink" title="Pixel2Mesh"></a>Pixel2Mesh</h2><blockquote>
<p>ECCV2018ã€ŠPixel2Mesh: Generating 3D Mesh Models from Single RGB Imagesã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="http://openaccess.thecvf.com/content_ECCV_2018/html/Nanyang_Wang_Pixel2Mesh_Generating_3D_ECCV_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/html/Nanyang_Wang_Pixel2Mesh_Generating_3D_ECCV_2018_paper.html</a></p>
</blockquote>
<h3 id="æ¦‚æ‹¬"><a href="#æ¦‚æ‹¬" class="headerlink" title="æ¦‚æ‹¬"></a>æ¦‚æ‹¬</h3><p>æå‡ºäº†å•è§†å›¾è¾“å…¥çš„end-to-endæ¡†æ¶ï¼Œèƒ½ç”Ÿæˆä¸‰è§’å½¢ç½‘æ ¼ï¼ˆtriangular meshï¼‰ã€‚ä½¿ç”¨GCNæ¥å¤„ç†meshçš„é¡¶ç‚¹ç‰¹å¾ï¼Œå°†æ¤­çƒå½¢å˜æ¥æ‹Ÿåˆè¡¨é¢ï¼ŒåŒæ—¶åˆ©ç”¨å›¾åƒçš„ç‰¹å¾ã€‚meshä»ç²—åˆ°ç²¾ç»†åŒ–ï¼Œé¡¶ç‚¹æ•°å˜å¤šã€‚å®šä¹‰äº†4ç§lossæ¥ä¼˜åŒ–ç»“æœã€‚ç»“æœå…·æœ‰æ›´å¥½çš„ç²¾ç»†åº¦ï¼Œè¶…è¶Šäº†SOTAã€‚</p>
<p>æ³¨ï¼š</p>
<ul>
<li>å½¢å˜æ³•çš„ä¼˜ç‚¹ï¼šdeep network is better at predicting residualã€‚a series of deformations can be added up together, which allows shape to be gradually refined in detailã€‚it provides the chance to encode any prior knowledge to the initial meshã€‚</li>
<li>é™åˆ¶æ¡ä»¶ï¼šåªèƒ½ç”¨äºäºæ ¼ï¼ˆgenusï¼‰ä¸ºé›¶çš„shapeï¼Œå› ä¸ºæ¤­çƒæ²¡æœ‰â€œå­”â€</li>
<li>å…·æœ‰ä¸Šé‡‡æ ·å±‚ï¼Œç‚¹æ•°é€æ¸å¢å¤šã€‚Deformation blockåˆ™è´Ÿè´£ç²¾ç»†åŒ–mesh</li>
</ul>
<h3 id="åŸç†-5"><a href="#åŸç†-5" class="headerlink" title="åŸç†"></a>åŸç†</h3><p><img src="9_2.png" alt></p>
<p>å°†meshåˆå§‹åŒ–ä¸ºæ¤­çƒï¼Œç„¶åç”¨GCNå¯¹vertex featureæ–½åŠ å˜æ¢ï¼Œä»è€Œå®ç°å¯¹3D vertex pointçš„ä½ç½®ç©ºé—´å˜æ¢ã€‚ç„¶åä¸Šé‡‡æ ·graphï¼Œä»¥å¢åŠ ç‚¹æ•°ã€‚ä¸æ–­é‡å¤æ­¤è¿‡ç¨‹ï¼Œå®ç°ä»ç²—åˆ°ç²¾çš„è¿‡æ¸¡ã€‚image featureèåˆè¿›å…¥deformation blocksä¸­æ¥å®ç°å…¨å±€shapeçš„æŠŠæ¡ã€‚</p>
<h3 id="å®ç°-8"><a href="#å®ç°-8" class="headerlink" title="å®ç°"></a>å®ç°</h3><p>æ•´ä½“ç”±image feature networkå’Œcascaded mesh deformation networkç»„æˆã€‚</p>
<p>deformation blocksï¼šå°†å›¾åƒçš„2Dç‰¹å¾æå‡åˆ°3D vertexçš„ç‰¹å¾ä¸­æ¥ï¼ˆ1280ç»´ï¼‰ï¼Œç„¶åcancatï¼ˆ1280+128=1408ç»´ï¼‰ï¼Œå†GCNï¼ˆè¾“å‡ºç©ºé—´åæ ‡3ç»´å’Œç‰¹å¾128ç»´ï¼‰ã€‚</p>
<p>graph unpooling layersï¼šä¸Šé‡‡æ ·å›¾ï¼Œå¢åŠ é¡¶ç‚¹æ•°ï¼Œä»è€Œå¯ä»¥å®ç°æ›´ç²¾ç»†çš„ç»“æ„</p>
<ol>
<li><p>Initial ellipsoid</p>
<ul>
<li><p>ellipsoid with average size placed at the common location</p>
</li>
<li><p>initial feature contains only the 3D coordinate of each vertexï¼ˆ3ç»´ã€‚ç‰¹å¾æå–ä¹‹åæ‰æ˜¯128ç»´çš„featureï¼‰</p>
</li>
</ul>
</li>
<li><p>GCN</p>
<p>å°†meshç”¨vertexå’Œedgeè¡¨ç¤ºï¼Œé‚£ä¹ˆå°±æ˜¯ä¸€å¼ graphã€‚æ¯ä¸ªvertexä¸Šéƒ½æœ‰ä¸ªfeatureã€‚é€šè¿‡ä¸€æ¬¡GCNå±‚ï¼Œå¾—åˆ°å˜æ¢åçš„ç‰¹å¾ï¼š</p>
<p><img src="9_1.png" alt></p>
<p>å…¶ä¸­$w_0$å’Œ$w_1$éƒ½æ˜¯$d_{l+1}\times d_{l} $å°ºå¯¸çš„å˜æ¢çŸ©é˜µï¼Œå³ç»è¿‡ä¸€å±‚GCNå±‚å…¶ç‰¹å¾å‘é‡çš„ç»´åº¦å¯èƒ½å‘ç”Ÿå˜åŒ–ã€‚æˆ‘ä»¬çš„ç‰¹å¾å‘é‡$f_p$æ˜¯â€œ3Dç©ºé—´åæ ‡â€ã€â€œå±€éƒ¨å½¢çŠ¶ç‰¹å¾â€å’Œâ€œè¾“å…¥å›¾åƒç‰¹å¾â€çš„cancatã€‚ä½¿ç”¨GCNå°†å˜æ¢ç‰¹å¾ï¼Œç­‰æ•ˆäºç©ºé—´ç‚¹ä½ç½®çš„å˜æ¢ä»¥åŠç‰¹å¾æå–ã€‚</p>
</li>
<li><p>Mesh deformation block</p>
<p><img src="9_3.png" alt></p>
<p>å°†â€œinput image featureâ€æå‡åˆ°3Dç©ºé—´ä¸­çš„ç‚¹ç‰¹å¾ï¼Œå¾—åˆ°1280ç»´çš„ç‰¹å¾ã€‚ä¸128ç»´çš„å½¢çŠ¶ç‰¹å¾concatå¾—åˆ°1408ç»´çš„ç‰¹å¾ï¼Œå†è¿›è¡ŒGCNï¼Œå…¶ä¸­ä¸€ä¸ªåˆ†æ”¯é¢„æµ‹ç‚¹çš„3ç»´åæ ‡ï¼Œå¦ä¸€ä¸ªåˆ†æ”¯é¢„æµ‹128ç»´ç‰¹å¾ã€‚</p>
<p>æå‡åˆ°3Dç©ºé—´ï¼šå°†3Dç‚¹æŠ•å°„åˆ°2Då¹³é¢ä¸Šï¼Œç„¶åæ ¹æ®å›¾åƒä¸­çš„gird featureè¿›è¡ŒåŒçº¿æ€§æ’å€¼å¾—åˆ°è¯¥ç‚¹çš„ç‰¹å¾ã€‚å…¶ä¸­feature mapså–è‡ªVGG16ï¼Œä¸€å…±æœ‰1280ä¸ªé€šé“ï¼Œæ‰€ä»¥è¾“å‡ºçš„ç‰¹å¾æ˜¯1280ç»´ã€‚</p>
<p>æ®‹å·®ç»“æ„çš„graph based ResNetï¼ˆG-ResNetï¼‰æœ‰åŠ©äºefficient exchange of the information between verticesã€æå‡æ„Ÿå—é‡ã€‚</p>
<p>æ‰€æœ‰çš„deformation blocksä¼¼ä¹æ˜¯å…±ç”¨åŒä¸€ä¸ªVGG16çš„feature maps</p>
</li>
<li><p>Graph unpooling layer</p>
<p>ç›®çš„ï¼šå¢åŠ ç‚¹çš„æ•°é‡ã€‚ä½¿ç”¨å›¾ä¸­Edge-basedçš„æ–¹æ³•ã€‚</p>
<p><img src="9_4.png" alt></p>
<p>This edge-based unpooling uniformly upsamples the vertices, and doesnâ€™t causes the imbalanced vertex degrees.</p>
</li>
<li><p>Losses and Regularizations</p>
<ul>
<li>Chamfer lossï¼šIt is reasonably good to regress the vertices close to its correct position, however is not sufficient to produce nice 3D mesh</li>
<li>Normal lossï¼šthis loss requires the edge between a vertex with its neighbors to perpendicular to the observation from the ground truth. enforce the consistency of surface normal</li>
<li>Laplacian regularizationï¼šprevent the vertices from moving too freely, which potentially avoids mesh self-intersection. encourages neighboring vertices to have the same movement. laplacian regularization to maintain relative location between neighboring vertices during deformation,</li>
<li>Edge length regularizationï¼šedge length regularization to prevent outliers. é¼“åŠ±edgeè¶ŠçŸ­è¶Šå¥½</li>
<li>æ€»ï¼šå°±æ˜¯ä¸Šé¢4ç§çš„çº¿æ€§åŠ æƒå’Œ</li>
</ul>
</li>
</ol>
<h2 id="Pixel2Mesh-1"><a href="#Pixel2Mesh-1" class="headerlink" title="Pixel2Mesh++"></a>Pixel2Mesh++</h2><blockquote>
<p>ICCV2019ã€ŠPixel2Mesh++: Multi-View 3D Mesh Generation via Deformationã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="https://arxiv.org/abs/1908.01491" target="_blank" rel="noopener">https://arxiv.org/abs/1908.01491</a></p>
</blockquote>
<h3 id="æ¦‚æ‹¬-1"><a href="#æ¦‚æ‹¬-1" class="headerlink" title="æ¦‚æ‹¬"></a>æ¦‚æ‹¬</h3><p>ä»å¤šè§†å›¾è¾“å…¥ã€å·²çŸ¥ç›¸æœºå§¿æ€çš„æ¡ä»¶ä¸‹é‡å»ºå‡º3D Meshï¼Œæ˜¯Pixel2Meshçš„å‡çº§ç‰ˆã€‚åŒæ ·æ˜¯åˆ©ç”¨GCNæŠ½å–é¡¶ç‚¹çš„ç‰¹å¾ã€å¯¹åˆå§‹meshè¿›è¡Œç²—åˆ°ç»†çš„å½¢å˜ã€‚ä¸åŒçš„æ˜¯å½¢å˜çš„è¿‡ç¨‹ä¸ºï¼šå¯¹æ¯ä¸ªé¡¶ç‚¹åˆ†åˆ«æå‡ºå½¢å˜çš„å€™é€‰ç‚¹ï¼Œç„¶ååˆ©ç”¨projectionã€GCNæ“ä½œã€ç»“åˆå›¾åƒçš„feature mapså˜æ¢ç‰¹å¾å¾—åˆ°æ¯ä¸ªå€™é€‰ç‚¹çš„é‡è¦æ€§ç³»æ•°ï¼Œè¿›è¡Œåæ ‡çš„çº¿æ€§åŠ æƒå¾—åˆ°å½¢å˜åçš„åæ ‡ã€‚èƒ½å¤Ÿç”Ÿæˆè§†è§‰æ•ˆæœå¥½çš„Meshï¼Œæ³›åŒ–èƒ½åŠ›å¼ºï¼Œè¾¾åˆ°SOTAã€‚</p>
<p>æ³¨ï¼š</p>
<ul>
<li>Pixel2Meshç”Ÿæˆçš„meshå¾€å¾€åªåœ¨single-imageçš„è§†è§’æ–¹å‘æ•ˆæœå¥½ï¼Œå†å…¶ä»–è§†è§’ä¸‹æ•ˆæœå·®</li>
<li>å¤šè§†å›¾è¾“å…¥çš„å…³é”®åŸç†ï¼šä½¿ç”¨è¯¸å¦‚meanã€stdã€maxçš„ç»Ÿè®¡ç‰¹å¾ï¼Œå®ç°å¯ä»¥æ¥å—ä»»æ„å¤šè§†å›¾çš„è¾“å…¥</li>
<li>Pixel2Mesh++ç”±perceptual networkï¼ˆVGG16ï¼‰ã€coarse shape generationï¼ˆPixel2Meshï¼‰å’ŒMulti-View Deformation Networkï¼ˆMDNï¼‰ç»„æˆã€‚</li>
<li>MDNæ˜¯end-to-end trainableçš„ã€‚å¯æ¥å—ä»»æ„æ•°é‡çš„è§†å›¾è¾“å…¥</li>
<li>æ³¨æ„åœ¨MDNä¸­æ²¡æœ‰ä¸Šé‡‡æ ·å±‚ï¼Œä¸èƒ½å¢åŠ ç‚¹çš„æ•°é‡ã€‚</li>
<li>ä½œè€…ä¸»è¦çš„è´¡çŒ®æ˜¯è®¾è®¡äº†MDNï¼Œè€ŒMDNçš„ä½œç”¨æ›´åƒæ˜¯å¾®è°ƒå·²ç”Ÿæˆçš„mesh</li>
<li>å€™é€‰ç‚¹ï¼ˆHypothesisï¼‰æœ¬è´¨ä¸Šæ˜¯å¯¹vertexå‘¨å›´ç¯å¢ƒçš„æ„ŸçŸ¥ï¼ŒGCNèµ·åˆ°ç±»ä¼¼äºlocal graphçš„neighborhoodä¹‹é—´çš„ç‰¹å¾äº¤äº’èåˆã€ç‰¹å¾æå–çš„ä½œç”¨ã€‚æœ€åæ ¹æ®GCNå¾—åˆ°çš„scoreæ¥make movement decisionã€‚è€ŒPixel2Meshæ²¡æœ‰æ„ŸçŸ¥vertexå‘¨å›´ç¯å¢ƒçš„èƒ½åŠ›ã€‚</li>
</ul>
<h3 id="åŸç†-6"><a href="#åŸç†-6" class="headerlink" title="åŸç†"></a>åŸç†</h3><p><img src="10_1.png" alt></p>
<p>åŸºäºPixel2Meshåšåˆå§‹meshçš„ç”Ÿæˆã€‚ä»å¤šè§†å›¾ä¸­ç”¨VGG16æŠ½å–ç‰¹å¾ï¼Œåº•å±‚çº§ç§°ä½œgeometry featureï¼Œé«˜å±‚çº§ç§°ä½œsemantic featureã€‚ç„¶åä¸ºæ¯ä¸ªvertexç”Ÿæˆå½¢å˜å€™é€‰ç‚¹ï¼Œåˆ©ç”¨å›¾åƒæŠ½å–æ¥çš„ç‰¹å¾ä¸ºæ¯ä¸ªå€™é€‰ç‚¹è®¡ç®—scoreï¼Œæœ€åæ ¹æ®scoreå’Œ3Dåæ ‡ä½œçº¿æ€§åŠ æƒå¾—åˆ°æœ€ç»ˆå½¢å˜åçš„ä½ç½®ã€‚å¤šæ¬¡å½¢å˜å³å¯å¾—åˆ°è¾“å‡ºçš„meshã€‚</p>
<h3 id="å®ç°-9"><a href="#å®ç°-9" class="headerlink" title="å®ç°"></a>å®ç°</h3><ol>
<li><p>Deformation Hypothesis Sampling</p>
<p>ç›®çš„ï¼špropose deformation hypothesesï¼ˆå½¢å˜å€™é€‰ç‚¹ï¼‰for each vertex</p>
<p><img src="10_2.png" alt></p>
<p>å®ç°ï¼šåœ¨æ¯ä¸ªvertexçš„ä½ç½®ä¸Šæ”¾ç½®ä¸€ä¸ªlevel-1 icosahedronï¼ˆå…·æœ‰42ä¸ªé¡¶ç‚¹ã€80ä¸ªé¢ã€120æ¡è¾¹ï¼‰ï¼Œç„¶åä¸ºæ¯ä¸ªvertexæ„é€ ä¸€ä¸ªlocal graphï¼ˆlocal graphçš„è¾¹ç”±â€œlevel-1 icosahedronâ€çš„120æ¡è¾¹ã€vertexåˆ°â€œlevel-1 icosahedronâ€çš„é¡¶ç‚¹çš„è¿çº¿ç»„æˆã€‚æ‰€ä»¥ä¸€ä¸ªlocal graphä¸€å…±æœ‰120+42=162æ¡è¾¹ï¼Œ42+1=43ä¸ªç‚¹ï¼‰ã€‚æ¯ä¸ªé¡¶ç‚¹éƒ½è¦æ„é€ ä¸€ä¸ªlocal graphï¼Œç„¶åå–‚ç»™æ¥ä¸‹æ¥çš„â€œCross-View Perceptual Feature Poolingâ€æ­¥éª¤</p>
</li>
<li><p>Cross-View Perceptual Feature Pooling</p>
<p>ç›®çš„ï¼šassign each nodeï¼ˆin the local graphï¼‰features from the multiple input color images</p>
<p><img src="10_3.png" alt></p>
<p>å¤§ä½“ç±»ä¼¼äºPixel2Meshä¸­çš„â€œperceptual feature poolingâ€æ“ä½œã€‚feature mapsæ¥è‡ªVGG16çš„conv1_2ã€conv2_2ã€conv3_3ï¼ˆå®ƒä»¬æ˜¯åº•å±‚çº§çš„geometry featureï¼‰ï¼Œä¸€ä¸ªè§†å›¾concatèµ·æ¥è¾“å‡º64+128+256=448é•¿åº¦çš„ç‰¹å¾ã€‚</p>
<p>è€ƒè™‘åˆ°å¯¹ä¸åŒæ•°é‡çš„è§†å›¾è¾“å…¥å¦‚æœconcatçš„è¯ä¼šå¾—åˆ°ä¸åŒé•¿åº¦çš„featureã€‚æˆ‘ä»¬æ”¹è€Œä½¿ç”¨ç»Ÿè®¡ç‰¹å¾ï¼Œå®ç°å›ºå®šé•¿åº¦çš„è¾“å‡ºã€‚ä½¿ç”¨meanã€maxã€stdè¿™ä¸‰ç§ç»Ÿè®¡ç‰¹å¾ã€‚è€Œä¸”ä½¿ç”¨ç»Ÿè®¡ç‰¹å¾å¯¹è§†å›¾çš„è¾“å…¥çš„é¡ºåºå…·æœ‰ä¸å˜æ€§ã€‚æ‰€ä»¥ç‰¹å¾é•¿åº¦å˜ä¸º448*3=1344ç»´ã€‚å†æŠŠç©ºé—´åæ ‡concatè¿›å»å¾—åˆ°1344+3=1347ç»´åº¦çš„ç‰¹å¾ã€‚</p>
</li>
<li><p>Deformation Reasoning</p>
<p>ç›®çš„ï¼šreason an optimal deformation for each vertex from the hypotheses using pooled cross-view perceptual features</p>
<p><img src="10_4.png" alt></p>
<p>å®ç°ï¼šå°†local graphå’Œlocal graph nodes featureï¼ˆå³pooled cross-view perceptual featuresï¼‰ä¸¢åˆ°scoring networkï¼ˆæœ¬è´¨æ˜¯GCNï¼‰ä¸­å¾—åˆ°æ¯ä¸ªnodesçš„é‡è¦æ€§å¾—åˆ†$s_i$ï¼ˆsoftmaxè¾“å‡ºåè‡ªåŠ¨æ»¡è¶³$\sum_{i=1}^{43} s_i=1$ï¼‰ã€‚è‹¥å€™é€‰ç‚¹çš„ç©ºé—´ä½ç½®è®°ä½œ$h_i$ï¼ˆåŒ…æ‹¬vertexï¼Œ$i=1â€¦43$ï¼‰ï¼Œé‚£ä¹ˆå½¢å˜åçš„ä½ç½®å°±æ˜¯ä½ç½®çš„çº¿æ€§åŠ æƒï¼š$\sum_{i=1}^{43}s_i h_i$ã€‚å¯¹æ¯ä¸ªé¡¶ç‚¹éƒ½è¿è¡Œä¸€éï¼Œå°±å¾—åˆ°äº†æœ€ç»ˆå½¢å˜åçš„ç»“æœã€‚</p>
</li>
<li><p>Losses</p>
<p>æŸå¤±å‡½æ•°ç…§æŠ„Pixel2Meshçš„ï¼Œä½†æ˜¯å”¯ä¸€çš„åŒºåˆ«æ˜¯ä½œè€…è¿˜extends the Chamfer distance loss to a resampled versionï¼Œå³ï¼šä»meshçš„faceä¸Šå‡åŒ€é‡‡æ ·ç‚¹ï¼Œé‡‡æ ·çš„ç‚¹æ•°æ­£æ¯”äºfaceçš„é¢ç§¯ï¼Œç”±æ­¤å¯ä»¥é¢å¤–é‡‡æ ·å‡º4000ä¸ªç‚¹ï¼ŒåŠ ä¸Š2466ä¸ªåŸæœ¬çš„meshçš„é¡¶ç‚¹ï¼Œæ€»å…±6466ä¸ªç‚¹ï¼Œæ ¹æ®6466ä¸ªç‚¹è®¡ç®—Chamfer distance loss</p>
<p>re-sample Chamfer lossçš„åŠŸèƒ½ï¼šhelps to remove artifacts in the resultsï¼Œè§£å†³äº†points are not uniformly distributed on the surfaceçš„é—®é¢˜</p>
</li>
<li><p>Implementation Details</p>
<p>we use Pixel2Mesh to generate a coarse shape with 2466 vertices â†’ æœ€ç»ˆç”Ÿæˆçš„ç‚¹çš„æ•°é‡å°±æ˜¯2466ä¸ª</p>
</li>
</ol>
<h3 id="å®éªŒ-4"><a href="#å®éªŒ-4" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><ul>
<li><p>å¯¹æ¯”çš„ç½‘ç»œï¼š</p>
<ul>
<li>P2M-Mï¼šwe directly run single-view Pixel2Mesh on each of the input image and fuse multiple results</li>
<li>MVP2Mï¼šwe replace the perceptual feature pooling to our cross-view version to enable Pixel2Mesh for the multi-view scenario</li>
<li>LSMï¼šLearnt Stereo Machine</li>
<li>3DR2N2ï¼š3D Recurrent Reconstruction Neural Network</li>
</ul>
</li>
<li><p>æ€§èƒ½ï¼šOur model significantly outperforms previous methodsï¼ˆbased on F-scoreï¼‰</p>
</li>
</ul>
<h2 id="AtlasNet-ğŸ‘"><a href="#AtlasNet-ğŸ‘" class="headerlink" title="AtlasNet ğŸ‘"></a>AtlasNet ğŸ‘</h2><blockquote>
<p>CVPR2018ã€ŠA Papier-MÃ¢chÃ© Approach to Learning 3D Surface Generationã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Groueix_A_Papier-Mache_Approach_CVPR_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/html/Groueix_A_Papier-Mache_Approach_CVPR_2018_paper.html</a></p>
</blockquote>
<h3 id="æ¦‚è¿°-8"><a href="#æ¦‚è¿°-8" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>æå‡ºä½¿ç”¨åŸºäº<a href="https://zh.wikipedia.org/wiki/æµå½¢" target="_blank" rel="noopener">æµå½¢</a>ä¸­Chartså’ŒAtlasesçš„æ¦‚å¿µçš„3Dshapesçš„surfaceç”Ÿæˆæ–¹æ³•ã€‚å°†surfaceè¡¨ç¤ºæˆå¤šä¸ªå±€éƒ¨å°è¡¨é¢çš„é›†åˆï¼ˆç±»ä¼¼äºChartsçš„æ¦‚å¿µï¼‰ã€‚æé«˜äº†ç²¾åº¦ã€æ³›åŒ–å¼ºã€èƒ½ç”Ÿæˆä»»æ„ç²¾åº¦çš„åˆ†è¾¨ç‡ã€‚AtlasNetçš„æœ¬è´¨æ˜¯ä¸€ä¸ª3D shape decoderï¼ˆè¾“å…¥å½¢çŠ¶æè¿°å­è¾“å‡ºmesh/pointcloudï¼‰ã€‚AtlasNetå¯ä»¥åº”ç”¨äºå½¢çŠ¶è‡ªç¼–ç ã€3Dé‡å»ºç­‰å¤šä¸ªé¢†åŸŸã€‚</p>
<p>æ³¨ï¼š</p>
<ul>
<li>pointcloudçš„ç¼ºç‚¹ï¼šä¸èƒ½ç›´æ¥è¡¨ç¤ºä¸é‚»å±…çš„å…³ç³»ï¼ˆno surface connectivityï¼‰ï¼Œä½¿å¾—å¾ˆéš¾å¾—åˆ°å…‰æ»‘ã€é«˜ä¿çœŸçš„æµå½¢</li>
<li>polygonal meshçš„ç‰¹ç‚¹ï¼šå¯¹å…‰æ»‘æµå½¢çš„åˆ†å—å¹³é¢è¿‘ä¼¼</li>
<li>Surface parameterizationï¼š Establishing a connection between the surface of the 3D shape and a 2D domain</li>
<li>3Dé‡å»ºæ—¶è¾“å…¥çš„å¯¹è±¡å¯ä»¥æ˜¯pointcloudã€imagesç­‰ï¼Œå› ä¸ºAtlasNetåªè¦æ±‚ç‰¹å¾å‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¯ä»¥ä½¿ç”¨å…¶ä»–ç½‘ç»œæå–è¾“å…¥å¯¹è±¡çš„ç‰¹å¾å‘é‡ä¹‹åä½œä¸ºAtlasNetçš„è¾“å…¥ã€‚</li>
<li>chartï¼š3Dâ†’2Dï¼ˆ1ä¸ªMLPå‡½æ•°ï¼‰ï¼›atlasï¼ša set of chartsï¼ˆå¤šä¸ªMLPsï¼‰</li>
<li>AtlasNetçš„åŠŸèƒ½ï¼šlearn an atlas for 2-manifold $\mathcal{S}$</li>
<li>ç¼ºç‚¹ï¼šç”Ÿæˆçš„meshä¸é—­åˆï¼Œæœ‰å°å­”ï¼Œä¸åŒçš„æ›²é¢å—ä¹‹é—´æœ‰overlap</li>
</ul>
<h3 id="æ€æƒ³"><a href="#æ€æƒ³" class="headerlink" title="æ€æƒ³"></a>æ€æƒ³</h3><p><img src="11_1.png" alt></p>
<p>å°†2Då•ä½æ­£æ–¹å½¢å¹³é¢çš„ç‚¹é›†ï¼ˆ$[0,1]\times [0,1]$ï¼‰ä½¿ç”¨MLPæ˜ å°„åˆ°3Dæ›²é¢ä¸Šã€‚æœ‰å¤šä¸ªMLPï¼Œäºæ˜¯å°±èƒ½å¾—åˆ°å¤šä¸ªå°çš„3Dæ›²é¢ã€‚å¤šä¸ªå°3Dæ›²é¢å°±èƒ½ç»„æˆç‰©ä½“ã€‚å³ï¼Œwe seek to approximate the target surface locally by<br>mapping a set of squares to the surface of the 3D shape</p>
<script type="math/tex; mode=display">
[0,1]\times[0,1] \leftrightarrow 3D \; surface</script><p>è¿™æ ·1ä¸ªMLPå°±èƒ½å±€éƒ¨ç”Ÿæˆä¸€ä¸ª2-manifoldï¼ˆ3Dæ›²é¢ï¼‰äº†</p>
<ul>
<li><p>2Dâ†’3Dï¼šé€šè¿‡MLPå¾—åˆ°</p>
</li>
<li><p>3Dâ†’2Dï¼šUV parameterization of the surface / 2D ï¼ˆUVï¼‰ embedding to a plane</p>
</li>
</ul>
<p>äºæ˜¯åœ¨2Då¹³é¢ä¸Šçš„æ€§è´¨å°±èƒ½è¿ç§»åˆ°3Dæ›²é¢ä¸­ï¼šä¾‹å¦‚2Då¹³é¢æœ‰çº¹ç†ï¼Œåˆ™åœ¨3Dæ›²é¢çš„å¯¹åº”ç‚¹ä¸Šä¹Ÿæœ‰ç›¸åŒçš„çº¹ç†</p>
<p>ç”Ÿæˆmeshçš„æ–¹æ³•ï¼šå°†æ–¹å½¢çš„2Dmeshæ˜ å°„åˆ°3Dç©ºé—´ä¸­ï¼Œå¹¶ä¿æŒç‚¹ä¸ç‚¹ä¹‹é—´çš„è¿æ¥å…³ç³»</p>
<h3 id="å®ç°-10"><a href="#å®ç°-10" class="headerlink" title="å®ç°"></a>å®ç°</h3><ol>
<li><p>Learning to decode a surface</p>
<p>ç›®æ ‡ï¼šæœ‰ä¸€ä¸ªå½¢çŠ¶æè¿°å­$\mathtt{x}$ï¼ˆå½¢çŠ¶ç‰¹å¾å‘é‡ï¼‰ï¼Œè¯·æ®æ­¤ç”Ÿæˆthe surface of the shape</p>
<p>å®ç°ï¼š</p>
<ul>
<li>æœ‰Nä¸ªlearnable parameterizationsï¼ˆMLPï¼‰$\phi_{\theta_i}$ï¼Œ$i\in\{1,â€¦,N\}$ï¼Œå…¶ä¸­$\theta_{i}$æ˜¯MLPå‚æ•°</li>
<li><p>å°†$\mathtt{x}$å’Œ$(0,1)\times(0,1)$é‡‡æ ·çš„ç‚¹$(x,y)$è¿›è¡Œcancatï¼Œå†é€åˆ°MLPä¸­</p>
</li>
<li><p>æŸå¤±å‡½æ•°ï¼šChamfer lossã€‚é€šè¿‡è®¡ç®—ä¸¤ä¸ªç‚¹é›†ä¹‹é—´çš„Chamfer Distanceæ¥æ¯”è¾ƒã€‚</p>
</li>
</ul>
<p>æ³¨æ„åˆ°MLPå¹¶æ²¡æœ‰æ˜ç¡®ç¦æ­¢æ‰€ç¼–ç çš„åŒºåŸŸé‡å ï¼ˆç¬¦åˆatlasçš„è¦æ±‚ä¹‹ä¸€ï¼‰ï¼Œå¹¶ä¸”æœ€å¥½è¦†ç›–æ•´ä¸ªshapeï¼ˆå…¨è¦†ç›–æ‰èƒ½ä½¿å¾—Chamfer losså˜å°ï¼‰</p>
</li>
<li><p>Implementation details</p>
<ul>
<li>auto-encoderä¸­çš„encoderæ˜¯PointNetï¼›å½¢çŠ¶æè¿°å­çš„ç»´åº¦ï¼š1024ï¼›è¾“å…¥ç‚¹äº‘çš„ç‚¹æ•°ï¼š250~2500</li>
<li>reconstructionä¸­çš„encoderæ˜¯ResNet-18ï¼›åªè®­ç»ƒencoderï¼Œè€Œdecoderåˆ™æ˜¯autoencoderä¸­çš„decoderï¼ˆå›ºå®šå‚æ•°ï¼Œä¸è®­ç»ƒï¼‰</li>
<li>decoderæ˜¯4å±‚çš„MLPï¼š1024ï¼ˆReLUï¼‰ã€512ï¼ˆReLUï¼‰ã€256ï¼ˆReLUï¼‰ã€128ï¼ˆtanhï¼‰ã€‚ä½¿ç”¨tanhçš„åŸå› å¯èƒ½æ˜¯ç‚¹äº‘ç»è¿‡å•ä½çƒåŒ–äº†</li>
<li>è¾“å‡ºç‚¹äº‘çš„ç‚¹æ•°ï¼š2500</li>
<li>2Dé‡‡æ ·æ–¹æ³•ï¼šç½‘æ ¼è§„åˆ™é‡‡æ ·</li>
</ul>
</li>
<li><p>Mesh generation</p>
<p>æœ‰ä¸‰ç§æ–¹æ³•ï¼š</p>
<ul>
<li>Propagate the patch-grid edges to the 3D pointsï¼šå³transfer a regular mesh on the unit square to 3Dï¼Œä½¿å¾—å¯ä»¥ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„meshï¼Œæ˜¯ä¸€ç§è‡ªç„¶çš„ç”Ÿæˆmeshçš„å¥½æ–¹æ³•ï¼ˆå› ä¸ºmeshçš„æ‹“æ‰‘è¿æ¥å…³ç³»æºè‡ªäº2D gridçš„edgeçš„è¿æ¥æ–¹å¼ï¼‰ã€AtlasNetä¸“ç”¨ï¼Œæ•ˆæœå¥½ã€‘</li>
<li>Generate a highly dense point cloud and use Poisson surface reconstructionï¼ˆPSRï¼‰ï¼šç”Ÿæˆå¾ˆå¤šç‚¹ä»¥åŠä»–ä»¬çš„normalsï¼Œç„¶åç”¨PSRæ–¹æ³•æ¥å¾—åˆ°meshã€Baselineä¸“ç”¨ï¼ŒAtlasNetå¯ç”¨ã€‘</li>
<li>Sample points on a closed surface rather than patchesï¼šä»3Dçƒé¢é‡‡æ ·è¾“å…¥çš„ç‚¹ï¼Œè€Œä¸æ˜¯ä»å¤šä¸ª2Då•ä½æ­£æ–¹å½¢ä¸­é‡‡æ ·ã€‚å¯ä»¥ç”Ÿæˆé—­åˆå›¾å½¢ï¼Œä½†æ˜¯ä¼¼ä¹åªèƒ½ç”¨ä¸€ä¸ªMLPã€‚ã€AtlasNetä¸“ç”¨ï¼Œè®°ä½œâ€œ1 sphereâ€ã€‘</li>
</ul>
</li>
</ol>
<h3 id="å®éªŒ-5"><a href="#å®éªŒ-5" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><ol>
<li><p>æ•°æ®é›†ï¼šstandard ShapeNet Core dataset</p>
</li>
<li><p>è¯„ä»·æŒ‡æ ‡ï¼šChamfer distanceï¼ˆCDï¼Œç”¨äºè¡¡é‡pointcloudï¼‰å’ŒMetroï¼ˆaverage Euclidean distance between the two meshesï¼Œç”¨äºè¡¡é‡meshï¼‰</p>
</li>
<li><p>Baseline/Oracle</p>
<ul>
<li>â€œPoints baselineâ€ï¼šå¦‚ä¸Šä¸€å¹…å›¾çš„ï¼ˆaï¼‰æ‰€ç¤ºã€‚ç›´æ¥è¾“å…¥1024ç»´åº¦çš„å½¢çŠ¶æè¿°å­ï¼Œç„¶åè¾“å‡º2500*3=7500ç»´åº¦ï¼Œå³2500ä¸ªç‚¹ï¼ˆMLPå±‚æ•°ä¸º1024ï¼ˆReLUï¼‰ã€512ï¼ˆReLUï¼‰ã€256ï¼ˆReLUï¼‰ã€7500ï¼ˆtanhï¼‰ï¼‰ã€‚æœ€ç»ˆè¾“å‡ºçš„æ˜¯pointcloudï¼Œæ‰€ä»¥æ²¡æœ‰â€œMetroâ€æŒ‡æ ‡ã€‚</li>
<li>â€œPointsbaseline + normalsâ€ï¼šè¾“å‡ºç©ºé—´æŒ‡æ ‡å’Œæ³•å‘é‡ï¼Œä¸€ä¸ªç‚¹æ˜¯$\mathbb{R}^6$ã€‚ç„¶åæ ¹æ®åˆ‡å¹³é¢æ¥å¢åŠ ç‚¹çš„æ•°é‡ï¼ˆAugmentationï¼‰ã€‚ç„¶åä½¿ç”¨PSRç®—æ³•å¾—åˆ°meshã€‚æœ€ç»ˆè¾“å‡ºçš„æ˜¯meshã€‚</li>
<li>Oracleï¼šä»GTä¸­éšæœºé‡‡æ ·ç‚¹ï¼Œç„¶åè®¡ç®—CDå’ŒMetroçš„å€¼ã€‚ä»£è¡¨äº†æ¨¡å‹æ‰€èƒ½è¾¾åˆ°çš„æ€§èƒ½çš„ä¸Šç•Œï¼ˆå› ä¸ºæ˜¯ç”±GTç”Ÿæˆçš„ï¼‰</li>
</ul>
</li>
<li><p>3D reconstructionç»“æœ</p>
<p><img src="11_2.png" alt></p>
</li>
<li><p>å…¶ä»–å®éªŒ</p>
<ul>
<li><p>Generalization across object categoriesï¼šç•¥</p>
</li>
<li><p>Singleview reconstructionï¼šç•¥</p>
</li>
<li><p>Shape interpolation</p>
<p><img src="11_3.png" alt></p>
</li>
<li><p>Finding shape correspondencesï¼šNotice that we get semantically meaningful correspondences, such as the chair back, seat, and legs without any supervision from the dataset on semantic information.</p>
<p><img src="11_4.png" alt></p>
</li>
<li><p>Mesh parameterizationï¼šour inferred atlas usually has relatively high texture distortion. But we can minimize distortion with off-theshelf geometric optimization, yielding small distortion.</p>
<p><img src="11_8.png" alt></p>
</li>
<li><p>Excess of distortion</p>
<p><img src="11_5.png" alt></p>
</li>
<li><p>Topological issues</p>
<p><img src="11_6.png" alt></p>
</li>
<li><p>Deformable shapes</p>
<p><img src="11_7.png" alt></p>
</li>
</ul>
</li>
</ol>
<h2 id="Deep-Marching-Cubes"><a href="#Deep-Marching-Cubes" class="headerlink" title="Deep Marching Cubes"></a>Deep Marching Cubes</h2><blockquote>
<p>CVPR2018ã€ŠDeep Marching Cubes: Learning Explicit Surface Representationsã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Liao_Deep_Marching_Cubes_CVPR_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/html/Liao_Deep_Marching_Cubes_CVPR_2018_paper.html</a></p>
</blockquote>
<h3 id="æ¦‚è¿°-9"><a href="#æ¦‚è¿°-9" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>æå‡ºäº†ä¸€ç§end-to-endçš„surface predictionæ–¹æ³•ã€‚å³â€œDifferentiable Marching Cubes Layerâ€ï¼Œä½¿å¾—å¯ä½œä¸ºç¥ç»ç½‘ç»œçš„æœ€åä¸€å±‚æ¥è¾“å‡ºmeshã€‚å¹¶ä¸”è®¾è®¡äº†losså‡½æ•°ä½¿å¾—å¯ä»¥åœ¨sparse point supervisionä¸Šè®­ç»ƒã€‚å¹¶ä¸”èƒ½è¡¥å…¨å½¢çŠ¶ã€åˆ†ç¦»ç‰©ä½“çš„å†…å¤–è¡¨é¢ï¼Œå³ä½¿åœ¨GTæ˜¯ç¨€ç–å’Œä¸å®Œå…¨çš„æƒ…å†µä¸‹ã€‚å¯ä»¥ç”¨äºä»ç‚¹äº‘ä¸­æ¨æ–­å½¢çŠ¶ã€‚å¯ä»¥ä¸å„ç§encoderã€shape inference techniquesç»“åˆä½¿ç”¨ã€‚</p>
<p>ç‰¹ç‚¹ï¼š</p>
<ul>
<li>differentiable, end-to-end</li>
<li>predicts explicit surface representations of arbitrary topology</li>
<li>avoids the need for defining auxiliary losses or converting target meshes to implicit distance fields</li>
<li>more accurate reconstructions while also handling noise and missing observations</li>
<li>separating inside from outside even if the ground truth is sparse or not watertight</li>
<li>easily integrating additional priors about the surfaceï¼ˆe.g., smoothnessï¼‰</li>
<li>does not require explicit surface ground truth</li>
</ul>
<p>æ³¨ï¼š</p>
<ul>
<li>æ™®é€šçš„marching cubesçš„è¾“å…¥æ˜¯SDFï¼Œè€Œdeep marching cubesè¾“å…¥æ˜¯$O$å’Œ$X$ã€‚æ‰€ä»¥ç½‘ç»œçš„è¾“å‡ºç±»å‹ä¹Ÿè¦è¦æ±‚ä¸åŒã€‚</li>
<li>ç°æœ‰çš„3D surface predictionä¸èƒ½end-to-endè®­ç»ƒï¼Œå› ä¸ºä»–ä»¬éœ€è¦ä¸­é—´è¡¨ç¤ºï¼ˆä¾‹å¦‚TSDFï¼‰ï¼Œå› è€Œéœ€è¦åå¤„ç†ï¼ˆä¾‹å¦‚marching cubesç®—æ³•ï¼‰</li>
<li>æ™®é€šçš„marching cubesç®—æ³•ä¸å¯å¾®åˆ†</li>
<li>ä¼ ç»Ÿçš„è¡¨é¢é‡å»ºæ–¹æ³•ï¼š<ul>
<li>Voxel based method <ul>
<li>output: voxel occupancy / TSDF</li>
<li>post-processing: Marching cubes</li>
</ul>
</li>
<li>Point based method<ul>
<li>output: points</li>
<li>post-processing: Poisson surface reconstruction / SSD</li>
</ul>
</li>
</ul>
</li>
<li>ä¼ ç»Ÿæ–¹æ³•çš„ç¼ºç‚¹ï¼š<ul>
<li>the ground truth of the implicit representation is often hard to obtain, e.g., in the presence of a noisy and incomplete point cloud or when the inside and outside of the object is unknown.</li>
<li>these methods only optimize an auxiliary loss defined on an intermediate representation and require an additional postprocessing step for surface extraction. Thus they are unable to directly constrain the properties of the predicted surface.</li>
</ul>
</li>
</ul>
<h3 id="å®ç°-11"><a href="#å®ç°-11" class="headerlink" title="å®ç°"></a>å®ç°</h3><ol>
<li><p>ä¼ ç»Ÿçš„Marching Cubesï¼ˆéæœ¬æ–‡çš„æ–¹æ³•ï¼‰</p>
<p>åˆ†ä¸ºä¸¤æ­¥ï¼š</p>
<ul>
<li>estimation of the topologyï¼šç¡®å®šcellçš„æ‹“æ‰‘ç±»å‹ï¼ˆé¢çš„é¡¶ç‚¹ä½ç½®ä¸ç¡®å®šï¼Œåªæ˜¯çŸ¥é“æ‹“æ‰‘æ¦‚å¿µä¸Šçš„ä½ç½®ï¼‰</li>
<li>prediction of the vertex locations of the trianglesï¼šç¡®å®šé¢çš„é¡¶ç‚¹çš„å…·ä½“ä½ç½®</li>
</ul>
<p>è®°å·ï¼š</p>
<ul>
<li>$D \in \mathbb{R}^{N\times N\times N}$ä¸ºsigned distance fieldã€‚è¡¨ç¤ºåˆ°surfaceçš„æœ‰å‘è·ç¦»ã€‚å†…éƒ¨ä¸ºæ­£ï¼Œå¤–éƒ¨ä¸ºè´Ÿï¼Œè¡¨é¢ä¸ºé›¶ã€‚å…¶å…ƒç´ è®°ä½œ$d_n$ï¼Œå…¶ä¸­$n=(i,j,k)\in \mathbb{N}^3$æ˜¯ç´¢å¼•</li>
</ul>
<p>å®ç°ï¼š</p>
<ul>
<li><p>é¦–å…ˆç¡®å®šcellâ€™s surface topology Tã€‚å‡è®¾$D\in \mathbb{R}^{3\times 3\times 3}$ï¼Œé‚£ä¹ˆç›¸å½“äºè¿™27ä¸ªç‚¹åˆ†å¸ƒåœ¨äºŒé˜¶é­”æ–¹çš„å„ä¸ªè§’å—çš„é¡¶è§’ä¸Šï¼Œå®ƒåªæ˜¯ç‚¹ã€‚cellå°±æ˜¯æŒ‡äºŒé˜¶é­”æ–¹çš„8ä¸ªè§’å—ï¼Œå®ƒå…·æœ‰ä½“ç§¯ã€‚ç„¶åæ ¹æ®dæ˜¯å¦ç¬¦å·æ”¹å˜ï¼ˆç©¿è¿‡é›¶ï¼‰ç¡®å®šè¿™ä¸ªcellçš„æ‹“æ‰‘ç±»å‹ã€‚ï¼ˆåªæ˜¯ç¡®å®šäº†æ‹“æ‰‘ç±»å‹ï¼Œå›¾ä¸­è“è‰²é¢çš„é¡¶ç‚¹çš„å…·ä½“ä½ç½®å¹¶ä¸çŸ¥é“ï¼Œéœ€è¦ä¸‹ä¸€æ­¥æ¥è®¡ç®—ï¼‰</p>
<p><img src="12_1.png" alt></p>
</li>
<li><p>ç„¶åå¦‚æœè¿™ä¸ªcellå†…éƒ¨å­˜åœ¨è“è‰²å¹³é¢ï¼Œå°±éœ€è¦è®¡ç®—è“è‰²å¹³é¢é¡¶ç‚¹çš„å…·ä½“ä½ç½®ã€‚ä½¿ç”¨çº¿æ€§æ’å€¼å¾—åˆ°ã€‚ï¼ˆå¦‚æœæ˜¯ä¸Šå›¾ä¸­çš„å·¦ä¸Šè§’çš„ç¬¬ä¸€ç§ç±»å‹ï¼Œé‚£å°±ä¸ç”¨è®¡ç®—äº†ï¼Œè¿™ç§ç±»å‹å¾€å¾€å‡ºç°åœ¨ç‰©ä½“çš„å†…éƒ¨ã€æˆ–è€…æ˜¯è¿œç¦»ç‰©ä½“çš„å¤–éƒ¨ï¼‰</p>
<p><img src="12_2.png" alt></p>
</li>
</ul>
</li>
<li><p>Differentiable Marching Cubes</p>
<p>è®°å·ï¼š</p>
<ul>
<li><p>æ¯ä¸ªæ ¼ç‚¹çš„ä¼¯åŠªåˆ©åˆ†å¸ƒå‚æ•°ï¼š$O\in [0,1]^{N\times N\times N}$ï¼Œ$o_n\in[0,1]$</p>
</li>
<li><p>æ¯ä¸ªæ ¼ç‚¹çš„é¢é¡¶ç‚¹çš„åç§»é‡ï¼š$X\in [0,1]^{N\times N\times N\times3}$ï¼Œ$x_n\in [0,1]^3$</p>
</li>
</ul>
<p>è®¡ç®—ï¼š</p>
<ul>
<li>é‚£ä¹ˆæ ¼ç‚¹$n$å¤„äºçŠ¶æ€$t\in \{0,1\}$ï¼ˆ1ä»£è¡¨è¢«å æ®ï¼ˆçº¢è‰²è¡¨ç¤ºï¼‰ï¼Œ0ä»£è¡¨ä¸è¢«å æ®ï¼ˆç»¿è‰²è¡¨ç¤ºï¼‰ï¼‰æ—¶çš„æ¦‚ç‡ä¸º$p_n(t)=(o_n)^t(1-o_n)^{1-t}$</li>
<li>é‚£ä¹ˆgrid cell nå¤„äºçŠ¶æ€$T$æ—¶çš„æ¦‚ç‡ä¸º$p_n(T)=\prod_{m\in \{0,1\}^3}(o_{n+m})^{t_m}(1-o_{n+m})^{1-t_m}$ã€‚å…¶ä¸­$2^8$ç§é¡¶ç‚¹çš„æ’åˆ—æ–¹å¼ä¸­åªæœ‰140ç§æ˜¯æœ‰æ•ˆçš„æ‹“æ‰‘å½¢å¼ã€‚</li>
<li>é‚£ä¹ˆentire gridçš„æ¦‚ç‡åˆ†å¸ƒå°±æ˜¯$p(\{T_n\})=\prod_{n\in\mathcal{T}}p_n(T_n)$ã€‚å…¶ä¸­$\mathcal{T}=\{1,â€¦,N-1\}^{3}$æœ‰$(N-1)^3$ä¸ªcell</li>
</ul>
<p>ç½‘ç»œç»“æ„å›¾ï¼šï¼ˆè¾“å…¥ç‚¹äº‘ï¼Œç„¶åé¢„æµ‹å‡º$O$å’Œ$X$ï¼Œä»è€Œé¢„æµ‹å‡ºmeshï¼‰</p>
<p><img src="12_3.png" alt></p>
<p>Lossï¼šï¼ˆåŒ…å«4é¡¹ï¼‰</p>
<ul>
<li>Point to Mesh Lossï¼šæœ€å°åŒ–observed 3D pointsåˆ°meshå¹³é¢çš„å‡ ä½•è·ç¦»ä¹‹å’Œã€‚ä½œç”¨ï¼šdirectly<br>measures the geometric error of the inferred mesh</li>
<li>Occupancy Lossï¼šé¼“åŠ±è¾¹ç•Œä¸Šä¸è¢«å æ®ï¼Œé¼“åŠ±å†…éƒ¨è¢«å æ®</li>
<li>Smoothness Lossï¼šé¼“åŠ±ç›¸é‚»æ ¼ç‚¹çš„å æ®çŠ¶æ€ä¸å˜</li>
<li>Curvature Lossï¼šé¼“åŠ±ç›¸é‚»cellçš„normal orientationçš„smooth transitions</li>
</ul>
</li>
</ol>
<h2 id="DeepSDF-ğŸ‘"><a href="#DeepSDF-ğŸ‘" class="headerlink" title="DeepSDF ğŸ‘"></a>DeepSDF ğŸ‘</h2><blockquote>
<p>CVPR2019ã€ŠDeepSDF: Learning Continuous Signed Distance Functions for Shape Representationã€‹</p>
<p>paperä¸‹è½½ï¼š<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_CVPR_2019/html/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.html</a></p>
</blockquote>
<h3 id="æ¦‚è¿°-10"><a href="#æ¦‚è¿°-10" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h3><p>DeepSDFèƒ½ç”Ÿæˆå…·æœ‰å¤æ‚æ‹“æ‰‘ç»“æ„çš„ã€é«˜è´¨é‡çš„ã€é—­åˆçš„è¿ç»­è¡¨é¢ã€å¯ç”¨äºå½¢çŠ¶æ’å€¼ã€å½¢çŠ¶è¡¥å…¨ã€‚DeepSDFèƒ½å¤Ÿè¡¨ç¤ºç±»åˆ«çš„å½¢çŠ¶ï¼ˆè€Œä¼ ç»Ÿçš„SDFæ–¹æ³•åªèƒ½è¡¨ç¤ºä¸€ä¸ªç‰©ä½“çš„å½¢çŠ¶ï¼‰ã€‚å–å¾—äº†SOTAã€‚è€Œä¸”æ¨¡å‹çš„å¤§å°ç¼©å°äº†ã€‚</p>
<p><img src="13_3.png" alt></p>
<p>æœ¬è´¨ï¼šä½¿ç”¨â€œcoordinate + shape latent vectorâ€ä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡MLPåè¾“å‡ºSDFå€¼ã€‚è®­ç»ƒæ—¶åŒæ—¶ä¼˜åŒ–â€œshape vectorâ€å’Œâ€œMLP parametersâ€ï¼ˆæ¢¯åº¦ä¸‹é™ä¼˜åŒ–ï¼Œæœ€åå¾—åˆ°çš„shape vectorå°±æ˜¯è®­ç»ƒé›†çš„shape vectorï¼‰ã€‚æ¨æ–­â€œlatent vectorâ€æ—¶ä½¿ç”¨æ¢¯åº¦ä¸‹é™ä¸æ–­è¿­ä»£ä¼˜åŒ–â€œlatent vectorâ€çš„åˆå§‹å€¼ï¼Œä»è€Œå¾—åˆ°ç¬¦åˆobservationçš„latent vectorçš„å€¼ã€‚</p>
<p>æ³¨ï¼š</p>
<ul>
<li>DeepSDFæœ€æœ‰ç”¨çš„ç”¨é€”æ˜¯Shape Completionï¼ˆinference + feed-forward + marchingcubesï¼‰ã€Shape Interpolationï¼ˆinference + interpolate + feed-forward + marchingcubesï¼‰</li>
<li>SDFï¼šæœ‰å‘è·ç¦»å‡½æ•°ï¼šå†…éƒ¨è´Ÿæ•°ã€å¤–éƒ¨æ­£æ•°ã€è¡¨é¢ä¸ºé›¶ã€‚</li>
<li>â€œauto-decoderâ€å¯ç”¨äºé™å™ªã€è¡¥å…¨ã€é”™è¯¯æ£€æµ‹</li>
<li>è¡¥å…¨ï¼šåªè¾“å…¥éƒ¨åˆ†æ•°æ®ï¼Œç„¶åç”Ÿæˆlatent vectorï¼ˆå½¢çŠ¶ä¿¡æ¯ï¼‰ï¼Œå†ç”Ÿæˆå®Œæ•´çš„shape prediction</li>
<li>æœ€åè¿˜æ˜¯è¦ç”¨marching cubesæ¥ç”Ÿæˆç­‰å€¼é¢</li>
<li>feed-forwardè€—æ—¶çŸ­ï¼›inferenceè€—æ—¶é•¿ï¼ˆå¯¹latent vectorçš„ä¼˜åŒ–é€Ÿåº¦æ…¢ï¼Œæˆ–è®¸å¯ä»¥è€ƒè™‘æ›¿æ¢æ‰ADAMä¼˜åŒ–å™¨ï¼‰</li>
</ul>
<p>TODO IDEAï¼š</p>
<ul>
<li>æˆ–è®¸å¯ä»¥ç”¨äºç”ŸæˆåŠ¨æ€çš„3Dç‰©ä½“ã€æˆ–è€…æ˜¯å¸¦æœ‰çº¹ç†æè´¨çš„ç‰©ä½“ã€‚</li>
<li>ä¸åŒç‰©ä½“å½¢çŠ¶åœ¨latent vectoråˆ†å¸ƒä¸­çš„ä½ç½®ä¸èƒ½æŒ‡å®šã€‚æˆ–è®¸latent vectorå¯ä»¥æ˜¯ç±»ä¼¼one-hotçš„ï¼Œä¸€ä¸ªå˜é‡ä»£è¡¨ä¸€ä¸ªç‰©ä½“ç§ç±»ï¼Œæ¯ä¸ªå˜é‡éƒ½æœä»é«˜æ–¯ï¼Œç„¶ååªéœ€è¦ä»é«˜æ–¯é‡‡æ ·å°±èƒ½å¾—åˆ°ç‰©ä½“å½¢çŠ¶äº†ã€‚å¯èƒ½ç±»ä¼¼äºVariational Auto-Decoderï¼Ÿ</li>
</ul>
<h3 id="å®ç°-12"><a href="#å®ç°-12" class="headerlink" title="å®ç°"></a>å®ç°</h3><p>é€šè¿‡å­¦ä¹ ä¸€ä¸ªâ€œshape-conditioned classifierâ€ï¼Œå†³ç­–è¾¹ç•Œï¼ˆæœ€åä¸€å±‚æ˜¯tanhï¼‰å°±æ˜¯ç‰©ä½“è¡¨é¢ã€‚</p>
<p>ä½¿ç”¨â€œauto-decoderâ€ï¼Œæ¥å—latent vectorå’Œpoint coordinateä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºSDFå€¼ã€‚</p>
<ul>
<li>trainingï¼šå·²çŸ¥observationï¼ˆç‚¹åæ ‡&amp;SDFï¼‰æ¥ä¼˜åŒ–latent vector $z$å’Œmodel parameters $\theta$</li>
<li>inferenceï¼šå·²çŸ¥observationï¼ˆç‚¹åæ ‡&amp;SDFï¼‰æ±‚latent vector $z$</li>
<li>feed-forwardï¼šå·²çŸ¥latent vector $z$å’Œç‚¹åæ ‡ï¼Œæ±‚SDF</li>
</ul>
<p><img src="13_1.png" alt></p>
<p>è®°å·ï¼š</p>
<ul>
<li>coordinate $x$ä¸¢åˆ°æ¨¡å‹é‡Œå¾—åˆ°çš„SDFä¼°è®¡ï¼ˆlatent vectorä¸º$z$ï¼‰ï¼š$f_\theta(z,x)$</li>
<li>ç¬¬iä¸ªå½¢çŠ¶çš„coordinate $x$å¤„çœŸå®çš„SDFå€¼ï¼š${SDF^i}(x)$</li>
<li>ç¬¬iä¸ªå½¢çŠ¶çš„æ•°æ®é›†ï¼ˆåŒ…å«ç‚¹åæ ‡ã€çœŸå®çš„SDFå€¼ï¼‰ï¼š$X_i := \{(x_j,s_j):s_j=SDF^i(x_j)\}$</li>
</ul>
<p>ç¬¬ä¸€ç§æ–¹å¼æ˜¯ä½¿ç”¨ä¸Šå›¾ï¼ˆaï¼‰æ‰€ç¤ºçš„æ–¹æ³•ã€‚ä½†æ˜¯ä¸€ä¸ªæ¨¡å‹åªèƒ½å¯¹åº”ä¸€ä¸ªç‰©ä½“ã€‚æ•…æˆ‘ä»¬ä¸é‡‡ç”¨ã€‚</p>
<p>ç¬¬äºŒç§æ–¹å¼æ˜¯ä½¿ç”¨ä¸Šå›¾ï¼ˆbï¼‰æ‰€ç¤ºçš„æ–¹æ³•ã€‚ä¸€ä¸ªæ¨¡å‹å¯ä»¥å¯¹åº”ä¸€æ•´ç±»ç‰©ä½“ï¼ˆä¾‹å¦‚å„ç§å°è½¦ï¼‰ã€‚æˆ‘ä»¬é‡‡æ ·è¿™ç§æ–¹æ³•ã€‚ä½†æ˜¯codeæœªçŸ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨â€œauto-decoderâ€çš„å­¦ä¹ æ–¹å¼æ¥è‡ªåŠ¨å­¦ä¹ codeçš„åˆ†å¸ƒï¼ˆæ³¨æ„è¿™é‡Œçš„codeä¸æ˜¯äººä¸ºæŒ‡å®šçš„åˆ†å¸ƒï¼Œä¾‹å¦‚ä¸æ˜¯one-hotï¼‰</p>
<ul>
<li><p>è®­ç»ƒï¼ˆtrainingï¼‰ï¼šæˆ‘ä»¬é¦–å…ˆåˆå§‹åŒ–codeä¸ºä¸€ä¸ªå¾ˆå°çš„å€¼ï¼ˆä¾‹å¦‚$\mathcal{N}(0,0.01^2)$ï¼‰ï¼Œç„¶åæ ¹æ®å·²çŸ¥çš„coordinateå’ŒSDFå€¼æ¥è®­ç»ƒç½‘ç»œï¼Œåå‘ä¼ æ’­æ—¶æ ¹æ®$\frac{\partial Loss}{\partial z_i}$å’Œ$\frac{\partial Loss}{\partial \theta}$åˆ†åˆ«æ›´æ–°Code $z_i$å’ŒParameter $\theta$ã€‚</p>
<p><img src="13_5.png" alt></p>
</li>
<li><p>æ¨æ–­ï¼ˆinferenceï¼‰ï¼šæ ¹æ®å·²çŸ¥çš„coordinateå’ŒSDFå€¼ï¼Œåˆ©ç”¨åå‘ä¼ æ’­çš„$\frac{\partial Loss}{\partial z}$ï¼Œæ›´æ–°ä¼˜åŒ–Code $z$</p>
<p><img src="13_4.png" alt></p>
</li>
<li><p>å‰å‘ä¼ æ’­ï¼ˆæš‚ä¸”ç§°ä½œfeed-forwardå§ï¼‰ï¼šæ ¹æ®latent vector $z$å’Œç‚¹åæ ‡$x$å¾—åˆ°é¢„æµ‹çš„SDFå€¼</p>
</li>
</ul>
<p>æ³¨ï¼š</p>
<ul>
<li><p>è¿˜å¯ä»¥è®¡ç®—å¾—åˆ°surface normalsï¼šæ–¹æ³•ä¸€å’ŒäºŒï¼ˆé‡‡ç”¨SDFçš„æ–¹æ³•ï¼‰éƒ½èƒ½é€šè¿‡è®¡ç®—$\frac{\partial f_\theta(x)}{\partial x}$æ¥è®¡ç®—ä¼°è®¡å¾—åˆ°çš„è¡¨é¢æ³•å‘ï¼ˆå› ä¸ºæ²¿ç€æ³•çº¿æ–¹å‘SDFå˜åŒ–æœ€å¿«ï¼‰</p>
</li>
<li><p>å¯¹äºä¸€ä¸ªç‚¹çš„æŸå¤±å‡½æ•°ï¼š$\mathcal{L}(f_\theta(x),s)=|clamp(f_\theta(x),\delta)-clamp(s,\delta)|$ï¼Œä»¥$f_\theta(x)$ã€$s$ä¸ºxã€yè½´ç”»å›¾å¾—ï¼ˆ$\delta$è¶Šå°è¶Šèƒ½æè¿°è¡¨é¢çš„ç»†èŠ‚ï¼‰ï¼š</p>
<p><img src="13_2.png" alt></p>
</li>
<li><p>â€œauto-decoderâ€æ˜¯å¯¹â€œcoded shape deepsdfâ€çš„è®­ç»ƒæ–¹å¼ã€‚</p>
</li>
<li><p>ä¸ºä»€ä¹ˆä¸ç”¨â€œencoder-decoderâ€ç»“æ„ï¼š</p>
<p>ä¼ ç»Ÿçš„â€œencoder-decoderâ€ç»“æ„çš„ä½¿ç”¨æ–¹æ³•ï¼š</p>
<ul>
<li>è®­ç»ƒï¼šâ€œencoder-decoderâ€ä¸¤éƒ¨åˆ†ä¸€èµ·è®­ç»ƒ</li>
<li>æµ‹è¯•ï¼šä¸¢æ‰è®­ç»ƒå¥½çš„encoderã€‚åœ¨å½¢çŠ¶è¡¥å…¨ä»»åŠ¡ä¸­ï¼Œé¦–å…ˆå‡†å¤‡å¾…è¡¥å…¨çš„è®­ç»ƒæ•°æ®ï¼Œç„¶åé‡æ–°è®­ç»ƒå¦ä¸€ä¸ªencoderã€‚</li>
</ul>
<p>ä½œè€…è®¤ä¸ºè®­ç»ƒâ€œencoder-decoderâ€ç»“æ„æ—¶ï¼Œæœ€åä½¿ç”¨æ—¶åªæ˜¯ç”¨åˆ°äº†decoderï¼Œè€Œæ²¡æœ‰ç”¨åˆ°è®­ç»ƒå®Œæˆçš„encoderï¼Œæå¤§æµªè´¹äº†è®¡ç®—åŠ›ã€‚å¹¶ä¸”ä½¿ç”¨â€œencoder-decoderâ€è¿›è¡Œå½¢çŠ¶è¡¥å…¨æ—¶ï¼Œè®­ç»ƒæ–°çš„encoderæ—¶çš„è®­ç»ƒæ•°æ®ä¹Ÿè¦æ˜¯â€œå¾…è¡¥å…¨â€çš„æ•°æ®é›†ï¼ˆè¿™æ ·æ‰èƒ½ä»è¾“å…¥æ¨æ–­å‡ºlatent vectorï¼‰ã€‚</p>
</li>
<li><p>DeepSDFå¯ä»¥åªè¾“å…¥éƒ¨åˆ†çš„observationï¼ˆä¾‹å¦‚depth mapä¸­ç‚¹ï¼Œåªæ˜¯éƒ¨åˆ†çš„è¡¨é¢çš„ç‚¹ï¼‰ï¼Œç„¶åæ¨æ–­å‡ºlatent vector $z$çš„å€¼ï¼Œæ‰€ä»¥å¯ä»¥ç”¨äºå½¢çŠ¶è¡¥å…¨ã€‚</p>
</li>
<li><p>æ•´ä¸ªå®ç°éƒ½æ˜¯åŸºäºåœ¨ç‰©ä½“å¯¹é½çš„æ¡ä»¶ä¸‹è¿›è¡Œçš„ï¼ˆin a canonical poseï¼‰ã€‚å¦åˆ™åŒä¸€ä¸ªcoordinateä¼šå› ä¸ºä¸å¯¹é½ï¼ˆä¾‹å¦‚æ—‹è½¬ï¼‰è€Œä¼šæœ‰ä¸åŒçš„SDFå€¼</p>
</li>
</ul>
<h3 id="å®ç°-13"><a href="#å®ç°-13" class="headerlink" title="å®ç°"></a>å®ç°</h3><p>å®æ–½ç»†èŠ‚è§å‰é¢çš„éƒ¨åˆ†ã€‚ä¸‹é¢æ˜¯å®éªŒéƒ¨åˆ†ï¼ˆä½¿ç”¨ShapeNetï¼‰ï¼š</p>
<ol>
<li><p>Representing Known 3D Shapesï¼ˆrepresent training dataï¼‰</p>
<p>ç”¨äºæµ‹è¯•latent vectorå’ŒMLPæ˜¯å¦èƒ½å……åˆ†è¡¨ç¤ºç²¾ç»†çš„ç»“æ„ã€‚æ‰€ä½¿ç”¨çš„ç‰©ä½“æ˜¯åœ¨è®­ç»ƒé›†å†…çš„ã€‚</p>
<p>å®ç°è¿‡ç¨‹ï¼šåˆ©ç”¨GTï¼ˆåœ¨è®­ç»ƒé›†ä¸­ï¼‰çš„$X$ï¼ˆåŒ…å«point coordinateå’ŒSDFï¼‰æ¥inferenceå¾—åˆ°è¿™ä¸ªç‰©ä½“æ‰€å¯¹åº”çš„latent vectorçš„å€¼ï¼›ç„¶åè¾“å…¥latent vectorå’Œå¯†é›†ç½‘æ ¼é‡‡æ ·çš„point coordinateï¼Œé€šè¿‡æ­£å‘ä¼ æ’­å¾—åˆ°é¢„æµ‹çš„SDFå€¼ï¼Œå†ç”¨marching cubesæ¥é‡å»ºè¡¨é¢ã€‚</p>
</li>
<li><p>Representing Test 3D Shapesï¼ˆuse learned feature representation to reconstruct unseen shapesï¼‰</p>
<p>ç”¨äºæµ‹è¯•â€œå¾—åˆ°latent vectorçš„æ–¹æ³•â€æ˜¯å¦èƒ½ç”¨äºå…¨æ–°æœªè§è¿‡çš„ç‰©ä½“</p>
<p>å®ç°è¿‡ç¨‹ï¼šåˆ©ç”¨GTï¼ˆä¸åœ¨è®­ç»ƒé›†ä¸­ï¼‰é€šè¿‡inferenceçš„æ–¹æ³•å¾—åˆ°latent vectorï¼›å†æ­£å‘ä¼ æ’­ã€marching cubeså¾—åˆ°è¡¨é¢ã€‚</p>
</li>
<li><p>Shape Completionï¼ˆapply shape priors to complete partial shapesï¼‰</p>
<p>å·²çŸ¥ç‰©ä½“è¡¨é¢çš„ä¸€äº›éƒ¨åˆ†ï¼ˆä¾‹å¦‚depth mapåªæ¶‰åŠä¸€äº›è¡¨é¢ï¼‰ï¼Œæ±‚æ•´ä¸ªç‰©ä½“çš„å½¢çŠ¶</p>
<p>å®ç°è¿‡ç¨‹ï¼šæ ¹æ®depth mapå¯ä»¥çŸ¥é“ä½äºsurfaceä¸Šçš„ç‚¹ï¼Œç„¶åä¼°è®¡surface normalã€‚æ²¿ç€surface normalçš„æ–¹å‘åç§»$\pm \eta$çš„è·ç¦»å¾—åˆ°ä¸¤ä¸ªç‚¹ï¼ˆä½äºsurfaceä¸¤ä¾§ä¸”è·ç¦»surface$\eta$çš„ä¸¤ä¸ªç‚¹ï¼‰ï¼Œè¿™æ ·å°±å¾—åˆ°SDFçš„æ ·æœ¬æ•°æ®ã€‚åˆ©ç”¨SDFæ ·æœ¬æ•°æ®å…ˆinferenceå¾—åˆ°latent vectorï¼Œå†æ­£å‘ä¼ æ’­ã€marching cubeå°±èƒ½å¾—åˆ°meshã€‚</p>
<p>æ³¨ï¼šdepth mapçš„è§†è§’éœ€è¦ä¸ç‰©ä½“å¯¹é½ã€‚ä½œè€…è¿˜é¢å¤–ä»â€œä»‹äºsurfaceå’Œcameraä¹‹é—´çš„free-spaceâ€ä¸­éšæœºé‡‡æ ·ä¸€äº›ç‚¹ä½œä¸ºempty space pointsï¼ˆæˆ–è€…ç§°ä½œfree-space observationsï¼Œä¸”SDFå€¼å¤§äºé›¶ï¼‰ï¼Œä½¿å¾—æ ·æœ¬çš„ç‚¹æ•°å¢åŠ ï¼Œä¸”ä¸ä¼šåœ¨free-spaceä¸­ç”Ÿæˆå¥‡æ€ªçš„å½¢çŠ¶ã€‚è€Œä¸”æ·»åŠ äº†â€œfreespace lossâ€ã€‚</p>
</li>
<li><p>Latent Space Shape Interpolationï¼ˆlearn smooth and complete shape embedding space from which we can sample new shapesï¼‰</p>
<p>è¿‡ç¨‹ï¼šåˆ©ç”¨trainingæœ€åæ—¶å¾—åˆ°çš„latent vectorï¼ˆæˆ–inferenceå¾—åˆ°çš„éƒ½å¯ä»¥ï¼‰ï¼Œå°†ä¸¤ä¸ªç‰©ä½“çš„latent vectorçº¿æ€§æ’å€¼å†feed-forwordå¾—åˆ°ä¸­é—´çŠ¶æ€çš„ç‰©ä½“</p>
</li>
</ol>

            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">èµ</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">ç»™å°ç¼–åŠ ä¸ªé¸¡è…¿ğŸ—å‘—</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">æ”¯ä»˜å®</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">å¾® ä¿¡</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="æ”¯ä»˜å®æ‰“èµäºŒç»´ç ">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="å¾®ä¿¡æ‰“èµäºŒç»´ç ">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>å¾®ä¿¡é‡Œç‚¹â€œå‘ç°â€->â€œæ‰«ä¸€æ‰«â€äºŒç»´ç ä¾¿å¯æŸ¥çœ‹åˆ†äº«ã€‚</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>è½¬è½½è§„åˆ™</span>
        </p>
        
            <div class="center-align">
                <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    ã€Š3Dç»“æ„é‡å»ºã€‹
                </span> ç”±
            <a xmlns:cc="http://creativecommons.org/ns#" href="/3d/3dreconstruction/" property="cc:attributionName"
               rel="cc:attributionURL">
                Karbo
            </a> é‡‡ç”¨
            <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                çŸ¥è¯†å…±äº«ç½²å 4.0 å›½é™…è®¸å¯åè®®
            </a>è¿›è¡Œè®¸å¯ã€‚
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: 'WwrKLalwiFrnKlAcLCjpeyK7-gzGzoHsz',
        appKey: 'zF7jn8hejoyxVPESEeCAxCzY',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'ãƒ¾ï¾‰â‰§âˆ€â‰¦)oæ¥è¯„è®ºå•Šï¼Œå¿«æ´»å•Š!'
    });
</script>
    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-dot-circle-o"></i>&nbsp;æœ¬ç¯‡
            </div>
            <div class="card">
                <a href="/3d/3dreconstruction/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/17.jpg" class="responsive-img" alt="3Dç»“æ„é‡å»º">
                        
                        <span class="card-title">3Dç»“æ„é‡å»º</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æœ¬æ–‡æ˜¯3Dé‡å»ºçš„å­¦ä¹ ç¬”è®°
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-10-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/3d/" class="post-category" target="_blank">
                                    3d
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/3d/" target="_blank">
                        <span class="chip bg-color">3d</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/english/englishgrammar/">
                    <div class="card-image">
                        
                        <img src="/english/englishgrammar/1.jpg" class="responsive-img" alt="è‹±è¯­è¯­æ³•åŸºç¡€">
                        
                        <span class="card-title">è‹±è¯­è¯­æ³•åŸºç¡€</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ç®€å•ä»‹ç»äº†è‹±è¯­çš„åŸºæœ¬è¯­æ³•è§„åˆ™
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-10-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/english/" class="post-category" target="_blank">
                                    english
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/english/" target="_blank">
                        <span class="chip bg-color">english</span>
                    </a>
                    
                    <a href="/tags/grammar/" target="_blank">
                        <span class="chip bg-color">grammar</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            æœ¬ç«™ç”±
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">hexo-theme-matery</a>ä¸»é¢˜æ­å»º.

            
            &nbsp;<i class="fa fa-area-chart"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;
            <span class="white-color">89.3k</span>
            

            
            
            <br>
            
            <span id="busuanzi_container_site_pv">
                <i class="fa fa-heart-o"></i>
                æœ¬ç«™æ€»è®¿é—®é‡ <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                <i class="fa fa-users"></i>
                æ¬¡,&nbsp;è®¿å®¢æ•° <span id="busuanzi_value_site_uv" class="white-color"></span> äºº.
            </span>
            
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
<a href="https://github.com/Karbo123" class="tooltipped" target="_blank" data-tooltip="æˆ‘çš„GitHub" data-position="top"
    data-delay="50">
    <i class="fa fa-github"></i>
</a>



<a href="https://www.zhihu.com/people/karbo-50/activities" class="tooltipped" target="_blank" data-tooltip="æˆ‘çš„çŸ¥ä¹" data-position="top"
    data-delay="50">
    <i class="fa fa-user"></i>
</a>



<a href="mailto:lei@karbo.online" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»"
    data-position="top" data-delay="50">
    <i class="fa fa-envelope-open"></i>
</a>



<a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS è®¢é˜…" data-position="top"
    data-delay="50">
    <i class="fa fa-rss"></i>
</a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>

<!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
<!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


</body>
</html>