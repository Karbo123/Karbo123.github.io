<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="3D结构重建, 任我行">
    <meta name="description" content="3D重建介绍3D重建的各种模型框架方法等。
3D-R2N2
ECCV2016《3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction》
p">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>3D结构重建 | 任我行</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">任我行</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">任我行</div>
        <div class="logo-desc">
            
            可以任我走怎么到头来又随着大队走，人群是那么像羊群
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Karbo123" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Karbo123" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>





<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/17.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        3D结构重建
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/3d/" target="_blank">
                                <span class="chip bg-color">3d</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/3d/" class="post-category" target="_blank">
                                3d
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-10-08
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                        6.6k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        28 分
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="3D重建"><a href="#3D重建" class="headerlink" title="3D重建"></a>3D重建</h1><p>介绍3D重建的各种模型框架方法等。</p>
<h2 id="3D-R2N2"><a href="#3D-R2N2" class="headerlink" title="3D-R2N2"></a>3D-R2N2</h2><blockquote>
<p>ECCV2016《3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction》</p>
<p>paper下载：<a href="https://arxiv.org/abs/1604.00449" target="_blank" rel="noopener">https://arxiv.org/abs/1604.00449</a></p>
</blockquote>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>提出3D-R2N2网络，能够输入一张/多张图片并重建出3D occupancy grid，该方法在训练/测试阶段不需要任何的图像标注和物体类别标签（但需要bounding box）。在某些情形中使用传统SFM/SLAM方法失效而本方法却能够重建出来（因为这些情形缺少纹理，或者摄像机的拍摄视角变化大）。3D-R2N2是自动学习的、end-to-end的。性能超越了SOTA。</p>
<p>创新点：使用RNN来实现允许单图片/多图片的输入</p>
<p>注：</p>
<ul>
<li>3D-R2N2 == 3D Recurrent Reconstruction Neural Network</li>
<li><p>先前方法的要求条件（因为SFM/SLAM这类方法假设了features can be matched across views）：</p>
<ul>
<li><p>观察的视角密集，即相机的位置变化比较小</p>
</li>
<li><p>表面是Lambertian reflectance，即均匀的漫反射</p>
</li>
<li><p>表面的纹理丰富，不单一</p>
</li>
</ul>
</li>
<li>所使用的数据集：ShapeNet、PASCAL 3D、Online Products、MVS CAD Models</li>
<li>所对比的模型：Kar et al.（《Category-Specific Object Reconstruction from a Single Image》）、Multi View Stereo method（MVS）</li>
</ul>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p><img src="1_1.png" alt></p>
<p>利用RNN的“可接受任意长的序列输入”的性质，来达到单视图/多视图输入的统一。</p>
<p>首先将图片利用2D conv编码成1024维的特征向量。然后丢到3D Convolutional LSTM中，输出是$4\times 4\times 4$大小的voxels（4D tensor），每个voxel位置上都是一个vector（其实是排列成$4\times 4\times 4$的64个LSTM单元，然后取hidden state作为每个voxel的特征向量）。然后将4D tensor丢到3D conv中上采样，得到$32\times 32\times 32$的3D occupancy grid（每个voxel位置上是这个voxel取到的概率，所以需要一个threshold来确定最终的输出）。</p>
<p>随着输入图片变多，得到的结果也逐渐变得精细。</p>
<p>视觉上解释LSTM带来的优点：LSTM的遗忘门/输入门机制对应于自动纠错错误重建的部分/自动重建未看见的部分（有效的处理物体遮挡问题）</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>分为三部分：2D Convolutional Neural Network (2D-CNN), a novel architecture named 3D Convolutional LSTM (3D-LSTM), and a 3D Deconvolutional Neural Network (3D-DCNN)</p>
<ol>
<li><p>Encoder: 2D-CNN</p>
<p>可以使用普通的浅CNN（上面那个），或者是使用残差结构的深CNN（下面那个）。实验表明残差结构更好。</p>
<p><img src="1_2.png" alt></p>
</li>
<li><p>Recurrence: 3D Convolutional LSTM</p>
<p><img src="1_3.png" alt></p>
<p>在实施例中，有64个不同的LSTM单元，排列成$4\times 4\times 4$的形状。经过某种计算之后，我们取每个LSTM单元的$N_h$维的hidden state作为输出，于是得到$4\times 4\times 4 \times N_h$的4D tensor输出。计算过程如下：</p>
<p><img src="1_4.png" alt></p>
<p>其中$f_t$是遗忘门，$i_t$是输入门，$s_t$是memory cell，$h_t$是hidden state。</p>
<p>先考虑在一个位置上的计算：$U*h_{t-1}$表示周围邻居（红色）的$t-1$时刻的hidden state的线性加权和$\sum_{k \in \mathcal{N}_{index}} u_k h_{t-1}[k]$，$\mathcal{T(x_t)}$表示$t$时刻的1024维向量输入。那么输出$h_t$就是一个向量。</p>
<p>如果考虑全部64个LSTM单元，那么输出$h_t$就是一个4D tensor。</p>
<p>作者在这里没有使用outputs gate，节省了参数量。这里的kernel size是3。</p>
<p>当然也有基于GRU（Gated Recurrent Unit）的实现方法，实验表明GRU效果好于LSTM，kernel size为3时好于为1时。</p>
</li>
<li><p>Decoder: 3D Deconvolutional Neural Network</p>
<p>可以用普通的3D卷积，也可以用残差结构的3D卷积。</p>
<p>最后将$32\times 32\times\times 32 \times 2$的输出套用softmax，得到voxel-wise的概率值（尺寸$32\times 32\times \times 32$）。然后用threshold截断概率便得到最后的结果。</p>
<p>损失函数是the sum of voxel-wise cross-entropy</p>
</li>
<li><p>训练和效果</p>
<ul>
<li>Data augmentation： augmented the input images with random crops、tinted the color、randomly translated the images、all viewpoints were sampled randomly</li>
<li>Training： variable length inputs ranging from one image to an arbitrary number of images</li>
<li>Metrics： voxel Intersection-over-Union (IoU)、cross-entropy loss</li>
</ul>
</li>
</ol>
<h2 id="PointOutNet"><a href="#PointOutNet" class="headerlink" title="PointOutNet"></a>PointOutNet</h2><blockquote>
<p>CVPR2017《A Point Set Generation Network for 3D Object Reconstruction from a Single Image》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Fan_A_Point_Set_CVPR_2017_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2017/html/Fan_A_Point_Set_CVPR_2017_paper.html</a></p>
</blockquote>
<h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><p>作者是第一个用深度学习重建点云的人。输入单张图片，输出点云的3D坐标。他们构造的模型是“conditional shape sampler”（即有个输入变量$r$可以控制生成的多样性，用于描述重建的不确定性），可以输出多种可能的点云（取决于$r$）。单图输入的情况下性能超越SOTA（与3D-R2N2对比）。也可以用于3D补全，以及多可能的输出。</p>
<p>似乎没深究如何生成点云以达到无序性输出，文中好像是在fc/conv这样的结构化排列中输出的？</p>
<p>难点：</p>
<ul>
<li>如何输出点云</li>
<li>仅靠输入的单张图片难以直接确定3D形状（即inherent ambiguity in groundtruth）</li>
</ul>
<p>特点：</p>
<ul>
<li>引入随机变量$r$可以从输入操控生成点云的多样性</li>
</ul>
<p>作者的Discussion：</p>
<ul>
<li>First, how to generate an orderless set of entities. Towards building generative models for more sophisticated combinatorial data structures such as graphs, knowing how to generate a set may be a good starting point.</li>
<li>Second, how to capture the ambiguity of the groundtruth in a regression problem. Other than 3D reconstruction, many regression problems may have such inherent ambiguity. Our construction of the MoN loss by wrapping existing loss functions may be generalizable to these problems.</li>
</ul>
<p>TODO IDEA：能否不使用“Distance Metric between Point Sets”，转而使用能直接处理点云的网络？能否定向操控$r$各个分量所对应的3D属性？</p>
<h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><p>主要由三部分组成：architecture, loss function and learning paradigm</p>
<p>注：architecture的作用是根据图片和随机向量$r$来生成点云；loss function的作用是度量点云相似度；learning paradigm作用是使得随机变量$r$能在网络中起作用，相当于在loss function外部包上了一层“MoN函数”。</p>
<ol>
<li><p>Architecture - Point Set Prediction Network（此网络简记作$\mathbb{G}$）</p>
<p><img src="2_1.png" alt></p>
<p>作者设计了3种网络的结构：vanilla version、two prediction branch version和hourglass version</p>
<p>每种网络都有encoder stage和predictor stage。encoder stage用于将图片$I$和输入的随机向量$r$映射到embedding space；而predictor则输出一个$N \times 3$大小的矩阵$M$（$N$是重建出的点云的点数）。A random vector $r$ is subsumed so that it perturbs the prediction from the image $I$（随机向量$r$的用法在“Generation of Multiple Plausible Shapes”会讲到）</p>
<ul>
<li>vanilla version：最原始的版本，细节见图（r.v.就是随机向量$r$）。Though simple, this version works reasonably well in practice.</li>
<li>two prediction branch version：目的是better accommodate large and smooth surfaces which are common in natural objects。它的predictor有两个并行的分支：a fully-connected (fc) branch and a deconvolution (deconv) branch。fc branch预测$N_1=256$个点（fc输出256*3个nodes），deconv branch预测输出$H \times W=24\times 32$个点（排列成$24\times 32$然后一个像素对应一个3D的点，是3通道的）。那么总共输出$N = 24 \times 32 + 256=1024$个点（不知道如何处理无序性呢？？）。Their predictions are later merged together to form the whole set of points in $M$. Multiple skip links are added to boost information flow across encoder and predictor。fc branch功能：high flexibility、可describe intricate structures。deconvolution branch功能：节省参数、more friendly to large smooth surfaces, due to the spatial continuity induced by deconv and conv。</li>
<li>hourglass version：This deep network conducts the encoding-decoding operations recurrently, thus has stronger representation power and can mix global and local information better.</li>
</ul>
</li>
<li><p>Loss function - Distance Metric between Point Sets</p>
<p>对Loss的要求：可微、高效计算、对异常点鲁棒</p>
<p>那么需要找到一种衡量两个点云$S_i^{pred}$和$S_i^{gt}$相似度的距离函数$d(S_i^{pred}，S_i^{gt})$，那么损失函数就是$L = \sum_i d(S_i^{pred}，S_i^{gt})$（其中$i$是training samples的index。这个损失函数还不是最终的损失函数，不能实际应用）</p>
<p>作者建议使用Chamfer distance（CD）或Earth Mover’s distance（EMD）</p>
<p><img src="2_2.png" alt></p>
<p>Facing the inherent inability to resolve the shape precisely, neural networks tend to predict a “mean” shape averaging out the space of uncertainty. The mean shape carries the characteristics of the distance itself.</p>
</li>
<li><p>Learning paradigm - Generation of Multiple Plausible Shapes</p>
<p>The ambiguity of groundtruth shape may significantly affect the trained predictor, as the loss function induces our model to predict the mean of possible shapes. So We expect that the random<br>variable $r$ passed to “Point Set Prediction Network” would help it explore the groundtruth distribution. 如果跳过这步不做的话，就会导致the loss minimization will nullify the randomness.</p>
<p>我们可以使用最小化下面的损失函数（称作Min-of-N loss （MoN））的方法来解决：</p>
<p><img src="2_3.png" alt></p>
<p>意思是尝试$n $个random variable的取值，然后取最小距离作为距离值。（$n=2$足矣）</p>
<p>另一种方法是使用Conditional VAE（这样好像$\mathbb{G}$里就不用$r$了），详情略。</p>
<p>似乎也能用Conditional GAN，但是作者没深究。</p>
</li>
</ol>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>用ShapeNet dataset，从CAD模型中渲染出图片来</p>
<ol>
<li><p>3D Shape Reconstruction from RGB Images</p>
<p>与3D-R2N2作比较。将3D-R2N2输出的体数据用最远点采样获得点数据，然后计算CD、EMD值；将本模型输出的点数据经过后期处理得到体数据，然后计算IoU值。</p>
<p>实验表明本方法在单张图片输入时，在所有种类上精度远超3D-R2N2。同时大部分种类的精度远超5张图片输入的3D-R2N2。而且本方法不存在“薄弱细小结构”不能重建的缺点。</p>
</li>
<li><p>3D Shape Completion from RGBD Images</p>
<p>当是RGBD输入时，还可以起到3D补全的作用。</p>
<p><img src="2_4.png" alt></p>
</li>
<li><p>Predicting Multiple Plausible Shapes</p>
<p>改变$r$值可以产生多种输出。</p>
<p><img src="2_5.png" alt></p>
</li>
<li><p>Network Design Analysis</p>
<ul>
<li><p>Effect of combining deconv and fc branches for reconstruction</p>
<ul>
<li><p>deconv的引入提升了精度；Stacking another hourglass level也提升了精度</p>
</li>
<li><p>In the deconv branch the network learns to use the convolution structure to constructs a 2D surface that warps around the object. In the fully connected branch the output is less organized as the channels are not ordered.</p>
</li>
<li><p>The deconv branch is in general good at capturing the “main body” of the object, while the fully connected branch complements the shape with more detailed components</p>
<p><img src="2_6.png" alt></p>
</li>
</ul>
</li>
<li><p>Analysis of distance metrics</p>
<p>The network trained by CD tends to scatter a few points in its uncertain area (e.g. behind the door) but is able to better preserve the detailed shape of the grip. In contrast, the network trained by EMD produces more compact results but sometimes overly shrinks local structures. This is in line with experiment on synthetic data.</p>
</li>
</ul>
</li>
<li><p>More results and application to real world data</p>
<p>也能用于现实生活中照片的3D重建，但需要从背景分割出物体来</p>
</li>
<li><p>Analysis of human ability for single view 3D reconstruction</p>
<p>某些图片上超越人类</p>
</li>
<li><p>Analysis of failure cases</p>
<p>仅仅是主观分析，略</p>
</li>
</ol>
<h2 id="OGN"><a href="#OGN" class="headerlink" title="OGN"></a>OGN</h2><blockquote>
<p>ICCV2017《Octree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputs》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_iccv_2017/html/Tatarchenko_Octree_Generating_Networks_ICCV_2017_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_iccv_2017/html/Tatarchenko_Octree_Generating_Networks_ICCV_2017_paper.html</a></p>
</blockquote>
<h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><p>使用八叉树（octree）的表示法，生成高分辨率的3D体素数据。本文中的OGN是deep convolutional decoder（即3D体素生成器）。近似平方的复杂度（而不是立方复杂度），大大节省了内存和计算量消耗。低分辨率时与普通的voxel方法精度差不多，而且它还能生成高分辨率体素，甚至可以生成$512^3$这么大的分辨率。可以用在多种场合，如3D convolutional autoencoders、reconstruction from high-level representations or a single image</p>
<p><img src="3_3.png" alt></p>
<p>注意：</p>
<ul>
<li>使用octree意味着可以使用不同大小的cell size，不断细分大的cell来达到高分辨率。即不断精细化体素来达到高分辨率</li>
<li>OGN是在八叉树上操作。用binary occupancy maps来表示生成的形状</li>
<li>同时OGN也是灵活的，即可以任意指定层数和层的配置</li>
<li>OGN是end-to-end的，可用反向传播计算</li>
</ul>
<h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p><img src="3_1.png" alt></p>
<ul>
<li><p>最左边的“dense block”由普通的3D卷积层组成，输出$d_1 \times d_2 \times d_3 \times c$大小的4D tensor。</p>
</li>
<li><p>然后这个4D tensor被转换为键值对（index-value pairs）存储在hash table中，value就是一个voxel内的特征向量。</p>
</li>
<li><p>然后接下来的octree block就会预测octree新生成的结构、和相应生成的内容（特征向量）。</p>
</li>
<li><p>多次通过octree block处理就会生成高精度的体素表示。</p>
</li>
</ul>
<h3 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>Octree编码法</p>
<p>作用：将体素空间用octree表示，那么对voxel grid的操作就可以转换为对octree的操作</p>
<p>基于哈希表的Octree编码（可以实现常数时间的元素获取）：</p>
<ul>
<li><p>Octree cell的空间坐标$\mathtt{x}=(x,y,z)$，其在树中的层级（分辨率等级）为$l$，其内容为$v$。</p>
</li>
<li><p>将其转换为索引$m=\mathcal{Z}(\mathtt{x},l)$，其中$\mathcal{Z}(\cdot)$是Z-order curve。</p>
</li>
<li><p>那么就形成了键值对$(m,v)$。于是八叉树就是$O=\{(m,v)\}$</p>
</li>
</ul>
<p>那么数据操作和更新都在hash table中进行。</p>
<p>查值函数（从八叉树$O$中获取值）：</p>
<p><img src="3_2.png" alt></p>
</li>
<li><p>Octree Generating Networks</p>
<p>binary occupancy values $v=\{0,1\}$</p>
<p>由普通3D卷积生成$d_1 \times d_2 \times d_3 \times c$大小的4D tensor，然后被转换成octree，并将数据存储在hash table中。</p>
<p><img src="3_4.png" alt></p>
<p>图中为了示意的简便起见，用2D voxel替代3D voxel来展示。</p>
<p>propagated features是指需要处理或细分的网格特征</p>
<p>empty是指不是实体的网格</p>
<p>filled是指被占据、是实体的网格</p>
<p>mixed是指需要细分的网格（与GT相比既有empty又有filled）</p>
<ul>
<li><p>OGN-Conv</p>
<p>OGN-Conv需要处理由哈希表表示的特征图。OGN-Conv支持步长卷积和上采样卷积。</p>
<p>基本原理（类似于“im2col”和“col2im”函数）：将hash table转变为feature matrix，然后与权重矩阵相乘，再复原回hash table</p>
</li>
<li><p>OGN-Loss</p>
<p>predictions就是判断voxel是empty/filled/mixed中的哪种，是3分类问题。用$1^3$卷积和softmax实现即可。</p>
<p>最小化predictions与the cell state of the ground truth的交叉熵：</p>
<p><img src="3_5.png" alt></p>
<p>$p_m^i$是输出概率值，$M_l$是第$l$层的叶子集合。那么总目标函数就是全部层的$\mathcal{L_l}$的求和。</p>
</li>
<li><p>OGN-Prop</p>
<p>将预测出来是“mixed”的取出来作为输出。可能还要取出一些其他的邻居，以便用于接下来的卷积计算。</p>
<p>根据在测试阶段是否知道Octree的GT，传播方式分为：Prop-Known方法（例如语义分割，结构不变，只需要与GT做对比即可）和Prop-Pred方法（例如三维重建，结构需要你预测，需要训练分类模型来判断每个voxel是empty/filled/mixed中的哪种）。不详述。</p>
</li>
</ul>
</li>
</ol>
<h2 id="MarrNet"><a href="#MarrNet" class="headerlink" title="MarrNet"></a>MarrNet</h2><blockquote>
<p>NIPS2017《MarrNet: 3D Shape Reconstruction via 2.5D Sketches》</p>
<p>paper下载：<a href="http://papers.nips.cc/paper/6657-marrnet-3d-shape-reconstruction-via-25d-sketches" target="_blank" rel="noopener">http://papers.nips.cc/paper/6657-marrnet-3d-shape-reconstruction-via-25d-sketches</a></p>
</blockquote>
<h3 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h3><p>从单张图片重构出3D voxel-based reconstruction。从RGB图得到2.5D表示，再转换成3D形状（two-step）。MarrNet可以在synthetic data数据上训练然后在real data上进行self-supervised的fine-tune（一定程度上解决了domain adaptation问题）。MarrNet是end-to-end的可训练模型，达到了SOTA。</p>
<p>2D → 2.5D → 3D的优点：</p>
<ul>
<li>First, compared to full 3D shape, 2.5D sketches are much easier to be recovered from a 2D image; models that recover 2.5D sketches are also more likely to transfer from synthetic to real data.</li>
<li>Second, for 3D reconstruction from 2.5D sketches, systems can learn purely from synthetic data.</li>
<li>Third, we derive differentiable projective functions from 3D shape to 2.5D sketches; the framework is therefore end-to-end trainable on real images, requiring no human annotations</li>
</ul>
<p>注：</p>
<ul>
<li>取名MarrNet是因为与David Marr’s theory of perception相近</li>
<li>intrinsic images（描述物体内在固有属性的可分离的本质图像）：例如depth、surface normals、silhouette等等</li>
<li>Reprojection Consistency只在fine-tune中使用；预训练使用与GT voxel gird比较的交叉熵。</li>
<li>本文定性分析（图片展示）比较多，定量分析比较少（只有人类肉眼比较结果和一个IoU结论）</li>
<li>我感觉本文的ablation study说服力不足，即不能说明fine-tune是有效的，并不能说明Reprojection Consistency的设计是起到实际作用的。详见实验的第二部分。</li>
</ul>
<h3 id="原理-2"><a href="#原理-2" class="headerlink" title="原理"></a>原理</h3><p><img src="4_1.png" alt></p>
<p>用2D CNN的方法生成2.5D图，然后将2.5D图用encoder-decoder方法生成体素表示。用reprojection consistency loss确保3D与2.5D匹配。</p>
<h3 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>2.5D Sketch Estimation</p>
<p>用encoder-decoder结构生成2.5D表示。用ResNet-18编码，将256x256的RGB转变为8x8x256的特征图。然后用decoder恢复成256x256的depth, surface normal, and silhouette images</p>
</li>
<li><p>3D Shape Estimation</p>
<p>用encoder-decoder结构生成3D体素。输入depth和normal图（施加以silhouette images掩膜），然后用卷积转变为200维向量，然后用3D卷积生成128x128x128的体素表示。</p>
</li>
<li><p>Reprojection Consistency</p>
<p>使得3D表示与2.5D表示相一致，即将2.5D投射到3D空间中，体素也需要具有与2.5D的描述相一致的性质。reprojection consistency loss分为depth reprojection loss和surface normal reprojection loss。并且reprojection consistency loss对voxel可求导，使得可以用反向传播计算和优化。</p>
<p>记3D voxel grid在$(x,y,z)$处存在该voxel的概率为$v_{x,y,z}\in[0,1]$，深度图在$(x,y)$处的值为$d_{x,y}$，法向图在$(x,y)$处的法向为$n_{x,y}=(n_a,n_b,n_c)$。并且假设是<strong>正交投影</strong>（注意这里不是相机成像的投影模型）</p>
<p><img src="4_3.png" alt></p>
<ul>
<li><p>depth reprojection loss的目标是：将depth image的point投影到3D中，使得这个3D point恰好出现在3D voxel reconstruction中，并且该点的视线前方无遮挡。</p>
<p><img src="4_2.png" alt></p>
</li>
<li><p>surface normal reprojection的目标是：使得该点在3D切平面上的邻居存在</p>
<p>已知法向$n_{x,y}=(n_a,b_b,n_c)$必定与$n_x’=(0,-1,n_b/n_c)$、$n_y’=(-1,0,n_a/n_c)$垂直。那么voxel在$(x,y,z)\pm n_x’$和$(x,y,z)\pm n_y’$的值必定为1（当这些点在silhouette image以内时才算）。</p>
<p><img src="4_4.png" alt></p>
</li>
</ul>
</li>
<li><p>Training paradigm</p>
<p>将“2.5D sketch estimation”和“3D shape estimation”分别在synthetic images上预训练：The 3D interpreter is trained using ground truth voxels and a <strong>cross-entropy loss</strong>（注意预训练是用与GT比较的交叉熵！）</p>
<p>然后再在真实图片上fine-tune：The <strong>reprojection consistency loss</strong> is used to fine-tune the 3D estimation component of our model on real images, using the predicted normal, depth, and silhouette。固定decoder of the 3D estimator（因为它包含了3D形状的先验，不希望改变），只fine-tune the encoder（学习映射到decoder合理的特征空间中）。这种fine-tune类似自监督，可以在无任何标注的单张测试图片上进行fine-tune。</p>
</li>
</ol>
<h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><ol>
<li><p>3D Reconstruction on ShapeNet</p>
<p>生成的形状具有smoother surfaces and finer details</p>
<p>Our full model achieves a higher IoU (0.57) than the direct prediction baseline (0.52).</p>
<p>direct prediction baseline：不经过2.5D表示，直接基于3D卷积的体素生成</p>
</li>
<li><p>3D Reconstruction on Pascal 3D+</p>
<p>现在ShapeNet上预训练，然后fine-tune them on the PASCAL 3D+ dataset</p>
<p><img src="4_5.png" alt></p>
<p>上图的ablation study表明，需要固定decoder of the 3D estimator进行fine-tune才能取得更好的fine-tune效果。</p>
<p>但感觉本文的ablation study说服力不足，文中说The model trained on synthetic data provides a reasonable shape estimate和Our final model, fine-tuned with the decoder fixed, keeps the shape prior and provides more details of the shape，这只是作者自己的观点，并没有数据支撑，并且“human studies”中并没有fine-tune前后的“preferences”对比，并不能说明fine-tune是有效的，即并不能说明Reprojection Consistency的设计是有作用的。</p>
<p>作者认为IoU指标不好，不能描述精细结构等，提出“human studies”，即人类肉眼比较MarrNet和竞争对手DRC哪个效果比较好。效果当然是说MarrNet比较好啦。</p>
<p><img src="4_6.png" alt></p>
<p>MarrNet不能复原复杂的、细弱的结构，而且silhouette mask不能精确估计。</p>
</li>
<li><p>3D Reconstruction on IKEA</p>
<p>IKEA furniture数据集，our model can deal with mild occlusions in real life scenarios</p>
</li>
<li><p>Extensions</p>
<p>We further train MarrNet jointly on all three object categories, and our model successfully recovers shapes of different categories</p>
</li>
</ol>
<h2 id="LSM"><a href="#LSM" class="headerlink" title="LSM"></a>LSM</h2><blockquote>
<p>NIPS2017《Learning a Multi-View Stereo Machine》</p>
<p>paper下载：<a href="http://papers.nips.cc/paper/6640-learning-a-multi-view-stereo-machine" target="_blank" rel="noopener">http://papers.nips.cc/paper/6640-learning-a-multi-view-stereo-machine</a></p>
</blockquote>
<h3 id="概述-4"><a href="#概述-4" class="headerlink" title="概述"></a>概述</h3><p>利用n幅图像（n≥1）以及这些摄像机的内外参（camera poses），求出物体的体素重建（Voxel LSM）或相应的n幅深度图（Depth LSM）。LSM端到端可微分。核心思想：利用投射关系将2D排列的特征与3D排列的特征相互转换，且能此过程可微分，使其利用了空间投影关系的几何先验。</p>
<p>注：</p>
<ul>
<li>多视角立体视觉（Multi-view stereopsis，简称MVS）：给定物体的多幅图像、这些图像所分别拍摄的摄像机的姿态（内参和外参），试求物体的几何表示（3D结构/深度图等）</li>
<li>LSM == Learnt Stereo Machine</li>
<li>our system is able to better use camera pose information leading to significantly large improvements while adding more views（然而对比的网路（3D-R2N2）是add pose information in a fully connected manner，并没有专门对此设计过）</li>
<li>可能作者调参和优化了很久。。。</li>
</ul>
<p>TODO IDEA：将几何投影等关系编码且使得可微分，使得可以反向传播。</p>
<h3 id="实现-4"><a href="#实现-4" class="headerlink" title="实现"></a>实现</h3><p><img src="5_1.png" alt></p>
<p>简述：输入n幅图像，然后经过2D CNN特征提取出2D的特征图。再分别使用“unprojection”操作得到3D排列的体特征$\mathcal{G}^f_i$。然后使用RNN将其全部整合成一个体特征$\mathcal{G}^p$。再将其用3D卷积得到$\mathcal{G}^o$。如果想得到体素表示，则直接使用3D卷积生成即可；如果想得到相应的深度图，则使用“projection”操作转换为2D特征图之后再使用2D卷积上采样即可。</p>
<ol>
<li><p>2D Image Encoder</p>
<p>用UNet生成特征图。从图像$\{I_i\}^n_{i=1}$转变为特征图$\{\mathcal{F}_i\}^n_{i=1}$</p>
</li>
<li><p>Differentiable Unprojection</p>
<p>输入特征图和相机姿态，输出3D排列的特征。</p>
<p>即从特征图$\{\mathcal{F}_i\}^n_{i=1}$转变为3D gird$\{\mathcal{G}_i^f\}^n_{i=1}$</p>
<p><img src="5_2.png" alt></p>
<p>上图只是方便图示而已，实际上是3D gird和2D feature map。</p>
<p>实际实现过程：将3D gird center投影到image plane得到连续的坐标，然后根据discrete grid的feature value用bilinear sampling插值得到该3D gird的feature</p>
<p>为了可以支持单张图片输入，我们还往每个3D gird中添加几何特征（例如depth value和ray direction）</p>
<p>这个过程是可微分的，使得可以端到端训练。</p>
</li>
<li><p>Recurrent Grid Fusion</p>
<p>从多个3D gird$\{\mathcal{G}_i^f\}^n_{i=1}$到单个$\mathcal{G^p} $</p>
<p>使用3D convolutional variant of the Gated Recurrent Unit (GRU)，类似于3D-R2N2中的做法。</p>
<p>训练时随机打乱输入的顺序，减小输入顺序带来的影响。</p>
</li>
<li><p>3D Grid Reasoning</p>
<p>将$\mathcal{G^p} $转变为$\mathcal{G^o} $</p>
<p>使用3D UNet。目的（感觉乱说。。）：use shape cues present in $\mathcal{G^p} $ such as feature matches and silhouettes as well as build in shape priors like smoothness and symmetries and knowledge about object classes enabling it to produce complete shapes even when only partial information is visible</p>
</li>
<li><p>Differentiable Projection</p>
<p>从$\mathcal{G^o}$转变为多个2D feature map$\{\mathcal{O}_i\}^n_{i=1}$</p>
<p>输入：$\mathcal{G^o}$和相机姿态。输出：2D feature map$\mathcal{O}$</p>
<p><img src="5_3.png" alt></p>
<p>上图只是方便图示而已，实际上是3D gird和2D feature map。</p>
<p>实际实现过程：有多个平行于相机平面的等间距平面（图中的z=1,2,3平面），视线ray是穿过2D feature map的离散格点中心的。由此横穿经过的3D gird的特征值就作为特征值。在3D gird中是nearest neighbor interpolation而不是trilinear interpolation。详情见上图。</p>
<p>最后使用1x1的卷积可以减少channels的数量。</p>
</li>
<li><p>Architecture Details and Experiments</p>
<p>卷积均使用instance normalization和layer normalization</p>
<ul>
<li><p>Voxel LSM (VLSM)：最后使用3D卷积上采样。softmax + binary cross entropy loss</p>
</li>
<li><p>Depth LSM (D-LSM)：使用Projection将$\mathcal{G^o}$转变为多个2D feature map$\{\mathcal{O}_i\}^n_{i=1}$，然后分别进行1x1卷积和deconvolution上采样，其中deconvolution有skip connections来自之前的image encoder。</p>
</li>
</ul>
<p>Experiments性能：</p>
<p><img src="5_4.png" alt></p>
</li>
</ol>
<h2 id="IM-NET"><a href="#IM-NET" class="headerlink" title="IM-NET"></a>IM-NET</h2><blockquote>
<p>CVPR2019《Learning Implicit Fields for Generative Shape Modeling》</p>
<p>paper下载：<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Implicit_Fields_for_Generative_Shape_Modeling_CVPR_2019_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Implicit_Fields_for_Generative_Shape_Modeling_CVPR_2019_paper.html</a></p>
</blockquote>
<h3 id="概述-5"><a href="#概述-5" class="headerlink" title="概述"></a>概述</h3><p>使用隐式场的方法来生成3D点云，后处理后的形成的mesh具有superior visual quality（higher surface quality）。并在插值时表现出良好的过度性质。所使用的implicit field decoder称作IM-NET，可以用于3D形状自编码（即shape representation learning）（IM-AE）、形状生成（IM-GAN）、形状插值、单视图3D重建等。其中encoder不属于本文设计范畴，只要能得到shape feature的都可以。</p>
<p>注：</p>
<ul>
<li>Our work is the first to introduce a deep network for learning implicit fields for generative shape modeling</li>
<li>缺点：训练时间长（因为the decoder needs to be applied on each point in the training set），或许可以考虑只生成物体表面的点来提高速度</li>
</ul>
<p>TODO IDEA：后期可以考虑用decoder来生成其他的属性，例如颜色、纹理等。或许还可以用来做part segmentation</p>
<h3 id="原理-3"><a href="#原理-3" class="headerlink" title="原理"></a>原理</h3><p>decoder的关键是怎么根据shape feature得到出3D数据（点云）。这通过判断给定点$p$是处于shape的内部还是外部来实现的，那么中间的分界等值面就是shape的边界。</p>
<p><img src="6_1.png" alt></p>
<p>构造一个MLP，输入是shape feature和point coordinate，输出是判断内外部的二分类（sigmoid函数）。</p>
<p><img src="6_2.png" alt></p>
<p>其中输入的point coordinate对空间的均匀采样得到的，因而输出形状的分辨率可以任意高。</p>
<p>The skip connections（copy and concatenate）可以使训练稳定、加快训练。</p>
<h3 id="实现-5"><a href="#实现-5" class="headerlink" title="实现"></a>实现</h3><ol>
<li><p>用decoder $f_\theta(p)$为每个点$p$计算“是内部点的概率”（$f_\theta(p):[0,1]^3 \rightarrow [0,1]$），然后计算等值面（如3D形状则使用Marching Cubes方法，2D图像则使用applying thresholding方法），从而得到mesh表示。对于闭合形状，GT为$\mathcal{F}(p)$内部取1外部取0。</p>
</li>
<li><p>decoder训练方法（可采取的方法有两种）（作者的实现方式是一个decoder只对应一个物体种类）：</p>
<ul>
<li>A naive sampling：将训练形状的空间离散化（voxelize or rasterize），然后均匀采样。多分辨率采样依次得到$16^3,32^3,64^3,128^3$个点。先用低分辨率训练再逐渐用高分辨率训练（train the model progressively）。大致是立方复杂度。</li>
<li>A more efficient approach：采样更多的靠近表面的点，对离表面比较远的点不采样。然后对采样的每个点都有个权重$w_p$，是该点采样密度的倒数，用以补偿采样密度的变化。大致是平方复杂度。</li>
</ul>
</li>
<li><p>损失函数（$S$是采样得到的点集）：</p>
</li>
</ol>
<script type="math/tex; mode=display">
\mathcal{L}(\theta)=\frac{\sum_{p \in S}|f_\theta(p)-\mathcal{F}(p)|^2 \cdot w_p}{\sum_{p \in S} w_p}</script><ol>
<li><p>IM-NET的应用举例</p>
<ul>
<li><p>Auto-Encoding：使用3D卷积从$64^3$的voxels中提取128维特征，然后decoder使用IM-NET。使用progressive training。</p>
</li>
<li><p>3D shape generation：使用autoencoder中训练好的encoder的输出作为latent-GAN的输入</p>
</li>
<li><p>single-view 3D reconstruction（SVR）：用ResNet将$128\times128$的图像编码成128维的特征向量。使用autoencoder中训练好的decoder，固定其参数不变，只训练ResNet的参数（encoder）去最小化mean squared loss</p>
</li>
</ul>
</li>
</ol>
<h3 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h3><ol>
<li><p>获取point cloud之后，转换为mesh（如Marching Cubes方法），最后用Poisson-disk Sampling获取10000个表面的点。</p>
</li>
<li><p>作者觉得chamfer distance（CD）、mean squared error（MSE）、IoU并不能很好的描述物体表面的视觉性质（例如桌子面发生一点点上下的移动将剧烈地改变IoU的值，但是视觉上的效果却差不多；并且IoU指标并不抵制表面的凹凸起伏），提出使用计算机图形领域的light field descriptor（LFD）指标。以及coverage score（COV-LFD）、Minimum Matching Distance（MMD-LFD）指标。</p>
</li>
<li><p>插值效果</p>
<p><img src="6_3.png" alt></p>
<p>优点：cleaner surface boundaries、smooth part movements、handles topology changes</p>
<p>但是不知道如何控制这种变化的过程</p>
</li>
</ol>

            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">给小编加个鸡腿🍗呗</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>转载规则</span>
        </p>
        
            <div class="center-align">
                <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《3D结构重建》
                </span> 由
            <a xmlns:cc="http://creativecommons.org/ns#" href="/3d/3dreconstruction/" property="cc:attributionName"
               rel="cc:attributionURL">
                Karbo
            </a> 采用
            <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                知识共享署名 4.0 国际许可协议
            </a>进行许可。
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: 'WwrKLalwiFrnKlAcLCjpeyK7-gzGzoHsz',
        appKey: 'zF7jn8hejoyxVPESEeCAxCzY',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'ヾﾉ≧∀≦)o来评论啊，快活啊!'
    });
</script>
    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-dot-circle-o"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/3d/3dreconstruction/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/17.jpg" class="responsive-img" alt="3D结构重建">
                        
                        <span class="card-title">3D结构重建</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            本文是3D重建的学习笔记
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-10-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/3d/" class="post-category" target="_blank">
                                    3d
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/3d/" target="_blank">
                        <span class="chip bg-color">3d</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6 overflow-policy" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/english/englishgrammar/">
                    <div class="card-image">
                        
                        <img src="/english/englishgrammar/1.jpg" class="responsive-img" alt="英语语法基础">
                        
                        <span class="card-title">英语语法基础</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            简单介绍了英语的基本语法规则
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-10-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/english/" class="post-category" target="_blank">
                                    english
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/english/" target="_blank">
                        <span class="chip bg-color">english</span>
                    </a>
                    
                    <a href="/tags/grammar/" target="_blank">
                        <span class="chip bg-color">grammar</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            本站由
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">hexo-theme-matery</a>主题搭建.

            
            &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
            <span class="white-color">81.3k</span>
            

            
            
            <br>
            
            <span id="busuanzi_container_site_pv">
                <i class="fa fa-heart-o"></i>
                本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                <i class="fa fa-users"></i>
                次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
            </span>
            
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
<a href="https://github.com/Karbo123" class="tooltipped" target="_blank" data-tooltip="我的GitHub" data-position="top"
    data-delay="50">
    <i class="fa fa-github"></i>
</a>



<a href="https://www.zhihu.com/people/karbo-50/activities" class="tooltipped" target="_blank" data-tooltip="我的知乎" data-position="top"
    data-delay="50">
    <i class="fa fa-user"></i>
</a>



<a href="mailto:lei@karbo.online" class="tooltipped" target="_blank" data-tooltip="邮件联系"
    data-position="top" data-delay="50">
    <i class="fa fa-envelope-open"></i>
</a>



<a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top"
    data-delay="50">
    <i class="fa fa-rss"></i>
</a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>

<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


</body>
</html>